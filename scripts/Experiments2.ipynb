{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Orb2eLYb_yO",
    "outputId": "7ed6b930-d029-4042-8ed1-99f458894d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0aVDLvRV6NI",
    "outputId": "fb332979-3f85-4106-f205-97ae7889974f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2MB 128kB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2020.11.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Installing collected packages: gensim\n",
      "  Found existing installation: gensim 3.6.0\n",
      "    Uninstalling gensim-3.6.0:\n",
      "      Successfully uninstalled gensim-3.6.0\n",
      "Successfully installed gensim-3.8.3\n",
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 13.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 49.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
      "Collecting tokenizers==0.9.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 51.5MB/s \n",
      "\u001b[?25hCollecting sentencepiece==0.1.91\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 46.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=2bee60abaa6c7e189d52845175bc8e68a9ba8d1fd49e2499ddaecce3d1cb5e26\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n",
      "Collecting sentence-transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/5a/6e41e8383913dd2ba923cdcd02be2e03911595f4d2f9de559ecbed80d2d3/sentence-transformers-0.3.9.tar.gz (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 6.6MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: transformers<3.6.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.7.0+cu101)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (0.8)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (0.9.3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (3.12.4)\n",
      "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
      "Requirement already satisfied, skipping upgrade: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (0.1.91)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (2020.11.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<3.6.0,>=3.1.0->sentence-transformers) (50.3.2)\n",
      "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.6.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.6.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.9-cp36-none-any.whl size=101036 sha256=60dd6b2eb90421b42933e94a5e1d7b9fdc787123739907499781a404704bdd06\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/89/43/f2f5bc00b03ef9724b0f6254a97eaf159a4c4ddc024b33e07a\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-0.3.9\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim\n",
    "!pip install transformers\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OcoVA1wTNwz",
    "outputId": "3bd69639-f16a-4a3d-cc7b-22fdf8382380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, f1_score, roc_auc_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, FeatureExtractionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMgf1hFH-wCr"
   },
   "source": [
    "## Cosas BETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310,
     "referenced_widgets": [
      "15ac0fb85b884b9ebe812dc54e3e3d61",
      "ee3989d9c8eb487fae77a1ad38e37626",
      "b6d3d01f10d64925b106d73c7cfb6f51",
      "d56faf744e1a4bcb8810f8d76709206b",
      "6e19da41b1c44f938d5fd023830c18ae",
      "d62de3eda1bd43ceb760f2e26ee8515e",
      "17cdce25665c4aadb77751942e38a756",
      "84ec795d79514a35b132a7ba107841f8",
      "1c4fb33be96e440199f8cf044a345bd2",
      "e1a828789ab64aa29b39b91572b13973",
      "eb9b8662da6e4695953c51bd95ab11f8",
      "b22811169771464f851a48d1d46319aa",
      "4f7a5f01dbc847408a61e02eefc813a4",
      "1cf09e75e7294f54bb3ffb1bb168c00f",
      "f2bf38d48c8141bca58806d4d4b781eb",
      "12d4ec0e41b547f18081ac98130311c4",
      "10ea299972b24d80a33531ae521f5d22",
      "7045a41d27824c51899ec0f187ec3139",
      "9c21c394de054d06a58d6271acaab139",
      "31dc8f9280794864ade21dbcd69f3928",
      "2f5980dcea214cd5982a97a3e0f72109",
      "f5a13f99464b46ad93a4ba53c03a6bc6",
      "5371dc7f483949d5a9b10b58fc86d268",
      "bd1c33748983407da09c5809f01829ce",
      "faf93418916648688fa1ccd2a04ce4f0",
      "3bdba093eef54e5a97c4e601a1e93345",
      "94ae206a4a0b438a874e656fe89cc103",
      "0c35f97ff67f46028bf7db0153978d1b",
      "be44a211f3394357beef2d0801462a24",
      "f2be2d3551ad406e9f56cabd5c07fee6",
      "7456e6c6654d4879a8877963af04c18f",
      "cfd33404c83e409f98070ffdd70e14c2",
      "1906c14c542743d9a23f1975de6385dd",
      "01213c1a832d4470a2fa43f44eadcefb",
      "80275da53562465b9ccc99ffc44a577d",
      "6300c62468154b78be4b083a7930a077",
      "186e00ec9711432f800dad7208ee934d",
      "f9dca32ff2034723a27234c65831f250",
      "416e2afaa86a4909a7ec7a2380edccfb",
      "de294721cb3d443b81ba0b630c097ed7",
      "57afa95252b84bab88bc788afba2bca4",
      "7310f750736b490cbdf3c67ec6deb4a0",
      "baf4fa2efecd4051897dcbc219cf367e",
      "de0ebe4d5e6d4d17ac0504e3b46bcb9e",
      "151161a54c47429bb719f4c261ad6084",
      "1db4c30f7431453e89004c3473d61676",
      "ffb467ff52bf4c94921575a7afceb2bc",
      "f863635ea3474dc697f698fcd80aeb2b"
     ]
    },
    "id": "oWUPVHlljf43",
    "outputId": "a98c3142-bf2d-402d-cf62-79cac3f83117"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ac0fb85b884b9ebe812dc54e3e3d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=248047.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4fb33be96e440199f8cf044a345bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ea299972b24d80a33531ae521f5d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf93418916648688fa1ccd2a04ce4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=42.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1906c14c542743d9a23f1975de6385dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57afa95252b84bab88bc788afba2bca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=441944381.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n",
    "model = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n",
    "model.eval()\n",
    "BETO_features = FeatureExtractionPipeline(model, tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0KSLLLh7oYiI",
    "outputId": "505cafe7-d86c-46be-cbb4-cf386f109855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [4, 1734, 1151, 1932, 5], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "sen = \"Hola como estás\"\n",
    "tokens = tokenizer(sen)\n",
    "print(tokens)\n",
    "ft = BETO_features(sen)\n",
    "print(len(ft[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_flnW9UHoWCh",
    "outputId": "fdc69b9f-8bf3-4100-ff53-854fa4649244"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(\"hola\")['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXRnCc5Pegy2"
   },
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daW8jCneDpK3"
   },
   "outputs": [],
   "source": [
    "categories_number_words = {\n",
    "        1: \"Apoyo Pedagógico en asignaturas\",\n",
    "        3: \"Apoyo pedagógico personal\",\n",
    "        4: \"Tutoría entre pares\",\n",
    "        7: \"Hacer a la familia partícipe del proceso\",\n",
    "        8: \"Apoyo psicóloga(o)\",\n",
    "        9: \"Apoyo fonoaudióloga(o)\",\n",
    "        10: \"Apoyo Educador(a) Diferencial\",\n",
    "        11: \"Apoyo Kinesióloga(o)\",\n",
    "        12: \"Apoyo Médico General\",\n",
    "        13: \"Apoyo Terapeuta Ocupacional\",\n",
    "        14: \"Control Neurólogo\",\n",
    "        15: \"Apoyo Interdisciplinario\",\n",
    "        16: \"Adecuación curricular de acceso\",\n",
    "        17: \"Adecuación curricular de objetivos\"\n",
    "    }\n",
    "categories_words_number = {v: k for k, v in categories_number_words.items()}\n",
    "\n",
    "diagnoses_codes = {\n",
    "    \"Trastorno específico del lenguaje\": 0,\n",
    "    \"Trastorno por déficit atencional\": 1,\n",
    "    \"Dificultad específica de aprendizaje\": 2,\n",
    "    \"Discapacidad intelectual\": 3,\n",
    "    \"Discapacidad visual\": 4,\n",
    "    \"Trastorno del espectro autista\": 5,\n",
    "    \"Discapacidad auditiva - Hipoacusia\": 6,\n",
    "    \"Funcionamiento intelectual limítrofe\": 7,\n",
    "    \"Síndrome de Down\": 8,\n",
    "    \"Trastorno motor\": 9,\n",
    "    \"Multidéficit\": 10,\n",
    "    \"Retraso global del desarrollo\": 11\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yphNKf9AsBE"
   },
   "source": [
    "### Datasets preseparados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmmX--YS_Sf7"
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('gdrive/My Drive/magister/train_ds.csv', keep_default_na=False)\n",
    "val_dataset = pd.read_csv('gdrive/My Drive/magister/val_ds.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJQwRwNTIqyd",
    "outputId": "82d7d349-d683-4b6f-ae1a-72a31d0e71e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1836, 29)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "id": "pSL2yxz5JIdW",
    "outputId": "01ddd3d5-f01c-4659-db23-c5a465fe96ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encoded Diagnosis</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>All perceptions</th>\n",
       "      <th>Special Education Teacher Perceptions</th>\n",
       "      <th>Speech Therapist Perceptions</th>\n",
       "      <th>Psychologist Perceptions</th>\n",
       "      <th>Medical Perceptions</th>\n",
       "      <th>Amount of SET perceptions</th>\n",
       "      <th>Amount of ST perceptions</th>\n",
       "      <th>Amount of P perceptions</th>\n",
       "      <th>Amount of M perceptions</th>\n",
       "      <th>Has SET perceptions</th>\n",
       "      <th>Has ST perceptions</th>\n",
       "      <th>Has P perceptions</th>\n",
       "      <th>Has M perceptions</th>\n",
       "      <th>Apoyo Pedagógico en asignaturas</th>\n",
       "      <th>Apoyo pedagógico personal</th>\n",
       "      <th>Tutoría entre pares</th>\n",
       "      <th>Hacer a la familia partícipe del proceso</th>\n",
       "      <th>Apoyo psicóloga(o)</th>\n",
       "      <th>Apoyo fonoaudióloga(o)</th>\n",
       "      <th>Apoyo Educador(a) Diferencial</th>\n",
       "      <th>Apoyo Kinesióloga(o)</th>\n",
       "      <th>Apoyo Médico General</th>\n",
       "      <th>Apoyo Terapeuta Ocupacional</th>\n",
       "      <th>Control Neurólogo</th>\n",
       "      <th>Apoyo Interdisciplinario</th>\n",
       "      <th>Adecuación curricular de acceso</th>\n",
       "      <th>Adecuación curricular de objetivos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Discapacidad intelectual</td>\n",
       "      <td>En cuanto a Lenguaje y Comunicacion, [ESTUDIAN...</td>\n",
       "      <td>En cuanto a Lenguaje y Comunicacion, [ESTUDIAN...</td>\n",
       "      <td></td>\n",
       "      <td>-Establece relaciones sociales principalmente ...</td>\n",
       "      <td>Estudiante con atenciones medicas debido a su ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Discapacidad intelectual</td>\n",
       "      <td>En cuanto a Lenguaje y Comunicacion, [ESTUDIAN...</td>\n",
       "      <td>En cuanto a Lenguaje y Comunicacion, [ESTUDIAN...</td>\n",
       "      <td></td>\n",
       "      <td>-Establece relaciones sociales principalmente ...</td>\n",
       "      <td>-Estudiante con atenciones medicas debido a su...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Discapacidad intelectual</td>\n",
       "      <td>Habilidades (Cognitivas, comunicativas, social...</td>\n",
       "      <td>Habilidades (Cognitivas, comunicativas, social...</td>\n",
       "      <td></td>\n",
       "      <td>Comunica sus deseos y emociones de manera mas ...</td>\n",
       "      <td>Controles periodicos al dia. Equipo multidisci...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Discapacidad intelectual</td>\n",
       "      <td>scar, no presenta dificultades en el desarroll...</td>\n",
       "      <td>scar, no presenta dificultades en el desarroll...</td>\n",
       "      <td></td>\n",
       "      <td>[ESTUDIANTE], es un niño entusiasta y colabora...</td>\n",
       "      <td>Estudiante con un estado sano de salud, pero c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Trastorno motor</td>\n",
       "      <td>En [ESTUDIANTE] se evidencia preferencia por e...</td>\n",
       "      <td>En [ESTUDIANTE] se evidencia preferencia por e...</td>\n",
       "      <td></td>\n",
       "      <td>Estudiante cariñoso y respetuoso con sus compa...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Encoded Diagnosis  ... Adecuación curricular de objetivos\n",
       "0                  3  ...                                  0\n",
       "1                  3  ...                                  0\n",
       "2                  3  ...                                  0\n",
       "3                  3  ...                                  0\n",
       "4                  9  ...                                  0\n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyqmh1NTmfp_"
   },
   "source": [
    "### Datasets creados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAWH2vr1Rj15",
    "outputId": "8035753c-6284-470f-e0ff-68f4ba39cf05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'Diagnoses', 'Special Education Teacher Perceptions',\n",
       "       'Psychological Perceptions', 'Medical Perceptions',\n",
       "       'Speech Therapist Perceptions', 'Written Strategies',\n",
       "       'Encoded Strategies'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_strats = pd.read_csv('gdrive/My Drive/magister/anonimized_dataset.csv')\n",
    "columns = students_strats.columns\n",
    "for var in columns:\n",
    "    if var != 'Diagnoses' and var != 'Index':\n",
    "        students_strats[var] = students_strats[var].apply(ast.literal_eval)\n",
    "students_strats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3nCeNfxMhoJ"
   },
   "outputs": [],
   "source": [
    "joined_perceptions = []\n",
    "joined_set_perceptions = []\n",
    "joined_st_perceptions = []\n",
    "joined_p_perceptions = []\n",
    "joined_m_perceptions = []\n",
    "\n",
    "amount_set_perceptions = []\n",
    "amount_st_perceptions = []\n",
    "amount_p_perceptions = []\n",
    "amount_m_perceptions = []\n",
    "\n",
    "has_set = []\n",
    "has_st = []\n",
    "has_p = []\n",
    "has_m = []\n",
    "\n",
    "for index in students_strats['Index']:\n",
    "  text = \"\"\n",
    "  \n",
    "  set_text = \"\"\n",
    "  st_text = \"\"\n",
    "  p_text = \"\"\n",
    "  m_text = \"\"\n",
    "  \n",
    "  amount_set = 0\n",
    "  for perception in students_strats['Special Education Teacher Perceptions'][index]:\n",
    "    text += perception + \" \"\n",
    "    set_text += perception + \" \"\n",
    "    amount_set += 1\n",
    "\n",
    "  amount_st = 0\n",
    "  for perception in students_strats['Speech Therapist Perceptions'][index]:\n",
    "    text += perception + \" \"\n",
    "    st_text += perception + \" \"\n",
    "    amount_st += 1\n",
    "\n",
    "  amount_p = 0\n",
    "  for perception in students_strats['Psychological Perceptions'][index]:\n",
    "    text += perception + \" \"\n",
    "    p_text += perception + \" \"\n",
    "    amount_p += 1\n",
    "\n",
    "  amount_m = 0\n",
    "  for perception in students_strats['Medical Perceptions'][index]:\n",
    "    text += perception + \" \"\n",
    "    m_text += perception + \" \"\n",
    "    amount_m += 1\n",
    "\n",
    "  joined_perceptions.append(text)\n",
    "\n",
    "  joined_set_perceptions.append(set_text)\n",
    "  joined_st_perceptions.append(st_text)\n",
    "  joined_p_perceptions.append(p_text)\n",
    "  joined_m_perceptions.append(m_text)\n",
    "\n",
    "  amount_set_perceptions.append(amount_set)\n",
    "  amount_st_perceptions.append(amount_st)\n",
    "  amount_p_perceptions.append(amount_p)\n",
    "  amount_m_perceptions.append(amount_m)\n",
    "\n",
    "  has_set.append(1 if amount_set > 0 else 0)\n",
    "  has_st.append(1 if amount_st > 0 else 0)\n",
    "  has_p.append(1 if amount_p > 0 else 0)\n",
    "  has_m.append(1 if amount_m > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KxW0v4bN3AE"
   },
   "outputs": [],
   "source": [
    "categories_number_words = {\n",
    "        1: \"Apoyo Pedagógico en asignaturas\",\n",
    "        3: \"Apoyo pedagógico personal\",\n",
    "        4: \"Tutoría entre pares\",\n",
    "        7: \"Hacer a la familia partícipe del proceso\",\n",
    "        8: \"Apoyo psicóloga(o)\",\n",
    "        9: \"Apoyo fonoaudióloga(o)\",\n",
    "        10: \"Apoyo Educador(a) Diferencial\",\n",
    "        11: \"Apoyo Kinesióloga(o)\",\n",
    "        12: \"Apoyo Médico General\",\n",
    "        13: \"Apoyo Terapeuta Ocupacional\",\n",
    "        14: \"Control Neurólogo\",\n",
    "        15: \"Apoyo Interdisciplinario\",\n",
    "        16: \"Adecuación curricular de acceso\",\n",
    "        17: \"Adecuación curricular de objetivos\"\n",
    "    }\n",
    "categories_words_number = {v: k for k, v in categories_number_words.items()}\n",
    "\n",
    "diagnoses_codes = {\n",
    "    \"Trastorno específico del lenguaje\": 0,\n",
    "    \"Trastorno por déficit atencional\": 1,\n",
    "    \"Dificultad específica de aprendizaje\": 2,\n",
    "    \"Discapacidad intelectual\": 3,\n",
    "    \"Discapacidad visual\": 4,\n",
    "    \"Trastorno del espectro autista\": 5,\n",
    "    \"Discapacidad auditiva - Hipoacusia\": 6,\n",
    "    \"Funcionamiento intelectual limítrofe\": 7,\n",
    "    \"Síndrome de Down\": 8,\n",
    "    \"Trastorno motor\": 9,\n",
    "    \"Multidéficit\": 10,\n",
    "    \"Retraso global del desarrollo\": 11\n",
    "}\n",
    "\n",
    "strat_present = {\n",
    "    strat: [] for strat in list(categories_words_number.keys())\n",
    "}\n",
    "diag_codes = []\n",
    "for index in students_strats['Index']:\n",
    "  diag = students_strats['Diagnoses'][index]\n",
    "  diag_codes.append(diagnoses_codes[diag])\n",
    "  for strat_number in categories_number_words:\n",
    "    if strat_number in students_strats['Encoded Strategies'][index]:\n",
    "      strat_present[categories_number_words[strat_number]].append(1)\n",
    "    else:\n",
    "      strat_present[categories_number_words[strat_number]].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gytoAKKDLXM8"
   },
   "outputs": [],
   "source": [
    "new_dataset_to_export = {\n",
    "    'Encoded Diagnosis': diag_codes,\n",
    "    'Diagnosis': students_strats['Diagnoses'],\n",
    "    'All perceptions': joined_perceptions,\n",
    "    'Special Education Teacher Perceptions': joined_set_perceptions,\n",
    "    'Speech Therapist Perceptions': joined_st_perceptions,\n",
    "    'Psychologist Perceptions': joined_p_perceptions,\n",
    "    'Medical Perceptions': joined_m_perceptions,\n",
    "    'Amount of SET perceptions': amount_set_perceptions,\n",
    "    'Amount of ST perceptions': amount_st_perceptions,\n",
    "    'Amount of P perceptions': amount_p_perceptions,\n",
    "    'Amount of M perceptions': amount_m_perceptions,\n",
    "    'Has SET perceptions': has_set,\n",
    "    'Has ST perceptions': has_st,\n",
    "    'Has P perceptions': has_p,\n",
    "    'Has M perceptions': has_m,\n",
    "}\n",
    "x_keys = list(new_dataset_to_export.keys())\n",
    "new_dataset_to_export.update(strat_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uN-rTL91SpDf",
    "outputId": "8231af4f-984d-44a5-dc2c-0e1db489a499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Diagnosis 3035\n",
      "Diagnosis 3035\n",
      "All perceptions 3035\n",
      "Special Education Teacher Perceptions 3035\n",
      "Speech Therapist Perceptions 3035\n",
      "Psychologist Perceptions 3035\n",
      "Medical Perceptions 3035\n",
      "Amount of SET perceptions 3035\n",
      "Amount of ST perceptions 3035\n",
      "Amount of P perceptions 3035\n",
      "Amount of M perceptions 3035\n",
      "Has SET perceptions 3035\n",
      "Has ST perceptions 3035\n",
      "Has P perceptions 3035\n",
      "Has M perceptions 3035\n",
      "Apoyo Pedagógico en asignaturas 3035\n",
      "Apoyo pedagógico personal 3035\n",
      "Tutoría entre pares 3035\n",
      "Hacer a la familia partícipe del proceso 3035\n",
      "Apoyo psicóloga(o) 3035\n",
      "Apoyo fonoaudióloga(o) 3035\n",
      "Apoyo Educador(a) Diferencial 3035\n",
      "Apoyo Kinesióloga(o) 3035\n",
      "Apoyo Médico General 3035\n",
      "Apoyo Terapeuta Ocupacional 3035\n",
      "Control Neurólogo 3035\n",
      "Apoyo Interdisciplinario 3035\n",
      "Adecuación curricular de acceso 3035\n",
      "Adecuación curricular de objetivos 3035\n"
     ]
    }
   ],
   "source": [
    "for key in new_dataset_to_export:\n",
    "  print(key, len(new_dataset_to_export[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9825Rxgamlso"
   },
   "source": [
    "## Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKl49oD67ApW"
   },
   "outputs": [],
   "source": [
    "y_keys = list(categories_words_number.keys())\n",
    "# df = pd.DataFrame(data=new_dataset_to_export)\n",
    "# X = df\n",
    "# Y = df[y_keys]\n",
    "X_train = train_dataset.drop(y_keys, axis=1)\n",
    "Y_train = train_dataset[y_keys]\n",
    "X_val = val_dataset.drop(y_keys, axis=1)\n",
    "Y_val = val_dataset[y_keys]\n",
    "strats_amounts = {\n",
    "              'Adecuación curricular de acceso': 2264,\n",
    "              'Hacer a la familia partícipe del proceso': 2048,\n",
    "              'Apoyo Interdisciplinario': 1441, \n",
    "              'Apoyo Educador(a) Diferencial': 1311,\n",
    "              'Apoyo pedagógico personal': 1240,\n",
    "              'Apoyo fonoaudióloga(o)': 378,\n",
    "              'Apoyo psicóloga(o)': 588,\n",
    "              'Apoyo Terapeuta Ocupacional': 153,\n",
    "              'Tutoría entre pares': 350,\n",
    "              'Control Neurólogo': 63,\n",
    "              'Apoyo Médico General': 64,\n",
    "              'Apoyo Kinesióloga(o)': 32,\n",
    "              'Adecuación curricular de objetivos': 281,\n",
    "              'Apoyo Pedagógico en asignaturas': 1314\n",
    "}\n",
    "# most_unbalanced_strategies = [strategy for strategy in y_keys if (strats_amounts[strategy] < len(X)*0.15 or strats_amounts[strategy] > len(X)*0.85)]\n",
    "# less_unbalanced_strategies = [strategy for strategy in y_keys if strategy not in most_unbalanced_strategies]\n",
    "most_unbalanced_strategies = [strategy for strategy in y_keys if (strats_amounts[strategy] < (len(X_train)+len(X_val))*0.15 or strats_amounts[strategy] > (len(X_train)+len(X_val))*0.85)]\n",
    "less_unbalanced_strategies = [strategy for strategy in y_keys if strategy not in most_unbalanced_strategies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aG9FEovFbobu",
    "outputId": "2b172fdc-2c03-4e01-bf2d-b992edb5ab81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.01G/1.01G [00:33<00:00, 30.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_model = SentenceTransformer('xlm-r-bert-base-nli-stsb-mean-tokens', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWJNtAmJsb8y"
   },
   "outputs": [],
   "source": [
    "sentence_model.max_seq_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqma6YpgQwzP"
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "               [],\n",
    "               [{'name': 'All perceptions', 'type': 'embed_string', 'n_features': 100, 'special_token': '', 'transformation': 0}],\n",
    "               [{'name': 'All perceptions', 'type': 'embed_string', 'n_features': 100, 'special_token': '', 'transformation': 0}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'All perceptions', 'type': 'BETO_string', 'transformation': 0}],\n",
    "               [{'name': 'All perceptions', 'type': 'BETO_string', 'transformation': 0}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'set'},\n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'm'}\n",
    "                ],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'set'},\n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'm'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}\n",
    "                ],\n",
    "               [{'name': 'All perceptions', 'type': 'sentence_embedding'}],\n",
    "               [{'name': 'All perceptions', 'type': 'sentence_embedding'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'sentence_embedding'}],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}\n",
    "                ]\n",
    "               ]\n",
    "experiments_names = [\n",
    "                     \"Most frequent\",\n",
    "                     \"All perceptions with word embedding\",\n",
    "                     \"All perceptions (word embedding) + diagnosis\",\n",
    "                     \"All perceptions with BETO (average)\",\n",
    "                     \"All perceptions (BETO) + diagnosis (average)\",\n",
    "                     \"Different perceptions with BETO (average)\",\n",
    "                     \"Different perceptions (BETO) + diagnosis (average)\",\n",
    "                     \"Sentence BERT embedding\",\n",
    "                     \"Sentence + diagnosis\",\n",
    "                     \"Different perceptions\",\n",
    "                     \"Different + diagnosis\"\n",
    "]\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sAzRyHDYPrf"
   },
   "outputs": [],
   "source": [
    "def custom_tokenizer(special_token=\"\", use_clean=True):\n",
    "  def tokenize(sentence):\n",
    "    clean_sentence = re.sub(r'[^\\w\\s[]]', '', str(sentence).lower().strip()) if use_clean else sentence\n",
    "    if special_token != \"\":\n",
    "      return list(map(lambda word: special_token+ \"_\" + word, clean_sentence.split()))\n",
    "    else:\n",
    "      return clean_sentence.split()\n",
    "  return tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvxmLARGoYP3"
   },
   "outputs": [],
   "source": [
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akzmBhPSqnuk"
   },
   "outputs": [],
   "source": [
    "def normalize_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    cap = []\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            cap.append(model[word])\n",
    "    cap_vec = np.sum(np.array(cap), axis=0)\n",
    "    cap_vec = cap_vec / np.sqrt(cap_vec.dot(cap_vec))\n",
    "        \n",
    "    return cap_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9kJn29uI7Je"
   },
   "outputs": [],
   "source": [
    "def average_feature_vectors(vectors):\n",
    "  feature_vector = np.zeros((len(vectors[0]),),dtype=\"float64\")\n",
    "  \n",
    "  for vector in vectors:\n",
    "    feature_vector = np.add(feature_vector, vector)\n",
    "\n",
    "  feature_vector = np.divide(feature_vector, len(vectors))\n",
    "      \n",
    "  return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UzfzCAOKbxJ"
   },
   "outputs": [],
   "source": [
    "def normalize_feature_vectors(vectors):\n",
    "  cap_vec = np.sum(np.array(vectors), axis=0)\n",
    "  cap_vec = cap_vec / np.sqrt(cap_vec.dot(cap_vec))\n",
    "        \n",
    "  return cap_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_nFWRNDnrKi"
   },
   "outputs": [],
   "source": [
    "def split_list(alist, wanted_parts=1):\n",
    "    length = len(alist)\n",
    "    return [ alist[i*length // wanted_parts: (i+1)*length // wanted_parts] \n",
    "             for i in range(wanted_parts) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FO-gW5ZDR0uu"
   },
   "outputs": [],
   "source": [
    "def transform_perception_to_feature_vector(perception, mode):\n",
    "  aproved = False\n",
    "  divide_exponent = 0\n",
    "  splitted_perception = perception.split()\n",
    "  while not aproved:\n",
    "    amount_aproved = 0\n",
    "    divided_array = split_list(splitted_perception, 2**divide_exponent)\n",
    "    separator = \" \"\n",
    "    divided_perceptions = [separator.join(words) for words in divided_array]\n",
    "    for mini_perception in divided_perceptions:\n",
    "      if len(tokenizer(mini_perception)['input_ids']) < 500:\n",
    "        amount_aproved += 1\n",
    "      else:\n",
    "        pass \n",
    "    if amount_aproved == len(divided_perceptions):\n",
    "      aproved = True\n",
    "    else:\n",
    "      divide_exponent += 1\n",
    "  partial_modified_vector = []\n",
    "  for mini_perception in divided_perceptions:\n",
    "    mini_features = BETO_features(mini_perception)[0]\n",
    "    if mode == 0:\n",
    "      partial_modified_vector.append(average_feature_vectors(mini_features))\n",
    "    if mode == 1:\n",
    "      partial_modified_vector.append(normalize_feature_vectors(mini_features))\n",
    "  if mode == 0:\n",
    "    return average_feature_vectors(partial_modified_vector)\n",
    "  if mode == 1:\n",
    "    return normalize_feature_vectors(partial_modified_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pICBKZTXGvY1"
   },
   "outputs": [],
   "source": [
    "def make_top_tables(features, coeffs, top_n=10):\n",
    "  ordered_coeffs, ordered_features = zip(*sorted(zip(coeffs, features), reverse=True))\n",
    "  for i in range(top_n if len(features) > top_n else len(features)):\n",
    "    print(i+1, ordered_features[i], ordered_coeffs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BN94NJo3ag0w"
   },
   "outputs": [],
   "source": [
    "def make_bottom_tables(features, coeffs, top_n=10):\n",
    "  ordered_coeffs, ordered_features = zip(*sorted(zip(coeffs, features), reverse=True))\n",
    "  for i in range(top_n if len(features) > top_n else len(features)):\n",
    "    print(i+1, ordered_features[(i+1)*-1], ordered_coeffs[(i+1)*-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skLRZ0_-RJxD"
   },
   "outputs": [],
   "source": [
    "def execute_experiments(X, df, selected_strategies, experiments):\n",
    "  all_results = []\n",
    "  for strategy in selected_strategies:\n",
    "    i = 0\n",
    "    print('experimentando para estrategia: '+strategy)\n",
    "    strat_acc = []\n",
    "    strat_kappa = []\n",
    "    strat_f1 = []\n",
    "    strat_auc = []\n",
    "    strat_coefs = []\n",
    "    strat_features = []\n",
    "    for experiment in experiments:\n",
    "      print(\"\\t\"+str(i+1)+'° experimento')\n",
    "      i += 1\n",
    "      y=df[strategy]\n",
    "      X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                          y,\n",
    "                                                          test_size=0.2,\n",
    "                                                          random_state=1)\n",
    "      X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                        y_train,\n",
    "                                                        stratify=y_train,\n",
    "                                                        test_size=0.25,\n",
    "                                                        random_state=1)\n",
    "      if len(experiment) > 0:\n",
    "        classifier = LogisticRegression(penalty='l2', dual=True, solver='liblinear', max_iter=10000)\n",
    "        X_train_transformed = pd.DataFrame()\n",
    "        X_val_transformed = pd.DataFrame()\n",
    "        for input in experiment:\n",
    "          # Encoding diagnosis as categorical attribute\n",
    "          if input['type'] == 'categorical_diagnostic':\n",
    "            enc = OneHotEncoder(handle_unknown='ignore')\n",
    "            enc.fit(np.asarray(X_train[input['name']].append(X_val[input['name']])).reshape(-1, 1))\n",
    "\n",
    "            train_arrays = enc.transform(np.asarray(X_train[input['name']]).reshape(-1,1)).toarray()\n",
    "            temp_train_df = pd.DataFrame(train_arrays, columns=list(diagnoses_codes.keys()))\n",
    "\n",
    "            val_arrays = enc.transform(np.asarray(X_val[input['name']]).reshape(-1,1)).toarray()\n",
    "            temp_val_df = pd.DataFrame(val_arrays, columns=list(diagnoses_codes.keys()))\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          # Copying numeric and binary attributes\n",
    "          if input['type'] == 'numeric' or input['type'] == 'binary':\n",
    "            X_train_transformed[input['name']] = X_train[input['name']].to_numpy()\n",
    "            X_val_transformed[input['name']] = X_val[input['name']].to_numpy()\n",
    "\n",
    "          # Encoding strings\n",
    "          if input['type'] == 'string':\n",
    "            vectorizer = CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=stopwords, ngram_range=(1,3), max_df=0.8, min_df=0.05)\n",
    "            vectorizer.fit(X_train[input['name']])\n",
    "            print(vectorizer.get_feature_names())\n",
    "            train_arrays = vectorizer.transform(X_train[input['name']]).toarray()\n",
    "            temp_train_df = pd.DataFrame(train_arrays, columns=vectorizer.get_feature_names())\n",
    "            \n",
    "            val_arrays = vectorizer.transform(X_val[input['name']]).toarray()\n",
    "            temp_val_df = pd.DataFrame(val_arrays, columns=vectorizer.get_feature_names())\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          # Encoding strings with special tokens\n",
    "          if input['type'] == 'special_string':\n",
    "            tokenzr = custom_tokenizer(input['special_token'])\n",
    "            vectorizer = CountVectorizer(strip_accents='unicode',\n",
    "                                        tokenizer=tokenzr,\n",
    "                                        lowercase=True,\n",
    "                                        stop_words=list(map(lambda word: input['special_token']+ \"_\" + word, stopwords)),\n",
    "                                        ngram_range=(1,3),\n",
    "                                        max_df=0.8,\n",
    "                                        min_df=0.05)\n",
    "            vectorizer.fit(X_train[input['name']])\n",
    "            train_arrays = vectorizer.transform(X_train[input['name']]).toarray()\n",
    "            temp_train_df = pd.DataFrame(train_arrays, columns=vectorizer.get_feature_names())\n",
    "            \n",
    "            val_arrays = vectorizer.transform(X_val[input['name']]).toarray()\n",
    "            temp_val_df = pd.DataFrame(val_arrays, columns=vectorizer.get_feature_names())\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          if input['type'] == \"binary_labels\":\n",
    "            for other_label in list(df.columns):\n",
    "              if other_label != strategy:\n",
    "                X_train_transformed[other_label] = X_train[other_label].to_numpy()\n",
    "                X_val_transformed[other_label] = X_val[other_label].to_numpy()\n",
    "\n",
    "          if input['type'] == \"binary_single_label\":\n",
    "              if input['name'] != strategy:\n",
    "                X_train_transformed[input['name']] = X_train[input['name']].to_numpy()\n",
    "                X_val_transformed[input['name']] = X_val[input['name']].to_numpy()\n",
    "\n",
    "          if input['type'] == \"embed_string\":\n",
    "            c_tokenizer = custom_tokenizer(input['special_token'])\n",
    "            embedding_model = Word2Vec(\n",
    "                list(map(lambda doc: c_tokenizer(doc), X_train[input['name']])),\n",
    "                min_count=1, \n",
    "                window=3, \n",
    "                sg=1, \n",
    "                size=input['n_features'])\n",
    "            vocab = embedding_model.wv.vocab\n",
    "            tokenized_train_perceptions = list(map(lambda doc: c_tokenizer(doc), X_train[input['name']]))\n",
    "            tokenized_val_perceptions = list(map(lambda doc: c_tokenizer(doc), X_val[input['name']]))\n",
    "            if input['transformation'] == 0:\n",
    "              transformed_train_perceptions = list(map(\n",
    "                  lambda tokenized_perception: normalize_word_vectors(tokenized_perception,\n",
    "                                                                    embedding_model, \n",
    "                                                                    vocab, \n",
    "                                                                    input['n_features']), tokenized_train_perceptions))\n",
    "              transformed_val_perceptions = list(map(\n",
    "                  lambda tokenized_perception: normalize_word_vectors(tokenized_perception,\n",
    "                                                                    embedding_model, \n",
    "                                                                    vocab, \n",
    "                                                                    input['n_features']), tokenized_val_perceptions))\n",
    "            if input['transformation'] == 1:\n",
    "              transformed_train_perceptions = list(map(\n",
    "                  lambda tokenized_perception: average_word_vectors(tokenized_perception,\n",
    "                                                                    embedding_model, \n",
    "                                                                    vocab, \n",
    "                                                                    input['n_features']), tokenized_train_perceptions))\n",
    "              transformed_val_perceptions = list(map(\n",
    "                  lambda tokenized_perception: average_word_vectors(tokenized_perception,\n",
    "                                                                    embedding_model, \n",
    "                                                                    vocab, \n",
    "                                                                    input['n_features']), tokenized_val_perceptions))\n",
    "            \n",
    "\n",
    "            temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(input['n_features'])])\n",
    "            temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(input['n_features'])])\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          if input['type'] == \"BETO_string\":\n",
    "\n",
    "            transformed_train_perceptions = list(map(\n",
    "                lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_train[input['name']]))\n",
    "            transformed_val_perceptions = list(map(\n",
    "                lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_val[input['name']]))\n",
    "\n",
    "            temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature_'+input['code'] for i in range(len(transformed_train_perceptions[0]))])\n",
    "            temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature_'+input['code'] for i in range(len(transformed_val_perceptions[0]))])\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          if input['type'] == \"sentence_embedding\":\n",
    "\n",
    "            transformed_train_perceptions = list(map(\n",
    "                lambda perception: sentence_model.encode(perception), X_train[input['name']]))\n",
    "            transformed_val_perceptions = list(map(\n",
    "                lambda perception: sentence_model.encode(perception), X_val[input['name']]))\n",
    "\n",
    "            temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_train_perceptions[0]))])\n",
    "            temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_val_perceptions[0]))])\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "              \n",
    "\n",
    "        classifier.fit(X_train_transformed, y_train)\n",
    "        y_pred = classifier.predict(X_val_transformed)\n",
    "        strat_acc.append(round(accuracy_score(y_val, y_pred), 2))\n",
    "        strat_kappa.append(round(cohen_kappa_score(y_val, y_pred), 2))\n",
    "        strat_f1.append(round((f1_score(y_val, y_pred, pos_label=1) + f1_score(y_val, y_pred, pos_label=0))/2, 2))\n",
    "        strat_auc.append(round(roc_auc_score(y_val, y_pred), 2))\n",
    "        strat_coefs.append(classifier.coef_)\n",
    "        strat_features.append(list(X_train_transformed.columns))\n",
    "        del X_train_transformed, X_val_transformed\n",
    "      else:\n",
    "        classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "        classifier.fit(X_train['Diagnosis'], y_train)\n",
    "        y_pred = classifier.predict(X_val['Diagnosis'])\n",
    "        strat_acc.append(round(accuracy_score(y_val, y_pred), 2))\n",
    "        strat_kappa.append(round(cohen_kappa_score(y_val, y_pred), 2))\n",
    "        strat_f1.append(round((f1_score(y_val, y_pred, pos_label=1) + f1_score(y_val, y_pred, pos_label=0))/2, 2))\n",
    "        strat_auc.append(round(roc_auc_score(y_val, y_pred), 2))\n",
    "\n",
    "    all_results.append({'name': strategy, 'accs': strat_acc, 'kappas': strat_kappa, 'f1s': strat_f1, 'aucs': strat_auc, 'coefs': strat_coefs, 'features': strat_features})\n",
    "  return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJvhoKNpgp5H"
   },
   "outputs": [],
   "source": [
    "def execute_experiments(X_train, Y_train, X_val, Y_val, selected_strategies, experiments):\n",
    "  all_results = []\n",
    "  for strategy in selected_strategies:\n",
    "    i = 0\n",
    "    print('experimentando para estrategia: '+strategy)\n",
    "    strat_acc = []\n",
    "    strat_kappa = []\n",
    "    strat_f1 = []\n",
    "    strat_auc = []\n",
    "    strat_coefs = []\n",
    "    strat_features = []\n",
    "    for experiment in experiments:\n",
    "      print(\"\\t\"+str(i+1)+'° experimento')\n",
    "      i += 1\n",
    "      # y = df[strategy]\n",
    "      y_train = Y_train[strategy]\n",
    "      y_val = Y_val[strategy]\n",
    "      # X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "      #                                                     y,\n",
    "      #                                                     test_size=0.2,\n",
    "      #                                                     random_state=1)\n",
    "      # X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "      #                                                   y_train,\n",
    "      #                                                   stratify=y_train,\n",
    "      #                                                   test_size=0.25,\n",
    "      #                                                   random_state=1)\n",
    "      if len(experiment) > 0:\n",
    "        classifier = LogisticRegression(penalty='l2', dual=True, solver='liblinear', max_iter=10000)\n",
    "        X_train_transformed = pd.DataFrame()\n",
    "        X_val_transformed = pd.DataFrame()\n",
    "        for input in experiment:\n",
    "          # Encoding diagnosis as categorical attribute\n",
    "          if input['type'] == 'categorical_diagnostic':\n",
    "            enc = OneHotEncoder(handle_unknown='ignore')\n",
    "            enc.fit(np.asarray(X_train[input['name']].append(X_val[input['name']])).reshape(-1, 1))\n",
    "\n",
    "            train_arrays = enc.transform(np.asarray(X_train[input['name']]).reshape(-1,1)).toarray()\n",
    "            temp_train_df = pd.DataFrame(train_arrays, columns=list(diagnoses_codes.keys()))\n",
    "\n",
    "            val_arrays = enc.transform(np.asarray(X_val[input['name']]).reshape(-1,1)).toarray()\n",
    "            temp_val_df = pd.DataFrame(val_arrays, columns=list(diagnoses_codes.keys()))\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          # Copying numeric and binary attributes\n",
    "          if input['type'] == 'numeric' or input['type'] == 'binary':\n",
    "            X_train_transformed[input['name']] = X_train[input['name']].to_numpy()\n",
    "            X_val_transformed[input['name']] = X_val[input['name']].to_numpy()\n",
    "\n",
    "          # Encoding strings\n",
    "          if input['type'] == 'string':\n",
    "            vectorizer = CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=stopwords, ngram_range=(1,3), max_df=0.8, min_df=0.05)\n",
    "            vectorizer.fit(X_train[input['name']])\n",
    "            print(vectorizer.get_feature_names())\n",
    "            train_arrays = vectorizer.transform(X_train[input['name']]).toarray()\n",
    "            temp_train_df = pd.DataFrame(train_arrays, columns=vectorizer.get_feature_names())\n",
    "            \n",
    "            val_arrays = vectorizer.transform(X_val[input['name']]).toarray()\n",
    "            temp_val_df = pd.DataFrame(val_arrays, columns=vectorizer.get_feature_names())\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          # Encoding strings with special tokens\n",
    "          if input['type'] == 'special_string':\n",
    "            tokenzr = custom_tokenizer(input['special_token'])\n",
    "            vectorizer = CountVectorizer(strip_accents='unicode',\n",
    "                                        tokenizer=tokenzr,\n",
    "                                        lowercase=True,\n",
    "                                        stop_words=list(map(lambda word: input['special_token']+ \"_\" + word, stopwords)),\n",
    "                                        ngram_range=(1,3),\n",
    "                                        max_df=0.8,\n",
    "                                        min_df=0.05)\n",
    "            vectorizer.fit(X_train[input['name']])\n",
    "            train_arrays = vectorizer.transform(X_train[input['name']]).toarray()\n",
    "            temp_train_df = pd.DataFrame(train_arrays, columns=vectorizer.get_feature_names())\n",
    "            \n",
    "            val_arrays = vectorizer.transform(X_val[input['name']]).toarray()\n",
    "            temp_val_df = pd.DataFrame(val_arrays, columns=vectorizer.get_feature_names())\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          if input['type'] == \"binary_labels\":\n",
    "            for other_label in list(Y_train.columns):\n",
    "              if other_label != strategy:\n",
    "                X_train_transformed[other_label] = Y_train[other_label].to_numpy()\n",
    "                X_val_transformed[other_label] = Y_val[other_label].to_numpy()\n",
    "\n",
    "          if input['type'] == \"binary_single_label\":\n",
    "              if input['name'] != strategy:\n",
    "                X_train_transformed[input['name']] = Y_train[input['name']].to_numpy()\n",
    "                X_val_transformed[input['name']] = Y_val[input['name']].to_numpy()\n",
    "\n",
    "          if input['type'] == \"embed_string\":\n",
    "            c_tokenizer = custom_tokenizer(input['special_token'])\n",
    "            embedding_model = Word2Vec(\n",
    "                list(map(lambda doc: c_tokenizer(doc), X_train[input['name']])),\n",
    "                min_count=1, \n",
    "                window=3, \n",
    "                sg=1, \n",
    "                size=input['n_features'])\n",
    "            vocab = embedding_model.wv.vocab\n",
    "            tokenized_train_perceptions = list(map(lambda doc: c_tokenizer(doc), X_train[input['name']]))\n",
    "            tokenized_val_perceptions = list(map(lambda doc: c_tokenizer(doc), X_val[input['name']]))\n",
    "            if input['transformation'] == 0:\n",
    "              transformed_train_perceptions = list(map(\n",
    "                  lambda tokenized_perception: normalize_word_vectors(tokenized_perception,\n",
    "                                                                    embedding_model, \n",
    "                                                                    vocab, \n",
    "                                                                    input['n_features']), tokenized_train_perceptions))\n",
    "              transformed_val_perceptions = list(map(\n",
    "                  lambda tokenized_perception: normalize_word_vectors(tokenized_perception,\n",
    "                                                                    embedding_model, \n",
    "                                                                    vocab, \n",
    "                                                                    input['n_features']), tokenized_val_perceptions))\n",
    "            if input['transformation'] == 1:\n",
    "              transformed_train_perceptions = list(map(\n",
    "                  lambda tokenized_perception: average_word_vectors(tokenized_perception,\n",
    "                                                                    embedding_model, \n",
    "                                                                    vocab, \n",
    "                                                                    input['n_features']), tokenized_train_perceptions))\n",
    "              transformed_val_perceptions = list(map(\n",
    "                  lambda tokenized_perception: average_word_vectors(tokenized_perception,\n",
    "                                                                    embedding_model, \n",
    "                                                                    vocab, \n",
    "                                                                    input['n_features']), tokenized_val_perceptions))\n",
    "            \n",
    "\n",
    "            temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(input['n_features'])])\n",
    "            temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(input['n_features'])])\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          if input['type'] == \"BETO_string\":\n",
    "\n",
    "            transformed_train_perceptions = list(map(\n",
    "                lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_train[input['name']]))\n",
    "            transformed_val_perceptions = list(map(\n",
    "                lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_val[input['name']]))\n",
    "\n",
    "            temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_train_perceptions[0]))])\n",
    "            temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_val_perceptions[0]))])\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          if input['type'] == \"sentence_embedding\":\n",
    "\n",
    "            transformed_train_perceptions = list(map(\n",
    "                lambda perception: sentence_model.encode(perception), X_train[input['name']]))\n",
    "            transformed_val_perceptions = list(map(\n",
    "                lambda perception: sentence_model.encode(perception), X_val[input['name']]))\n",
    "\n",
    "            temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_train_perceptions[0]))])\n",
    "            temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_val_perceptions[0]))])\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "              \n",
    "\n",
    "        classifier.fit(X_train_transformed, y_train)\n",
    "        y_pred = classifier.predict(X_val_transformed)\n",
    "        strat_acc.append(round(accuracy_score(y_val, y_pred), 2))\n",
    "        strat_kappa.append(round(cohen_kappa_score(y_val, y_pred), 2))\n",
    "        strat_f1.append(round((f1_score(y_val, y_pred, pos_label=1) + f1_score(y_val, y_pred, pos_label=0))/2, 2))\n",
    "        strat_auc.append(round(roc_auc_score(y_val, y_pred), 2))\n",
    "        strat_coefs.append(classifier.coef_)\n",
    "        strat_features.append(list(X_train_transformed.columns))\n",
    "        del X_train_transformed, X_val_transformed\n",
    "      else:\n",
    "        classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "        classifier.fit(X_train['Diagnosis'], y_train)\n",
    "        y_pred = classifier.predict(X_val['Diagnosis'])\n",
    "        strat_acc.append(round(accuracy_score(y_val, y_pred), 2))\n",
    "        strat_kappa.append(round(cohen_kappa_score(y_val, y_pred), 2))\n",
    "        strat_f1.append(round((f1_score(y_val, y_pred, pos_label=1) + f1_score(y_val, y_pred, pos_label=0))/2, 2))\n",
    "        strat_auc.append(round(roc_auc_score(y_val, y_pred), 2))\n",
    "\n",
    "    all_results.append({'name': strategy, 'accs': strat_acc, 'kappas': strat_kappa, 'f1s': strat_f1, 'aucs': strat_auc, 'coefs': strat_coefs, 'features': strat_features})\n",
    "  return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7COdCBk2enL"
   },
   "outputs": [],
   "source": [
    "def make_table_for_python(strats_results, difference_val=0.04):\n",
    "  header_columns = ['Experiment names']\n",
    "  experiments = [[name] for name in experiments_names] \n",
    "  for strat_result in strats_results:\n",
    "    marks = [\"(*)\", \"(**)\"] \n",
    "    sorted_accs = sorted(list(set(strat_result['accs'])), reverse=True)\n",
    "    sorted_kappas = sorted(list(set(strat_result['kappas'])), reverse=True)\n",
    "    sorted_f1s = sorted(list(set(strat_result['f1s'])), reverse=True)\n",
    "    sorted_aucs = sorted(list(set(strat_result['aucs'])), reverse=True)\n",
    "    for i in range(len(strat_result['accs'])):\n",
    "      exp_results = []\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['accs'][i] == sorted_accs[0]:\n",
    "        if len(sorted_accs) > 1 and strat_result['accs'][i] >= sorted_accs[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      exp_results.append((str(strat_result['accs'][i]) if strat_result['accs'][i]>0 else \"0.00\")+chosen_mark)\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['kappas'][i] == sorted_kappas[0]:\n",
    "        if len(sorted_kappas) > 1 and strat_result['kappas'][i] >= sorted_kappas[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      exp_results.append((str(strat_result['kappas'][i]) if strat_result['kappas'][i]>0 else \"0.00\")+chosen_mark)\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['f1s'][i] == sorted_f1s[0]:\n",
    "        if len(sorted_f1s) > 1 and strat_result['f1s'][i] >= sorted_f1s[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      exp_results.append((str(strat_result['f1s'][i]) if strat_result['f1s'][i]>0 else \"0.00\")+chosen_mark)\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['aucs'][i] == sorted_aucs[0]:\n",
    "        if len(sorted_aucs) > 1 and strat_result['aucs'][i] >= sorted_aucs[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      exp_results.append((str(strat_result['aucs'][i]) if strat_result['aucs'][i]>0 else \"0.00\")+chosen_mark)\n",
    "      experiments[i].append(tabulate([exp_results], tablefmt=\"plain\"))\n",
    "    header_columns.append(\n",
    "        strat_result['name'])\n",
    "  return tabulate(experiments, headers=header_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSmAFPgRm3El"
   },
   "outputs": [],
   "source": [
    "def make_table_for_latex(strats_results, difference_val=0.04):\n",
    "  header_columns = ['Experiment names']\n",
    "  experiments = [[name] for name in experiments_names] \n",
    "  experiments_means = [[0, 0, 0, 0] for name in experiments_names]\n",
    "  for strat_result in strats_results:\n",
    "    marks = [\"(*)\", \"(**)\"] \n",
    "    sorted_accs = sorted(list(set(strat_result['accs'])), reverse=True)\n",
    "    sorted_kappas = sorted(list(set(strat_result['kappas'])), reverse=True)\n",
    "    sorted_f1s = sorted(list(set(strat_result['f1s'])), reverse=True)\n",
    "    sorted_aucs = sorted(list(set(strat_result['aucs'])), reverse=True)\n",
    "    for i in range(len(strat_result['accs'])):\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['accs'][i] == sorted_accs[0]:\n",
    "        if len(sorted_accs) > 1 and strat_result['accs'][i] >= sorted_accs[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      experiments[i].append(str(strat_result['accs'][i])+chosen_mark)\n",
    "      experiments_means[i][0] += strat_result['accs'][i]\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['kappas'][i] == sorted_kappas[0]:\n",
    "        if len(sorted_kappas) > 1 and strat_result['kappas'][i] >= sorted_kappas[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      experiments[i].append(str(strat_result['kappas'][i])+chosen_mark)\n",
    "      experiments_means[i][1] += strat_result['kappas'][i]\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['f1s'][i] == sorted_f1s[0]:\n",
    "        if len(sorted_f1s) > 1 and strat_result['f1s'][i] >= sorted_f1s[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      experiments[i].append(str(strat_result['f1s'][i])+chosen_mark)\n",
    "      experiments_means[i][2] += strat_result['f1s'][i]\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['aucs'][i] == sorted_aucs[0]:\n",
    "        if len(sorted_aucs) > 1 and strat_result['aucs'][i] >= sorted_aucs[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      experiments[i].append(str(strat_result['aucs'][i])+chosen_mark)\n",
    "      experiments_means[i][3] += strat_result['aucs'][i]\n",
    "    header_columns.extend(\n",
    "        [strat_result['name']+(\" (\"+str(strats_amounts[strat_result['name']])+\" cases)\"), 'Kappa', 'F1', 'AUC'])\n",
    "  for i in range(len(experiments_means)):\n",
    "    experiments[i].append(round(experiments_means[i][0]/len(strats_results), 2))\n",
    "    experiments[i].append(round(experiments_means[i][1]/len(strats_results), 2))\n",
    "    experiments[i].append(round(experiments_means[i][2]/len(strats_results), 2))\n",
    "    experiments[i].append(round(experiments_means[i][3]/len(strats_results), 2))\n",
    "  header_columns.extend(\n",
    "        [\"Means\", 'Kappa', 'F1', 'AUC'])\n",
    "  return tabulate(experiments, headers=header_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0La0vjCZNZc",
    "outputId": "95c00362-9213-4c71-a0a7-44560794fd46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experimentando para estrategia: Tutoría entre pares\n",
      "\t1° experimento\n",
      "\t2° experimento\n",
      "\t3° experimento\n",
      "\t4° experimento\n",
      "\t5° experimento\n",
      "\t6° experimento\n",
      "\t7° experimento\n",
      "\t8° experimento\n",
      "\t9° experimento\n",
      "experimentando para estrategia: Apoyo Kinesióloga(o)\n",
      "\t1° experimento\n",
      "\t2° experimento\n",
      "\t3° experimento\n",
      "\t4° experimento\n",
      "\t5° experimento\n",
      "\t6° experimento\n",
      "\t7° experimento\n",
      "\t8° experimento\n",
      "\t9° experimento\n",
      "experimentando para estrategia: Apoyo Médico General\n",
      "\t1° experimento\n",
      "\t2° experimento\n",
      "\t3° experimento\n",
      "\t4° experimento\n",
      "\t5° experimento\n",
      "\t6° experimento\n",
      "\t7° experimento\n",
      "\t8° experimento\n",
      "\t9° experimento\n",
      "experimentando para estrategia: Apoyo Terapeuta Ocupacional\n",
      "\t1° experimento\n",
      "\t2° experimento\n",
      "\t3° experimento\n",
      "\t4° experimento\n",
      "\t5° experimento\n",
      "\t6° experimento\n",
      "\t7° experimento\n",
      "\t8° experimento\n",
      "\t9° experimento\n",
      "experimentando para estrategia: Control Neurólogo\n",
      "\t1° experimento\n",
      "\t2° experimento\n",
      "\t3° experimento\n",
      "\t4° experimento\n",
      "\t5° experimento\n",
      "\t6° experimento\n",
      "\t7° experimento\n",
      "\t8° experimento\n",
      "\t9° experimento\n",
      "experimentando para estrategia: Adecuación curricular de acceso\n",
      "\t1° experimento\n",
      "\t2° experimento\n",
      "\t3° experimento\n",
      "\t4° experimento\n",
      "\t5° experimento\n",
      "\t6° experimento\n",
      "\t7° experimento\n",
      "\t8° experimento\n",
      "\t9° experimento\n",
      "experimentando para estrategia: Adecuación curricular de objetivos\n",
      "\t1° experimento\n",
      "\t2° experimento\n",
      "\t3° experimento\n",
      "\t4° experimento\n",
      "\t5° experimento\n",
      "\t6° experimento\n",
      "\t7° experimento\n",
      "\t8° experimento\n",
      "\t9° experimento\n"
     ]
    }
   ],
   "source": [
    "most_unbalanced_results = execute_experiments(X_train, Y_train, X_val, Y_val, most_unbalanced_strategies, experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4EzuZsm7MHV",
    "outputId": "1bbff25a-c956-48d7-a822-bbc3f3eabb7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'accs', 'kappas', 'f1s', 'aucs', 'coefs', 'features'])"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_unbalanced_results[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wH9yeNQOeGI",
    "outputId": "9604eb0c-8446-4715-e1c9-6da9b4bf016b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Resultados para Tutoría entre pares -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 207_feature 1.2734819369302832\n",
      "2 171_feature 1.0992325060240213\n",
      "3 552_feature 1.0966840291744906\n",
      "4 567_feature 1.0216226189569333\n",
      "5 179_feature 1.0171326257853601\n",
      "6 290_feature 1.0145910750496319\n",
      "7 715_feature 0.9989740997810506\n",
      "8 229_feature 0.9642358203405063\n",
      "9 287_feature 0.9629624214040813\n",
      "10 579_feature 0.9409337081051768\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 207_feature 1.3005093172707887\n",
      "2 171_feature 1.0762499203317288\n",
      "3 Síndrome de Down 1.0667687157757135\n",
      "4 567_feature 1.0630399930312653\n",
      "5 552_feature 1.0627130196517862\n",
      "6 179_feature 1.0455452885791456\n",
      "7 287_feature 1.023437779803003\n",
      "8 290_feature 1.016429842354784\n",
      "9 715_feature 0.9687641394951287\n",
      "10 229_feature 0.9481277080867409\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 629_feature 1.0851043047078428\n",
      "2 346_feature 0.759911969128583\n",
      "3 84_feature 0.7445356933554502\n",
      "4 305_feature 0.728736679778789\n",
      "5 53_feature 0.7249936701560619\n",
      "6 614_feature 0.69019977674297\n",
      "7 229_feature 0.6881286162068223\n",
      "8 552_feature 0.6797868198566052\n",
      "9 259_feature 0.6641334074665696\n",
      "10 239_feature 0.6575120971568739\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 629_feature 1.0479559407608323\n",
      "2 346_feature 0.742174351142288\n",
      "3 305_feature 0.7381342242376202\n",
      "4 53_feature 0.7201656125586408\n",
      "5 84_feature 0.7102377056673811\n",
      "6 552_feature 0.6752985592339298\n",
      "7 614_feature 0.668563784573664\n",
      "8 259_feature 0.6644090251164994\n",
      "9 229_feature 0.6597046091080715\n",
      "10 239_feature 0.6426312021731807\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 76_feature 0.9528180489156454\n",
      "2 740_feature 0.9403860349189782\n",
      "3 120_feature 0.8463838294567286\n",
      "4 233_feature 0.8388100324950353\n",
      "5 495_feature 0.8108632998267452\n",
      "6 504_feature 0.8038573990874334\n",
      "7 117_feature 0.7558949138885114\n",
      "8 662_feature 0.7552799036013559\n",
      "9 377_feature 0.7379352936228871\n",
      "10 373_feature 0.7329894755145892\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 Síndrome de Down 0.9924246800679908\n",
      "2 76_feature 0.9137880025245236\n",
      "3 495_feature 0.846754555767593\n",
      "4 740_feature 0.8335843574426033\n",
      "5 504_feature 0.8248611467725487\n",
      "6 120_feature 0.8109156649086386\n",
      "7 233_feature 0.8086216781936582\n",
      "8 61_feature 0.7760925728351821\n",
      "9 468_feature 0.7318260474810161\n",
      "10 117_feature 0.7277146500054953\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 562_feature 0.8524200508285857\n",
      "2 111_feature 0.7825917458359771\n",
      "3 620_feature 0.7074752547926301\n",
      "4 525_feature 0.6932525157980955\n",
      "5 437_feature 0.6757740131594003\n",
      "6 261_feature 0.6617080396714975\n",
      "7 310_feature 0.6616724095350823\n",
      "8 509_feature 0.6544472526271377\n",
      "9 485_feature 0.6448080098062707\n",
      "10 5_feature 0.6272013703717796\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 562_feature 0.8281859212777645\n",
      "2 111_feature 0.7954869040513155\n",
      "3 620_feature 0.7149230065035199\n",
      "4 Síndrome de Down 0.7090219942511112\n",
      "5 525_feature 0.7079266743973021\n",
      "6 485_feature 0.6617225406818688\n",
      "7 509_feature 0.6582387668632875\n",
      "8 145_feature 0.6523259240707056\n",
      "9 437_feature 0.6427377640835203\n",
      "10 486_feature 0.6416038665540617\n",
      "\n",
      "--------- Resultados para Apoyo Kinesióloga(o) -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 216_feature 0.7430833921276657\n",
      "2 184_feature 0.6973263136803785\n",
      "3 628_feature 0.6683215934793159\n",
      "4 239_feature 0.653894541978608\n",
      "5 189_feature 0.5843399268574805\n",
      "6 729_feature 0.5460399009283226\n",
      "7 41_feature 0.5395123562553253\n",
      "8 223_feature 0.5293482501079345\n",
      "9 301_feature 0.5194820626629421\n",
      "10 427_feature 0.5143926937423474\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Trastorno motor 2.9917106482760976\n",
      "2 239_feature 0.6334843488849905\n",
      "3 628_feature 0.5797033623872375\n",
      "4 216_feature 0.5769393531475558\n",
      "5 184_feature 0.5276190202864975\n",
      "6 41_feature 0.4859775080407219\n",
      "7 189_feature 0.46681909096014657\n",
      "8 272_feature 0.4443265700741299\n",
      "9 Síndrome de Down 0.43769393089051783\n",
      "10 720_feature 0.43615142558377107\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 34_feature 0.3728148347481069\n",
      "2 239_feature 0.3613695903470703\n",
      "3 156_feature 0.2705024586881884\n",
      "4 101_feature 0.267836041767548\n",
      "5 340_feature 0.2663720989634248\n",
      "6 50_feature 0.24748018668489996\n",
      "7 239_feature 0.24672729780230448\n",
      "8 588_feature 0.24385540896081032\n",
      "9 640_feature 0.24333761348435273\n",
      "10 361_feature 0.2427087265227156\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Trastorno motor 1.627161035442175\n",
      "2 34_feature 0.31686709459130813\n",
      "3 239_feature 0.30601705172792054\n",
      "4 101_feature 0.24781969744882945\n",
      "5 239_feature 0.23667743314632364\n",
      "6 156_feature 0.23600815125834385\n",
      "7 50_feature 0.233244846736853\n",
      "8 96_feature 0.22676688506293216\n",
      "9 361_feature 0.22485046455337343\n",
      "10 640_feature 0.21398865773724626\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 309_feature 0.7015333838151822\n",
      "2 428_feature 0.5889662444875647\n",
      "3 673_feature 0.5716060947022659\n",
      "4 554_feature 0.5619184702567023\n",
      "5 496_feature 0.5232614285339093\n",
      "6 143_feature 0.49449965272476404\n",
      "7 13_feature 0.4228146603947773\n",
      "8 674_feature 0.4167033477613169\n",
      "9 731_feature 0.4149824594369408\n",
      "10 363_feature 0.4057544647575939\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 Trastorno motor 3.3917750340501502\n",
      "2 428_feature 0.47697459622727245\n",
      "3 309_feature 0.4664204699284356\n",
      "4 673_feature 0.4620874701782161\n",
      "5 143_feature 0.44438574146661614\n",
      "6 496_feature 0.43467481154379406\n",
      "7 554_feature 0.40974981408605626\n",
      "8 Multidéficit 0.4093880379345646\n",
      "9 13_feature 0.3982222581685899\n",
      "10 432_feature 0.38644981104613113\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 673_feature 0.3607280787796871\n",
      "2 557_feature 0.3468123677088012\n",
      "3 233_feature 0.30347690186179976\n",
      "4 516_feature 0.26139792209651125\n",
      "5 449_feature 0.25289796281280125\n",
      "6 313_feature 0.2503476846948502\n",
      "7 706_feature 0.24959758028164944\n",
      "8 564_feature 0.23655017346503462\n",
      "9 570_feature 0.23037252835622649\n",
      "10 767_feature 0.22959464929855247\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 Trastorno motor 1.6485870739639914\n",
      "2 673_feature 0.3299667828236876\n",
      "3 557_feature 0.3238041810014769\n",
      "4 233_feature 0.2500136155420702\n",
      "5 516_feature 0.2287421833232565\n",
      "6 449_feature 0.22011515740053383\n",
      "7 767_feature 0.21858539473178007\n",
      "8 313_feature 0.21476884062459542\n",
      "9 706_feature 0.21359420998155884\n",
      "10 570_feature 0.20806540695547507\n",
      "\n",
      "--------- Resultados para Apoyo Médico General -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 146_feature 0.7381784241927987\n",
      "2 43_feature 0.6261626267918905\n",
      "3 71_feature 0.6119532915747162\n",
      "4 532_feature 0.6076240698267964\n",
      "5 455_feature 0.5995901571307944\n",
      "6 626_feature 0.5895526971344686\n",
      "7 727_feature 0.5813541378059892\n",
      "8 432_feature 0.5784790705474233\n",
      "9 248_feature 0.5718782155210262\n",
      "10 622_feature 0.568492720987813\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 146_feature 0.7463099781567768\n",
      "2 727_feature 0.6533425086311093\n",
      "3 43_feature 0.6463780199431155\n",
      "4 71_feature 0.6232585804322074\n",
      "5 455_feature 0.622110067017806\n",
      "6 Trastorno del espectro autista 0.6091204979631619\n",
      "7 432_feature 0.601022594318428\n",
      "8 Trastorno por déficit atencional 0.5980261879265752\n",
      "9 626_feature 0.5912848163010489\n",
      "10 622_feature 0.5780098320895115\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 25_feature 0.489021860086251\n",
      "2 626_feature 0.4231164537055862\n",
      "3 662_feature 0.39244168251031775\n",
      "4 532_feature 0.38821628641957834\n",
      "5 365_feature 0.3820427187855548\n",
      "6 539_feature 0.37748317797473385\n",
      "7 701_feature 0.37184707693660424\n",
      "8 728_feature 0.3717588134132701\n",
      "9 454_feature 0.36833603672661225\n",
      "10 236_feature 0.36682029199638855\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Trastorno por déficit atencional 0.9567698074116894\n",
      "2 25_feature 0.4497943842358305\n",
      "3 Trastorno del espectro autista 0.42430418263590336\n",
      "4 728_feature 0.4071612112661832\n",
      "5 626_feature 0.4009837916230577\n",
      "6 365_feature 0.36951626077402105\n",
      "7 185_feature 0.35687225197045663\n",
      "8 539_feature 0.35652945711154727\n",
      "9 236_feature 0.3547763938526829\n",
      "10 715_feature 0.3535727218484341\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 222_feature 0.65811738196779\n",
      "2 35_feature 0.6527263525489914\n",
      "3 652_feature 0.6003617782734729\n",
      "4 278_feature 0.5731684869862368\n",
      "5 367_feature 0.5657241856318116\n",
      "6 745_feature 0.5332897692299315\n",
      "7 127_feature 0.5252253664408801\n",
      "8 655_feature 0.5072367411778808\n",
      "9 116_feature 0.49805144292633\n",
      "10 226_feature 0.48882766177293513\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 Trastorno del espectro autista 0.8531852604254172\n",
      "2 35_feature 0.6697382979313253\n",
      "3 222_feature 0.668394660496238\n",
      "4 745_feature 0.5720897843569267\n",
      "5 367_feature 0.5638901493094478\n",
      "6 278_feature 0.5566237103463719\n",
      "7 652_feature 0.5524254611457368\n",
      "8 127_feature 0.5461011328630918\n",
      "9 116_feature 0.5166658271646601\n",
      "10 513_feature 0.5008248740337321\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 108_feature 0.39723477000297885\n",
      "2 460_feature 0.3947772830834459\n",
      "3 663_feature 0.3789684219256984\n",
      "4 711_feature 0.3659465856481486\n",
      "5 11_feature 0.3632463270225146\n",
      "6 358_feature 0.3486100759667008\n",
      "7 712_feature 0.34854856678553103\n",
      "8 35_feature 0.34701615502597866\n",
      "9 496_feature 0.33616495677080493\n",
      "10 652_feature 0.33481532002830117\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 Trastorno por déficit atencional 0.7264875820869389\n",
      "2 Trastorno del espectro autista 0.48335386157771154\n",
      "3 108_feature 0.39411573002001205\n",
      "4 460_feature 0.3832355539953216\n",
      "5 711_feature 0.3737972748816901\n",
      "6 663_feature 0.3668561419732211\n",
      "7 11_feature 0.36542944538868\n",
      "8 712_feature 0.35082591131615054\n",
      "9 358_feature 0.3436343254428996\n",
      "10 35_feature 0.34359456674076566\n",
      "\n",
      "--------- Resultados para Apoyo Terapeuta Ocupacional -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 162_feature 0.8352960972864838\n",
      "2 597_feature 0.7616123882659036\n",
      "3 419_feature 0.7574896325343266\n",
      "4 354_feature 0.730522756768309\n",
      "5 434_feature 0.7264256781794842\n",
      "6 569_feature 0.7119153067596472\n",
      "7 687_feature 0.7010758239169446\n",
      "8 640_feature 0.6831519441810897\n",
      "9 452_feature 0.6549777920980351\n",
      "10 682_feature 0.6457483707366641\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Trastorno del espectro autista 1.4974973171853652\n",
      "2 Discapacidad intelectual 1.1508746675015928\n",
      "3 508_feature 0.7525029927446925\n",
      "4 640_feature 0.7346736037024684\n",
      "5 169_feature 0.7040584288375421\n",
      "6 354_feature 0.7039408260208018\n",
      "7 39_feature 0.6881481025519682\n",
      "8 168_feature 0.6809045290056367\n",
      "9 434_feature 0.6788721341680429\n",
      "10 569_feature 0.6785424107620687\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 327_feature 0.5866958076658232\n",
      "2 43_feature 0.5513666408822898\n",
      "3 594_feature 0.5219649640921254\n",
      "4 11_feature 0.5211250163892601\n",
      "5 376_feature 0.5047821746142603\n",
      "6 569_feature 0.504028273594933\n",
      "7 316_feature 0.49732869483266323\n",
      "8 767_feature 0.49459278862558753\n",
      "9 730_feature 0.49421234912101675\n",
      "10 37_feature 0.4904557307128854\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Discapacidad intelectual 1.1870607448583905\n",
      "2 Discapacidad auditiva - Hipoacusia 1.0923547291561813\n",
      "3 Trastorno del espectro autista 0.7371605108870086\n",
      "4 327_feature 0.5374573021484739\n",
      "5 11_feature 0.4823400245295385\n",
      "6 43_feature 0.4712240236639064\n",
      "7 594_feature 0.4632893933865284\n",
      "8 765_feature 0.46290149657784346\n",
      "9 376_feature 0.4609535003672196\n",
      "10 316_feature 0.4499980199304182\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 52_feature 0.9672480674359976\n",
      "2 103_feature 0.8013072708085761\n",
      "3 284_feature 0.7652335150431306\n",
      "4 539_feature 0.748998693446524\n",
      "5 58_feature 0.6631488160688187\n",
      "6 123_feature 0.6587342583717826\n",
      "7 283_feature 0.6540088423997125\n",
      "8 332_feature 0.6370840863219017\n",
      "9 547_feature 0.6319390631070884\n",
      "10 214_feature 0.6287329227172255\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 Trastorno del espectro autista 1.2774138879985892\n",
      "2 Discapacidad intelectual 1.1005839852837842\n",
      "3 52_feature 0.8605426978587878\n",
      "4 284_feature 0.7327841898701557\n",
      "5 Síndrome de Down 0.684423335760153\n",
      "6 539_feature 0.6585929287406957\n",
      "7 103_feature 0.6539907849800298\n",
      "8 123_feature 0.6432896851972897\n",
      "9 283_feature 0.6428728806477256\n",
      "10 332_feature 0.6386797957818268\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 439_feature 0.6270383112852066\n",
      "2 630_feature 0.5980847210103403\n",
      "3 566_feature 0.590079556114669\n",
      "4 283_feature 0.5762716118595417\n",
      "5 479_feature 0.5628987359157919\n",
      "6 633_feature 0.5606324940555548\n",
      "7 229_feature 0.48429922590092495\n",
      "8 461_feature 0.4816132807701319\n",
      "9 309_feature 0.4729381918411491\n",
      "10 404_feature 0.4703051261188697\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 Discapacidad intelectual 1.2839032145194624\n",
      "2 Discapacidad auditiva - Hipoacusia 1.049134426966088\n",
      "3 Trastorno del espectro autista 0.9973331528314462\n",
      "4 630_feature 0.6241017123860432\n",
      "5 479_feature 0.5755589090869758\n",
      "6 439_feature 0.5723576113358334\n",
      "7 283_feature 0.5626894609372856\n",
      "8 633_feature 0.5224909699158288\n",
      "9 566_feature 0.4890432494732665\n",
      "10 596_feature 0.4773559882258046\n",
      "\n",
      "--------- Resultados para Control Neurólogo -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 594_feature 0.8161588165122265\n",
      "2 711_feature 0.7980432324710028\n",
      "3 386_feature 0.7041736753939661\n",
      "4 391_feature 0.7003531368551065\n",
      "5 180_feature 0.692326538143182\n",
      "6 566_feature 0.6688779252008747\n",
      "7 399_feature 0.6299714026125642\n",
      "8 717_feature 0.5805726796298631\n",
      "9 103_feature 0.5471116394330721\n",
      "10 242_feature 0.5348995741220043\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Trastorno por déficit atencional 1.3313544840451983\n",
      "2 594_feature 0.8378961723935567\n",
      "3 386_feature 0.7379763254099795\n",
      "4 711_feature 0.727938622120398\n",
      "5 566_feature 0.7222002969464592\n",
      "6 180_feature 0.6815793988828792\n",
      "7 391_feature 0.6573644498066966\n",
      "8 Discapacidad intelectual 0.6139212680438889\n",
      "9 103_feature 0.6128738989617678\n",
      "10 399_feature 0.6078798102877463\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 368_feature 0.4604448410878055\n",
      "2 239_feature 0.42574353801452575\n",
      "3 602_feature 0.4233839177707691\n",
      "4 603_feature 0.4078343653430163\n",
      "5 194_feature 0.39629659846945026\n",
      "6 595_feature 0.3897816508577561\n",
      "7 490_feature 0.3465941740840065\n",
      "8 204_feature 0.3460394416856628\n",
      "9 395_feature 0.3448549647049764\n",
      "10 386_feature 0.3447729528394298\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Trastorno por déficit atencional 0.4830462269285205\n",
      "2 368_feature 0.4505900863237125\n",
      "3 602_feature 0.43155457207970227\n",
      "4 239_feature 0.41766034801969526\n",
      "5 603_feature 0.3937955563859905\n",
      "6 595_feature 0.3829636397936253\n",
      "7 194_feature 0.37547856822584086\n",
      "8 386_feature 0.3438250989907172\n",
      "9 395_feature 0.3405671402238406\n",
      "10 398_feature 0.33867968220657196\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 516_feature 0.6720496317100191\n",
      "2 624_feature 0.6652516628323185\n",
      "3 52_feature 0.6101942692257744\n",
      "4 525_feature 0.6018168137626603\n",
      "5 597_feature 0.6005421439959022\n",
      "6 465_feature 0.5939011222014913\n",
      "7 706_feature 0.5598868168984028\n",
      "8 296_feature 0.5250149338452232\n",
      "9 327_feature 0.5086481762961393\n",
      "10 616_feature 0.5047795119872746\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 Trastorno por déficit atencional 1.2662706864784625\n",
      "2 624_feature 0.6545744981029857\n",
      "3 516_feature 0.621938270658752\n",
      "4 465_feature 0.6037283329958621\n",
      "5 52_feature 0.5837264524701039\n",
      "6 597_feature 0.5500569589540523\n",
      "7 556_feature 0.5447871738818653\n",
      "8 525_feature 0.528587135796439\n",
      "9 706_feature 0.5279496334646369\n",
      "10 Discapacidad intelectual 0.5278677353928743\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 669_feature 0.3721736627019759\n",
      "2 154_feature 0.3705531299388792\n",
      "3 384_feature 0.36617507639744795\n",
      "4 586_feature 0.3632460066015018\n",
      "5 763_feature 0.3588689195962419\n",
      "6 52_feature 0.3534258236504774\n",
      "7 757_feature 0.3534251187011862\n",
      "8 655_feature 0.35103386573289286\n",
      "9 283_feature 0.3445404908239696\n",
      "10 42_feature 0.33984232891618327\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 Trastorno por déficit atencional 0.5094052434481428\n",
      "2 586_feature 0.3717655873331789\n",
      "3 669_feature 0.365218283187601\n",
      "4 384_feature 0.3617144670585173\n",
      "5 154_feature 0.3606227791869557\n",
      "6 763_feature 0.3529995222784849\n",
      "7 655_feature 0.3514839216501572\n",
      "8 757_feature 0.34938345592639475\n",
      "9 52_feature 0.3390590772632498\n",
      "10 580_feature 0.3354752976373037\n",
      "\n",
      "--------- Resultados para Adecuación curricular de acceso -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 161_feature 1.4702657103094112\n",
      "2 255_feature 1.4115836296804625\n",
      "3 423_feature 1.2190823340195038\n",
      "4 260_feature 1.176790773369849\n",
      "5 395_feature 1.0922482751480083\n",
      "6 548_feature 1.089646612968969\n",
      "7 26_feature 1.0764798572056982\n",
      "8 508_feature 1.0237879365866498\n",
      "9 566_feature 1.0164774460972132\n",
      "10 517_feature 1.0126412703585632\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 161_feature 1.464698040272943\n",
      "2 255_feature 1.400132272820061\n",
      "3 423_feature 1.2693105024357931\n",
      "4 260_feature 1.1636279566736918\n",
      "5 566_feature 1.03732564906199\n",
      "6 26_feature 1.0346214428524332\n",
      "7 548_feature 1.0198915718025838\n",
      "8 395_feature 1.0107785984374484\n",
      "9 508_feature 1.0060456397156956\n",
      "10 517_feature 0.9991978553609331\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 79_feature 0.9569372102829437\n",
      "2 566_feature 0.946841142650659\n",
      "3 228_feature 0.9421200144540942\n",
      "4 388_feature 0.8779087925481033\n",
      "5 669_feature 0.8707300370516574\n",
      "6 697_feature 0.8464722967958427\n",
      "7 212_feature 0.8371699881841967\n",
      "8 614_feature 0.8216946959223146\n",
      "9 231_feature 0.8212387394808703\n",
      "10 500_feature 0.8028378422660079\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Trastorno por déficit atencional 0.9898439215829943\n",
      "2 Trastorno específico del lenguaje 0.9668304999649302\n",
      "3 388_feature 0.9572007433353195\n",
      "4 228_feature 0.9369139693888693\n",
      "5 669_feature 0.9201361089091453\n",
      "6 566_feature 0.9011990976773375\n",
      "7 79_feature 0.8600152957842387\n",
      "8 697_feature 0.7983632524763471\n",
      "9 614_feature 0.7925478265626228\n",
      "10 340_feature 0.7807885727314456\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 85_feature 1.018930505437854\n",
      "2 485_feature 0.9740617354017239\n",
      "3 345_feature 0.9458266882282543\n",
      "4 702_feature 0.9211983974196336\n",
      "5 76_feature 0.8671522469267848\n",
      "6 336_feature 0.863355062025175\n",
      "7 181_feature 0.8495503420890297\n",
      "8 725_feature 0.8407318891879964\n",
      "9 341_feature 0.8394965311082856\n",
      "10 77_feature 0.8348875525272846\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 85_feature 0.9815703799594021\n",
      "2 485_feature 0.9703379807716999\n",
      "3 76_feature 0.9556165291625058\n",
      "4 345_feature 0.9303191982780182\n",
      "5 341_feature 0.8729988247124477\n",
      "6 702_feature 0.8704423542747516\n",
      "7 336_feature 0.8527143547416122\n",
      "8 Trastorno específico del lenguaje 0.8260906622256047\n",
      "9 372_feature 0.8251847199545087\n",
      "10 654_feature 0.7998635625330509\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 89_feature 0.8543767490352691\n",
      "2 7_feature 0.8376387879435081\n",
      "3 185_feature 0.831279897362961\n",
      "4 395_feature 0.8311488819892613\n",
      "5 675_feature 0.8231135916228814\n",
      "6 671_feature 0.8108052322569725\n",
      "7 426_feature 0.7929735791276632\n",
      "8 205_feature 0.7866847492502789\n",
      "9 402_feature 0.7602850871993762\n",
      "10 292_feature 0.748513688887254\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 Trastorno específico del lenguaje 1.0427383896643054\n",
      "2 Funcionamiento intelectual limítrofe 0.8649706153778278\n",
      "3 205_feature 0.8291221258404632\n",
      "4 395_feature 0.820922530442995\n",
      "5 7_feature 0.816678455784307\n",
      "6 89_feature 0.8101436532566859\n",
      "7 185_feature 0.7927011347267208\n",
      "8 292_feature 0.7744834619052426\n",
      "9 675_feature 0.7465876981418013\n",
      "10 671_feature 0.7455381427019006\n",
      "\n",
      "--------- Resultados para Adecuación curricular de objetivos -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 327_feature 1.2237568346250678\n",
      "2 718_feature 1.0727134440285035\n",
      "3 373_feature 1.036009009408509\n",
      "4 265_feature 1.0066647372705815\n",
      "5 17_feature 0.9982460107946609\n",
      "6 541_feature 0.9470238065867218\n",
      "7 441_feature 0.9147643302894498\n",
      "8 386_feature 0.8583300083927449\n",
      "9 183_feature 0.8461480284547378\n",
      "10 540_feature 0.8334963205063176\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 327_feature 1.2269512190147374\n",
      "2 373_feature 1.0608095549816996\n",
      "3 718_feature 1.0363670713638578\n",
      "4 17_feature 0.9826937900349985\n",
      "5 265_feature 0.9644293992428284\n",
      "6 441_feature 0.917836604360536\n",
      "7 541_feature 0.8904607544951272\n",
      "8 386_feature 0.8702612271122755\n",
      "9 286_feature 0.8355101416877488\n",
      "10 183_feature 0.8051877037166033\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 73_feature 0.7957333214626522\n",
      "2 261_feature 0.7476943182126169\n",
      "3 169_feature 0.6969152241276986\n",
      "4 481_feature 0.6353607883917074\n",
      "5 12_feature 0.6228654288936026\n",
      "6 715_feature 0.6095516324911671\n",
      "7 220_feature 0.594606001417973\n",
      "8 611_feature 0.5869383071562055\n",
      "9 340_feature 0.5828770648585315\n",
      "10 115_feature 0.5765179446928029\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 73_feature 0.7717307158259775\n",
      "2 261_feature 0.7299271809515259\n",
      "3 169_feature 0.7023980521210845\n",
      "4 481_feature 0.6433808878100745\n",
      "5 220_feature 0.6161384220815543\n",
      "6 576_feature 0.6017704716730031\n",
      "7 611_feature 0.5998391611248343\n",
      "8 12_feature 0.595781223692938\n",
      "9 715_feature 0.5909986986174757\n",
      "10 67_feature 0.5844706865426087\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 73_feature 0.9572667949242489\n",
      "2 496_feature 0.9020412647459723\n",
      "3 230_feature 0.8613510421240435\n",
      "4 279_feature 0.8437523669284289\n",
      "5 272_feature 0.8301958968531513\n",
      "6 430_feature 0.8125208666350525\n",
      "7 722_feature 0.809358953835587\n",
      "8 201_feature 0.8073128457385456\n",
      "9 129_feature 0.7942591600713641\n",
      "10 228_feature 0.7932132600292099\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 73_feature 0.9594307732714635\n",
      "2 496_feature 0.8832995598696122\n",
      "3 230_feature 0.853511532609792\n",
      "4 722_feature 0.8290403372570512\n",
      "5 184_feature 0.82835043172233\n",
      "6 Retraso global del desarrollo 0.8255139806590516\n",
      "7 272_feature 0.8040028078203812\n",
      "8 129_feature 0.7926920327452884\n",
      "9 201_feature 0.7923728842988619\n",
      "10 430_feature 0.7915640741183225\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 28_feature 0.81952197472177\n",
      "2 22_feature 0.7546802923302002\n",
      "3 682_feature 0.7456034341375977\n",
      "4 430_feature 0.6998042909222025\n",
      "5 575_feature 0.6716645395971519\n",
      "6 551_feature 0.6509048326873293\n",
      "7 686_feature 0.6479511854987505\n",
      "8 522_feature 0.6322252743485062\n",
      "9 687_feature 0.6312222157825677\n",
      "10 335_feature 0.6249852961030713\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 28_feature 0.8234730826158219\n",
      "2 682_feature 0.7317955199911093\n",
      "3 22_feature 0.7187171475108908\n",
      "4 430_feature 0.6920875807570279\n",
      "5 Trastorno por déficit atencional 0.6472256927036664\n",
      "6 686_feature 0.6438812911118428\n",
      "7 522_feature 0.6373155118654323\n",
      "8 687_feature 0.622898056381186\n",
      "9 550_feature 0.6221203199460124\n",
      "10 335_feature 0.6220993869896296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for result in most_unbalanced_results:\n",
    "  strat_name = result['name']\n",
    "  print('--------- Resultados para '+strat_name+' -----------')\n",
    "  for i in range(len(result['coefs'])):\n",
    "    print('++++++++++ Experimento: '+experiments_names[i+1] + '+++++++++++')\n",
    "    make_top_tables(result['features'][i], result['coefs'][i][0], 10)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vkkFkyIwbAit",
    "outputId": "8a8fbd13-4488-4c6c-a4f1-14bed4adf121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Resultados para Tutoría entre pares -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 140_feature -1.310830174006506\n",
      "2 295_feature -1.1468951684787332\n",
      "3 192_feature -1.0686317594153845\n",
      "4 251_feature -0.9657967906621132\n",
      "5 660_feature -0.9536138001459507\n",
      "6 362_feature -0.9065461275083841\n",
      "7 148_feature -0.8837235737164406\n",
      "8 692_feature -0.8678190606739695\n",
      "9 463_feature -0.8469724997751862\n",
      "10 767_feature -0.8464825511211371\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 140_feature -1.3034448998388801\n",
      "2 295_feature -1.0752162335371815\n",
      "3 Trastorno motor -1.0583702632001601\n",
      "4 192_feature -0.9903589858953994\n",
      "5 251_feature -0.9445340263794944\n",
      "6 362_feature -0.909239185188197\n",
      "7 660_feature -0.8936969679384192\n",
      "8 692_feature -0.877552284228104\n",
      "9 233_feature -0.8675041808067556\n",
      "10 148_feature -0.8632271914608862\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 11_feature -0.7722565504404935\n",
      "2 140_feature -0.7451632463475089\n",
      "3 670_feature -0.7225644800754202\n",
      "4 595_feature -0.7049414007147047\n",
      "5 383_feature -0.6740542058806642\n",
      "6 50_feature -0.6615170482953964\n",
      "7 679_feature -0.6486458182370743\n",
      "8 157_feature -0.6454863297295561\n",
      "9 382_feature -0.6405376811201358\n",
      "10 329_feature -0.6323920984149909\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 11_feature -0.7633866789279535\n",
      "2 140_feature -0.758134473748681\n",
      "3 670_feature -0.7098703572786338\n",
      "4 595_feature -0.6781090347436811\n",
      "5 383_feature -0.6694617493207399\n",
      "6 50_feature -0.6608612528925863\n",
      "7 679_feature -0.6549897979985394\n",
      "8 382_feature -0.6540475753304973\n",
      "9 Trastorno por déficit atencional -0.6448266960217595\n",
      "10 157_feature -0.6427858269449362\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 48_feature -1.040773844198511\n",
      "2 79_feature -1.0070799854834684\n",
      "3 38_feature -0.89599972638966\n",
      "4 645_feature -0.8903042158712168\n",
      "5 660_feature -0.7768823899838774\n",
      "6 506_feature -0.7661841031303979\n",
      "7 17_feature -0.7334310510086972\n",
      "8 386_feature -0.7220926465233549\n",
      "9 635_feature -0.7207555775620913\n",
      "10 426_feature -0.7139175214698202\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 Trastorno motor -1.0835874202629243\n",
      "2 48_feature -1.036554116346133\n",
      "3 79_feature -0.956031684004861\n",
      "4 Trastorno por déficit atencional -0.9317247053400545\n",
      "5 645_feature -0.8730780783144859\n",
      "6 38_feature -0.8716675316557271\n",
      "7 660_feature -0.7663339585559745\n",
      "8 17_feature -0.7517006830618249\n",
      "9 635_feature -0.7429956766665006\n",
      "10 506_feature -0.72954933357991\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 440_feature -0.7957179012781478\n",
      "2 67_feature -0.7548504823260234\n",
      "3 622_feature -0.7404024615938207\n",
      "4 369_feature -0.6883645585897483\n",
      "5 217_feature -0.6797605087392606\n",
      "6 535_feature -0.6774293766870395\n",
      "7 38_feature -0.6752151338791493\n",
      "8 459_feature -0.6632028290966913\n",
      "9 478_feature -0.6469049719921012\n",
      "10 660_feature -0.6361041588009335\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 Trastorno por déficit atencional -1.0667108404987726\n",
      "2 Trastorno motor -0.8130802353524285\n",
      "3 622_feature -0.7633508854745248\n",
      "4 440_feature -0.7575559725608106\n",
      "5 67_feature -0.714751920396324\n",
      "6 369_feature -0.6799287338996983\n",
      "7 660_feature -0.6667111893678568\n",
      "8 459_feature -0.6656440629772279\n",
      "9 38_feature -0.6619101749821241\n",
      "10 217_feature -0.6520687674614408\n",
      "\n",
      "--------- Resultados para Apoyo Kinesióloga(o) -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 394_feature -0.6474602979395209\n",
      "2 107_feature -0.5828875696199972\n",
      "3 392_feature -0.5713090421572402\n",
      "4 30_feature -0.5546199313732246\n",
      "5 319_feature -0.5508003894009686\n",
      "6 541_feature -0.5457513576062055\n",
      "7 604_feature -0.5267686411805517\n",
      "8 719_feature -0.5135008989031709\n",
      "9 261_feature -0.4951890112454931\n",
      "10 226_feature -0.4694553453417839\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Trastorno específico del lenguaje -1.2862361459305593\n",
      "2 Trastorno por déficit atencional -0.8787329375961974\n",
      "3 Dificultad específica de aprendizaje -0.6761877354680109\n",
      "4 Funcionamiento intelectual limítrofe -0.6748375477062338\n",
      "5 394_feature -0.5741646538661319\n",
      "6 392_feature -0.5039631108073932\n",
      "7 261_feature -0.5034532898769568\n",
      "8 107_feature -0.4369521921901808\n",
      "9 541_feature -0.4339452358921867\n",
      "10 30_feature -0.4294989042733842\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 578_feature -0.2999062002868706\n",
      "2 246_feature -0.2750794461607629\n",
      "3 262_feature -0.26589026388000403\n",
      "4 468_feature -0.2633866242623607\n",
      "5 118_feature -0.26036404835667126\n",
      "6 269_feature -0.2556157953438727\n",
      "7 51_feature -0.25471595140076053\n",
      "8 273_feature -0.2466029672310999\n",
      "9 696_feature -0.24341815698023223\n",
      "10 211_feature -0.23628899624714042\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Funcionamiento intelectual limítrofe -0.5848615991056294\n",
      "2 Trastorno específico del lenguaje -0.3802341315539524\n",
      "3 Trastorno por déficit atencional -0.33317710145295626\n",
      "4 578_feature -0.2800278280406745\n",
      "5 262_feature -0.24797088977729487\n",
      "6 246_feature -0.24772225251009453\n",
      "7 269_feature -0.23541974593843215\n",
      "8 468_feature -0.2328464329569274\n",
      "9 51_feature -0.23157227030451272\n",
      "10 118_feature -0.22851553906231278\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 350_feature -0.6043034067303508\n",
      "2 265_feature -0.5630070192654651\n",
      "3 79_feature -0.5346381905318277\n",
      "4 48_feature -0.5297491032015724\n",
      "5 420_feature -0.500290717668067\n",
      "6 649_feature -0.4869148558643631\n",
      "7 684_feature -0.47098058742704213\n",
      "8 40_feature -0.4577917564470753\n",
      "9 490_feature -0.4521465212340806\n",
      "10 620_feature -0.42794565683023184\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 Trastorno específico del lenguaje -1.3876403584264958\n",
      "2 Trastorno por déficit atencional -0.9621068136065747\n",
      "3 Dificultad específica de aprendizaje -0.9096841303145006\n",
      "4 Funcionamiento intelectual limítrofe -0.6472104021857327\n",
      "5 350_feature -0.5000598062962448\n",
      "6 48_feature -0.47877622019843197\n",
      "7 265_feature -0.47766719637491595\n",
      "8 Trastorno del espectro autista -0.44823928041701566\n",
      "9 164_feature -0.4175626524765386\n",
      "10 119_feature -0.41060286602980195\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 265_feature -0.2738704627167323\n",
      "2 79_feature -0.2729344939883253\n",
      "3 576_feature -0.27199716721748046\n",
      "4 93_feature -0.2676594233144872\n",
      "5 397_feature -0.2675800588825182\n",
      "6 79_feature -0.26523583288819363\n",
      "7 431_feature -0.2632595691682076\n",
      "8 581_feature -0.25768976798934456\n",
      "9 30_feature -0.25341076424171716\n",
      "10 499_feature -0.24666595941701602\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 Funcionamiento intelectual limítrofe -0.5865271080771293\n",
      "2 Trastorno específico del lenguaje -0.573405816640806\n",
      "3 Trastorno por déficit atencional -0.3560753359965288\n",
      "4 265_feature -0.2458252969645421\n",
      "5 581_feature -0.23977183367834673\n",
      "6 79_feature -0.23829012474862635\n",
      "7 79_feature -0.2360247440490816\n",
      "8 431_feature -0.23581217517433692\n",
      "9 397_feature -0.23509946969765322\n",
      "10 93_feature -0.23011361266726654\n",
      "\n",
      "--------- Resultados para Apoyo Médico General -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 459_feature -0.7696538814362424\n",
      "2 547_feature -0.6934955916265549\n",
      "3 13_feature -0.6077954573552274\n",
      "4 508_feature -0.6017806187692034\n",
      "5 32_feature -0.5923115479241196\n",
      "6 749_feature -0.5912807334227186\n",
      "7 583_feature -0.5772166828905262\n",
      "8 1_feature -0.5753688536421897\n",
      "9 40_feature -0.5732050585987419\n",
      "10 262_feature -0.5656391431001434\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 459_feature -0.7571951998992414\n",
      "2 547_feature -0.6744235063593916\n",
      "3 Trastorno específico del lenguaje -0.6424180827365527\n",
      "4 749_feature -0.6239379130957423\n",
      "5 13_feature -0.6156367940824927\n",
      "6 278_feature -0.6075226100642969\n",
      "7 583_feature -0.5906976039916015\n",
      "8 262_feature -0.575489481374771\n",
      "9 639_feature -0.5700864394160284\n",
      "10 1_feature -0.5689044284024403\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 225_feature -0.4327436392944837\n",
      "2 696_feature -0.41146129446840723\n",
      "3 488_feature -0.38084508334907746\n",
      "4 183_feature -0.3803493632844451\n",
      "5 459_feature -0.38022008460921386\n",
      "6 134_feature -0.37450452787269123\n",
      "7 648_feature -0.3630952424572798\n",
      "8 32_feature -0.36077748424921663\n",
      "9 4_feature -0.354732341190855\n",
      "10 674_feature -0.33424920744186676\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Trastorno específico del lenguaje -0.8514789115495311\n",
      "2 Discapacidad intelectual -0.5897799440701267\n",
      "3 225_feature -0.42334846881717614\n",
      "4 696_feature -0.4195058214238661\n",
      "5 183_feature -0.37300939068049344\n",
      "6 134_feature -0.3680240770129223\n",
      "7 4_feature -0.35942649911582486\n",
      "8 488_feature -0.3574597767512003\n",
      "9 459_feature -0.3566330710892433\n",
      "10 648_feature -0.3527304354514234\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 113_feature -0.6717640571141213\n",
      "2 185_feature -0.6264298585431307\n",
      "3 48_feature -0.5892006542356059\n",
      "4 366_feature -0.5800708002369902\n",
      "5 754_feature -0.5604872717698637\n",
      "6 407_feature -0.5600881918529111\n",
      "7 65_feature -0.5225902915955682\n",
      "8 709_feature -0.4747977832930168\n",
      "9 93_feature -0.45968012427150995\n",
      "10 730_feature -0.43711302339170255\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 Trastorno específico del lenguaje -0.692631045821646\n",
      "2 113_feature -0.6633519535795622\n",
      "3 48_feature -0.6026365422857188\n",
      "4 185_feature -0.5951813296278526\n",
      "5 366_feature -0.593133139437476\n",
      "6 754_feature -0.5633913899956733\n",
      "7 407_feature -0.5581651546161873\n",
      "8 Discapacidad intelectual -0.5052341318107768\n",
      "9 65_feature -0.4941861803479189\n",
      "10 709_feature -0.4929753786983389\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 93_feature -0.44905682736348984\n",
      "2 754_feature -0.40443495960373965\n",
      "3 386_feature -0.35860599428658807\n",
      "4 366_feature -0.3485692100534183\n",
      "5 575_feature -0.33982948326694\n",
      "6 759_feature -0.3353314939222441\n",
      "7 58_feature -0.3334122056646516\n",
      "8 285_feature -0.32920892688920594\n",
      "9 67_feature -0.3285577491195959\n",
      "10 724_feature -0.3277470172760599\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 Trastorno específico del lenguaje -0.856694466180218\n",
      "2 93_feature -0.43711156191853073\n",
      "3 Discapacidad intelectual -0.38813786796114685\n",
      "4 754_feature -0.3778961254185025\n",
      "5 386_feature -0.3700527515426438\n",
      "6 285_feature -0.3512001539833272\n",
      "7 366_feature -0.3473362147151316\n",
      "8 759_feature -0.34283817576178577\n",
      "9 131_feature -0.3306671985644443\n",
      "10 67_feature -0.33061042347684216\n",
      "\n",
      "--------- Resultados para Apoyo Terapeuta Ocupacional -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 722_feature -0.9794044490749669\n",
      "2 319_feature -0.8821967653067405\n",
      "3 373_feature -0.8348500411532894\n",
      "4 308_feature -0.7940586108279309\n",
      "5 341_feature -0.7745882214623413\n",
      "6 403_feature -0.7600923543213688\n",
      "7 36_feature -0.713541913029956\n",
      "8 62_feature -0.7094230468536362\n",
      "9 651_feature -0.6654988961632928\n",
      "10 59_feature -0.6546851280967575\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Dificultad específica de aprendizaje -1.9078414583940424\n",
      "2 722_feature -0.9914717350085785\n",
      "3 Trastorno por déficit atencional -0.9652523324578409\n",
      "4 319_feature -0.8290544083624185\n",
      "5 373_feature -0.7371507614605248\n",
      "6 308_feature -0.7125702055204896\n",
      "7 Trastorno específico del lenguaje -0.7082408019042574\n",
      "8 469_feature -0.7022987199370943\n",
      "9 721_feature -0.6817002548659988\n",
      "10 341_feature -0.6814207027048794\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 716_feature -0.6135117446978771\n",
      "2 343_feature -0.5662749373460008\n",
      "3 363_feature -0.5608695753880594\n",
      "4 29_feature -0.555314905316065\n",
      "5 568_feature -0.542588595243787\n",
      "6 346_feature -0.5383600274364672\n",
      "7 371_feature -0.5178986217060632\n",
      "8 719_feature -0.5033689579423354\n",
      "9 370_feature -0.49687345369849256\n",
      "10 193_feature -0.4935958453336633\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Dificultad específica de aprendizaje -1.347377959806082\n",
      "2 Trastorno por déficit atencional -0.962146340745205\n",
      "3 Trastorno específico del lenguaje -0.782268752869104\n",
      "4 716_feature -0.5592000231578664\n",
      "5 343_feature -0.5590657033638021\n",
      "6 363_feature -0.553962147238397\n",
      "7 29_feature -0.5020994847878095\n",
      "8 193_feature -0.49572277664943803\n",
      "9 719_feature -0.48349018077951716\n",
      "10 370_feature -0.46006700641740833\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 133_feature -0.9604654845189264\n",
      "2 193_feature -0.7381982623180723\n",
      "3 144_feature -0.6886772928632111\n",
      "4 696_feature -0.680770700064936\n",
      "5 167_feature -0.6678244044775213\n",
      "6 709_feature -0.6393767806691554\n",
      "7 192_feature -0.6270198885480643\n",
      "8 59_feature -0.6018503609524944\n",
      "9 468_feature -0.5937599915947684\n",
      "10 683_feature -0.5863520010975781\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 Dificultad específica de aprendizaje -1.9312260389155556\n",
      "2 Trastorno por déficit atencional -0.9393163698271196\n",
      "3 133_feature -0.8062545094077722\n",
      "4 Trastorno específico del lenguaje -0.7672241698289793\n",
      "5 193_feature -0.7176018033819598\n",
      "6 192_feature -0.6722120905495863\n",
      "7 709_feature -0.6562391601300523\n",
      "8 144_feature -0.6417314289463101\n",
      "9 638_feature -0.6147886091947522\n",
      "10 59_feature -0.5840556090828899\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 442_feature -0.5987746732545122\n",
      "2 297_feature -0.5716165318352845\n",
      "3 577_feature -0.5701320283294972\n",
      "4 439_feature -0.5631917611509437\n",
      "5 681_feature -0.5210993401550366\n",
      "6 603_feature -0.5122614802174942\n",
      "7 622_feature -0.5008645982002475\n",
      "8 308_feature -0.5004266322546462\n",
      "9 89_feature -0.49321992609504506\n",
      "10 537_feature -0.4922480872907145\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 Dificultad específica de aprendizaje -1.6806942590597\n",
      "2 Trastorno por déficit atencional -1.053185497336777\n",
      "3 Trastorno específico del lenguaje -0.9859222115783507\n",
      "4 442_feature -0.5682220372065793\n",
      "5 577_feature -0.532388247773362\n",
      "6 439_feature -0.506131427206984\n",
      "7 454_feature -0.4977419643814258\n",
      "8 603_feature -0.4807648910069243\n",
      "9 544_feature -0.4788054315381058\n",
      "10 89_feature -0.4784669173170009\n",
      "\n",
      "--------- Resultados para Control Neurólogo -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 274_feature -0.7471099804153006\n",
      "2 80_feature -0.7360636464407678\n",
      "3 659_feature -0.7175062647569088\n",
      "4 761_feature -0.5769881413283691\n",
      "5 345_feature -0.5694252668344081\n",
      "6 338_feature -0.5527613275237598\n",
      "7 388_feature -0.5488586825085251\n",
      "8 15_feature -0.5408337204384032\n",
      "9 465_feature -0.5224590740659304\n",
      "10 495_feature -0.5198906138694533\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 274_feature -0.7908284667607037\n",
      "2 80_feature -0.7536413606744878\n",
      "3 659_feature -0.6564717636437345\n",
      "4 Dificultad específica de aprendizaje -0.6466382019185206\n",
      "5 465_feature -0.5859208161726963\n",
      "6 15_feature -0.5654917062895198\n",
      "7 761_feature -0.5637031775948501\n",
      "8 345_feature -0.5411263631959317\n",
      "9 723_feature -0.5401431891383174\n",
      "10 487_feature -0.5307488209545884\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 465_feature -0.4250490108345369\n",
      "2 704_feature -0.3985504551087918\n",
      "3 768_feature -0.37221199629287083\n",
      "4 432_feature -0.35569902332744\n",
      "5 537_feature -0.3532857514116055\n",
      "6 334_feature -0.3301268480537343\n",
      "7 635_feature -0.3289299100720482\n",
      "8 569_feature -0.3286990306026032\n",
      "9 483_feature -0.32842514691962776\n",
      "10 744_feature -0.3250372369598508\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 465_feature -0.4264740847151471\n",
      "2 704_feature -0.3840323564863157\n",
      "3 768_feature -0.36278044614128885\n",
      "4 537_feature -0.3584714525771081\n",
      "5 Dificultad específica de aprendizaje -0.34951249508391447\n",
      "6 432_feature -0.3441143372980342\n",
      "7 Síndrome de Down -0.34376466557478846\n",
      "8 334_feature -0.34014257415878885\n",
      "9 635_feature -0.32466762852513265\n",
      "10 349_feature -0.32353359155954503\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 755_feature -0.7183498180820155\n",
      "2 17_feature -0.6141919780443554\n",
      "3 466_feature -0.5748107563159052\n",
      "4 543_feature -0.530500323129873\n",
      "5 584_feature -0.5210541798688395\n",
      "6 765_feature -0.5183970953280342\n",
      "7 241_feature -0.50895220188913\n",
      "8 733_feature -0.49620546497081874\n",
      "9 244_feature -0.48477675067772175\n",
      "10 106_feature -0.4751676849984309\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 755_feature -0.712844710628853\n",
      "2 17_feature -0.5792496491711171\n",
      "3 466_feature -0.5670715267667245\n",
      "4 543_feature -0.5649011352038404\n",
      "5 584_feature -0.516139630802987\n",
      "6 244_feature -0.49223868716965247\n",
      "7 336_feature -0.4870091713367642\n",
      "8 251_feature -0.46615902039543233\n",
      "9 106_feature -0.4441629466912188\n",
      "10 Dificultad específica de aprendizaje -0.4411122393627968\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 241_feature -0.45812958873219645\n",
      "2 263_feature -0.40533198399158954\n",
      "3 243_feature -0.38244651947201885\n",
      "4 733_feature -0.35115931944332385\n",
      "5 721_feature -0.3456031188618785\n",
      "6 366_feature -0.34008555464102086\n",
      "7 543_feature -0.33343456201739163\n",
      "8 507_feature -0.33342791021574836\n",
      "9 305_feature -0.3287141996884517\n",
      "10 420_feature -0.32532675400260846\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 241_feature -0.44837357211832296\n",
      "2 263_feature -0.4128219785836497\n",
      "3 243_feature -0.392990967698108\n",
      "4 721_feature -0.34892617199798637\n",
      "5 366_feature -0.34733630164494256\n",
      "6 543_feature -0.3421470419347487\n",
      "7 733_feature -0.3316566049599536\n",
      "8 507_feature -0.32574532140913737\n",
      "9 670_feature -0.3235427375009064\n",
      "10 420_feature -0.32350931635507774\n",
      "\n",
      "--------- Resultados para Adecuación curricular de acceso -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 583_feature -1.44905189774255\n",
      "2 317_feature -1.2570284009258155\n",
      "3 426_feature -1.2215914117498123\n",
      "4 367_feature -1.1504870349503495\n",
      "5 415_feature -1.125587112821892\n",
      "6 321_feature -1.1015304213788653\n",
      "7 668_feature -1.0605974869241017\n",
      "8 183_feature -1.0447135896219508\n",
      "9 38_feature -1.0436901018051812\n",
      "10 767_feature -1.0387319401200106\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Discapacidad auditiva - Hipoacusia -1.7344077746291764\n",
      "2 583_feature -1.4100050270706175\n",
      "3 426_feature -1.2725409545248765\n",
      "4 317_feature -1.2098820307519256\n",
      "5 321_feature -1.1962390399071945\n",
      "6 415_feature -1.1752343201701683\n",
      "7 367_feature -1.1536570142941327\n",
      "8 201_feature -1.062918030242387\n",
      "9 Trastorno motor -0.986793148423787\n",
      "10 183_feature -0.9737393816800757\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 326_feature -1.165845661029505\n",
      "2 550_feature -1.111595008538206\n",
      "3 582_feature -1.0312938430881147\n",
      "4 43_feature -1.0300432292913309\n",
      "5 663_feature -0.9836462615588975\n",
      "6 87_feature -0.9353174038754618\n",
      "7 174_feature -0.9195375137200237\n",
      "8 696_feature -0.9166366234134954\n",
      "9 437_feature -0.9086951651237649\n",
      "10 214_feature -0.8850451935716133\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Discapacidad auditiva - Hipoacusia -1.677045988156219\n",
      "2 326_feature -1.1589497587501816\n",
      "3 Trastorno motor -1.0908627752035558\n",
      "4 550_feature -1.0267041274112025\n",
      "5 582_feature -0.9961862599690299\n",
      "6 663_feature -0.9628009845292627\n",
      "7 437_feature -0.9397356770302835\n",
      "8 43_feature -0.9383624475574665\n",
      "9 696_feature -0.9309989216348853\n",
      "10 685_feature -0.9102753405694289\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 443_feature -1.1352314731795983\n",
      "2 264_feature -1.092524591527563\n",
      "3 594_feature -0.9487112102727882\n",
      "4 764_feature -0.9010913510040255\n",
      "5 561_feature -0.89918768055483\n",
      "6 318_feature -0.8836611008808862\n",
      "7 556_feature -0.8818002402189115\n",
      "8 738_feature -0.8551117635674476\n",
      "9 158_feature -0.8465287398277709\n",
      "10 454_feature -0.8274329724368722\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 Discapacidad auditiva - Hipoacusia -1.3780230383300789\n",
      "2 443_feature -1.1879696380249467\n",
      "3 Trastorno motor -1.1075742824967374\n",
      "4 264_feature -1.044236177283108\n",
      "5 556_feature -0.9018320276521263\n",
      "6 561_feature -0.8971689364809248\n",
      "7 137_feature -0.8785199088807634\n",
      "8 651_feature -0.8639552154627703\n",
      "9 318_feature -0.8550599376893017\n",
      "10 594_feature -0.8263741959293088\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 625_feature -1.1764724427295212\n",
      "2 298_feature -0.9382725626750054\n",
      "3 309_feature -0.9352804833196411\n",
      "4 661_feature -0.9121284432704926\n",
      "5 587_feature -0.9053087349027702\n",
      "6 654_feature -0.8619530185241792\n",
      "7 264_feature -0.8408700387328083\n",
      "8 729_feature -0.8382733326624187\n",
      "9 73_feature -0.8275459165238735\n",
      "10 148_feature -0.8225238558282029\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 Discapacidad auditiva - Hipoacusia -1.3260302457846012\n",
      "2 Trastorno motor -1.181431645038857\n",
      "3 625_feature -1.1361609281018263\n",
      "4 661_feature -0.9873805214710428\n",
      "5 298_feature -0.9402327363231546\n",
      "6 Discapacidad visual -0.876786981261225\n",
      "7 654_feature -0.8752453336703997\n",
      "8 309_feature -0.858967831728027\n",
      "9 73_feature -0.8490792660925118\n",
      "10 587_feature -0.8385605978409111\n",
      "\n",
      "--------- Resultados para Adecuación curricular de objetivos -----------\n",
      "++++++++++ Experimento: All perceptions with BETO (average)+++++++++++\n",
      "1 352_feature -1.251116389407542\n",
      "2 393_feature -1.1352984876248415\n",
      "3 375_feature -1.0703980917612603\n",
      "4 310_feature -1.0618946881285685\n",
      "5 344_feature -1.0133400212480344\n",
      "6 20_feature -0.9717977672138995\n",
      "7 150_feature -0.9713008386878923\n",
      "8 132_feature -0.9566596469297899\n",
      "9 5_feature -0.8912553429303097\n",
      "10 679_feature -0.8865270757245097\n",
      "\n",
      "++++++++++ Experimento: All perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 352_feature -1.270197167967533\n",
      "2 393_feature -1.1408679092820226\n",
      "3 310_feature -1.1104959376330596\n",
      "4 375_feature -1.0504089083665966\n",
      "5 679_feature -1.0060629990320282\n",
      "6 20_feature -0.9921919316610115\n",
      "7 344_feature -0.9720932220478039\n",
      "8 132_feature -0.9655819471468412\n",
      "9 150_feature -0.9574029654752042\n",
      "10 5_feature -0.948949970860473\n",
      "\n",
      "++++++++++ Experimento: Different perceptions with BETO (average)+++++++++++\n",
      "1 435_feature -0.6713833195929796\n",
      "2 309_feature -0.6450378587103129\n",
      "3 506_feature -0.627584053924546\n",
      "4 668_feature -0.6139636545331627\n",
      "5 99_feature -0.5990467843103524\n",
      "6 514_feature -0.5901093103813136\n",
      "7 5_feature -0.5899844170054178\n",
      "8 745_feature -0.5773299522363846\n",
      "9 663_feature -0.5756953865108639\n",
      "10 382_feature -0.5675839613403583\n",
      "\n",
      "++++++++++ Experimento: Different perceptions (BETO) + diagnosis (average)+++++++++++\n",
      "1 Trastorno específico del lenguaje -0.7621955575032866\n",
      "2 309_feature -0.6663039999633117\n",
      "3 435_feature -0.6573499644486626\n",
      "4 5_feature -0.6223681094656522\n",
      "5 506_feature -0.6138185022741767\n",
      "6 99_feature -0.5845251895111285\n",
      "7 514_feature -0.5781604251782534\n",
      "8 668_feature -0.5753372665015518\n",
      "9 382_feature -0.5679777177943953\n",
      "10 287_feature -0.5568475770062739\n",
      "\n",
      "++++++++++ Experimento: Sentence BERT embedding+++++++++++\n",
      "1 550_feature -1.0232401548295111\n",
      "2 420_feature -0.980896068211229\n",
      "3 636_feature -0.8982841191032102\n",
      "4 3_feature -0.8811472006795319\n",
      "5 434_feature -0.8742125043255484\n",
      "6 93_feature -0.8708152477459973\n",
      "7 676_feature -0.7935852181767539\n",
      "8 635_feature -0.786731675854686\n",
      "9 605_feature -0.7688730338619675\n",
      "10 768_feature -0.7603347839242425\n",
      "\n",
      "++++++++++ Experimento: Sentence + diagnosis+++++++++++\n",
      "1 550_feature -0.9760960522772538\n",
      "2 420_feature -0.9708013090495379\n",
      "3 636_feature -0.8568733511192016\n",
      "4 3_feature -0.8458770377642647\n",
      "5 93_feature -0.8349595337107834\n",
      "6 434_feature -0.8219182217677217\n",
      "7 277_feature -0.7803042140186105\n",
      "8 635_feature -0.771532451930025\n",
      "9 768_feature -0.7701088969454895\n",
      "10 676_feature -0.7580866564788709\n",
      "\n",
      "++++++++++ Experimento: Different perceptions+++++++++++\n",
      "1 84_feature -0.8052466406319662\n",
      "2 403_feature -0.7671689687969211\n",
      "3 521_feature -0.6643592539076504\n",
      "4 315_feature -0.6542679602115901\n",
      "5 92_feature -0.6464141727994416\n",
      "6 479_feature -0.6305971411422094\n",
      "7 738_feature -0.6168722152204598\n",
      "8 339_feature -0.6095933075745669\n",
      "9 708_feature -0.6076273789697731\n",
      "10 3_feature -0.5993785444576336\n",
      "\n",
      "++++++++++ Experimento: Different + diagnosis+++++++++++\n",
      "1 Trastorno específico del lenguaje -1.0322974288216609\n",
      "2 84_feature -0.7767351714529183\n",
      "3 403_feature -0.6987439542567155\n",
      "4 92_feature -0.6730878905315149\n",
      "5 315_feature -0.6488245914553514\n",
      "6 190_feature -0.611780345782851\n",
      "7 7_feature -0.5949885024066053\n",
      "8 479_feature -0.5878872155239389\n",
      "9 97_feature -0.5838979184798132\n",
      "10 339_feature -0.5808371950916023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for result in most_unbalanced_results:\n",
    "  strat_name = result['name']\n",
    "  print('--------- Resultados para '+strat_name+' -----------')\n",
    "  for i in range(len(result['coefs'])):\n",
    "    print('++++++++++ Experimento: '+experiments_names[i+1] + '+++++++++++')\n",
    "    make_bottom_tables(result['features'][i], result['coefs'][i][0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbFsbtqH7gNU",
    "outputId": "d5bac94f-95ad-46f9-c078-1a3eb6139793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment names                                    Tutoría entre pares              Apoyo Kinesióloga(o)                   Apoyo Médico General                   Apoyo Terapeuta Ocupacional      Control Neurólogo                   Adecuación curricular de acceso    Adecuación curricular de objetivos\n",
      "--------------------------------------------------  -------------------------------  -------------------------------------  -------------------------------------  -------------------------------  ----------------------------------  ---------------------------------  ------------------------------------\n",
      "Most frequent                                       0.88  0  0.47  0.5               0.99(*)  0  0.5  0.5                   0.98(*)  0  0.49  0.5                  0.95(*)  0  0.49  0.5            0.98(*)  0  0.49  0.5               0.78(*)  0  0.44  0.5              0.91(*)  0  0.48  0.5\n",
      "All perceptions with BETO (average)                 0.89(*)  0.17  0.57  0.56        0.99(*)  0  0.5  0.5                   0.98(*)  0.13(**)  0.56(**)  0.54(**)  0.95(*)  0.1  0.54  0.53         0.98(*)  0  0.49  0.5               0.77  0.19  0.59  0.58             0.9  0.01  0.49  0.5\n",
      "All perceptions (BETO) + diagnosis (average)        0.88  0.1  0.53  0.53            0.99(*)  0  0.5  0.5                   0.98(*)  0.13(**)  0.56(**)  0.54(**)  0.95(*)  0.19  0.59  0.56        0.98(*)  0  0.49  0.5               0.78(*)  0.22  0.61  0.59          0.9  0.01  0.49  0.5\n",
      "Different perceptions with BETO (average)           0.87  0.28(*)  0.64(*)  0.62(*)  0.99(*)  0.22  0.61  0.57              0.97  0  0.49  0.5                     0.94  0.22  0.61  0.59           0.98(*)  0  0.49  0.5               0.76  0.3  0.65  0.65              0.9  0.25(*)  0.62(**)  0.6(*)\n",
      "Different perceptions (BETO) + diagnosis (average)  0.87  0.28(*)  0.64(*)  0.62(*)  0.99(*)  0.25  0.62  0.57              0.97  0  0.49  0.5                     0.94  0.26(**)  0.63(*)  0.6(*)  0.98(*)  0  0.49  0.5               0.77  0.33(*)  0.66(*)  0.67(*)    0.9  0.24  0.62(**)  0.59\n",
      "Sentence BERT embedding                             0.89(*)  0.15  0.56  0.55        0.99(*)  0.25  0.62  0.57              0.98(*)  0.13(**)  0.56(**)  0.54(**)  0.95(*)  0.14  0.56  0.54        0.98(*)  0.12  0.56(*)  0.54(*)     0.77  0.17  0.57  0.57             0.9  0.01  0.49  0.5\n",
      "Sentence + diagnosis                                0.89(*)  0.17  0.57  0.55        0.99(*)  0.44(**)  0.72(**)  0.64(**)  0.98(*)  0.13(**)  0.56(**)  0.54(**)  0.95(*)  0.14  0.56  0.54        0.98(*)  0.13(*)  0.56(*)  0.54(*)  0.78(*)  0.22  0.6  0.59           0.9  0.01  0.49  0.5\n",
      "Different perceptions                               0.88  0.28(*)  0.64(*)  0.62(*)  0.99(*)  0  0.5  0.5                   0.98(*)  0  0.49  0.5                  0.93  0.05  0.52  0.52           0.97  0.09  0.54  0.53              0.76  0.27  0.64  0.63             0.9  0.16  0.58  0.56\n",
      "Different + diagnosis                               0.87  0.27  0.63  0.61           0.99(*)  0  0.5  0.5                   0.98(*)  0  0.49  0.5                  0.94  0.26(**)  0.63(*)  0.6(*)  0.97  0.09  0.54  0.53              0.77  0.31  0.65  0.65             0.9  0.18  0.58  0.57\n"
     ]
    }
   ],
   "source": [
    "print(make_table_for_python(most_unbalanced_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiPNXaUywlQ2",
    "outputId": "1b409cd7-a4bf-4020-d8d5-62d0fdf3e6f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features\n",
      "Tutoría entre pares\n",
      "All perceptions with BETO (average) : 768\n",
      "All perceptions (BETO) + diagnosis (average) : 780\n",
      "Different perceptions with BETO (average) : 3072\n",
      "Different perceptions (BETO) + diagnosis (average) : 3084\n",
      "Sentence BERT embedding : 768\n",
      "Sentence + diagnosis : 780\n",
      "Different perceptions : 3072\n",
      "Different + diagnosis : 3084\n",
      "\n",
      "Apoyo Kinesióloga(o)\n",
      "All perceptions with BETO (average) : 768\n",
      "All perceptions (BETO) + diagnosis (average) : 780\n",
      "Different perceptions with BETO (average) : 3072\n",
      "Different perceptions (BETO) + diagnosis (average) : 3084\n",
      "Sentence BERT embedding : 768\n",
      "Sentence + diagnosis : 780\n",
      "Different perceptions : 3072\n",
      "Different + diagnosis : 3084\n",
      "\n",
      "Apoyo Médico General\n",
      "All perceptions with BETO (average) : 768\n",
      "All perceptions (BETO) + diagnosis (average) : 780\n",
      "Different perceptions with BETO (average) : 3072\n",
      "Different perceptions (BETO) + diagnosis (average) : 3084\n",
      "Sentence BERT embedding : 768\n",
      "Sentence + diagnosis : 780\n",
      "Different perceptions : 3072\n",
      "Different + diagnosis : 3084\n",
      "\n",
      "Apoyo Terapeuta Ocupacional\n",
      "All perceptions with BETO (average) : 768\n",
      "All perceptions (BETO) + diagnosis (average) : 780\n",
      "Different perceptions with BETO (average) : 3072\n",
      "Different perceptions (BETO) + diagnosis (average) : 3084\n",
      "Sentence BERT embedding : 768\n",
      "Sentence + diagnosis : 780\n",
      "Different perceptions : 3072\n",
      "Different + diagnosis : 3084\n",
      "\n",
      "Control Neurólogo\n",
      "All perceptions with BETO (average) : 768\n",
      "All perceptions (BETO) + diagnosis (average) : 780\n",
      "Different perceptions with BETO (average) : 3072\n",
      "Different perceptions (BETO) + diagnosis (average) : 3084\n",
      "Sentence BERT embedding : 768\n",
      "Sentence + diagnosis : 780\n",
      "Different perceptions : 3072\n",
      "Different + diagnosis : 3084\n",
      "\n",
      "Adecuación curricular de acceso\n",
      "All perceptions with BETO (average) : 768\n",
      "All perceptions (BETO) + diagnosis (average) : 780\n",
      "Different perceptions with BETO (average) : 3072\n",
      "Different perceptions (BETO) + diagnosis (average) : 3084\n",
      "Sentence BERT embedding : 768\n",
      "Sentence + diagnosis : 780\n",
      "Different perceptions : 3072\n",
      "Different + diagnosis : 3084\n",
      "\n",
      "Adecuación curricular de objetivos\n",
      "All perceptions with BETO (average) : 768\n",
      "All perceptions (BETO) + diagnosis (average) : 780\n",
      "Different perceptions with BETO (average) : 3072\n",
      "Different perceptions (BETO) + diagnosis (average) : 3084\n",
      "Sentence BERT embedding : 768\n",
      "Sentence + diagnosis : 780\n",
      "Different perceptions : 3072\n",
      "Different + diagnosis : 3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of features')\n",
    "for strategy in most_unbalanced_results:\n",
    "  print(strategy['name'])\n",
    "  for i in range(1, len(experiments_names)):\n",
    "    print(experiments_names[i], ':', len(strategy['features'][i-1]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfdGBJaUGjYY",
    "outputId": "720b4275-9d97-4899-bb74-ea57c522fce6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment names                                    Tutoría entre pares (350 cases)    Kappa    F1       AUC      Apoyo Kinesióloga(o) (32 cases)    Kappa     F1        AUC       Apoyo Médico General (64 cases)    Kappa     F1        AUC       Apoyo Terapeuta Ocupacional (153 cases)    Kappa     F1       AUC     Control Neurólogo (63 cases)    Kappa    F1       AUC      Adecuación curricular de acceso (2264 cases)    Kappa    F1       AUC      Adecuación curricular de objetivos (281 cases)    Kappa    F1        AUC       Means    Kappa    F1    AUC\n",
      "--------------------------------------------------  ---------------------------------  -------  -------  -------  ---------------------------------  --------  --------  --------  ---------------------------------  --------  --------  --------  -----------------------------------------  --------  -------  ------  ------------------------------  -------  -------  -------  ----------------------------------------------  -------  -------  -------  ------------------------------------------------  -------  --------  ------  -------  -------  ----  -----\n",
      "Most frequent                                       0.88                               0.0      0.47     0.5      0.99(*)                            0.0       0.5       0.5       0.98(*)                            0.0       0.49      0.5       0.95(*)                                    0.0       0.49     0.5     0.98(*)                         0.0      0.49     0.5      0.78(*)                                         0.0      0.44     0.5      0.91(*)                                           0.0      0.48      0.5        0.92     0     0.48   0.5\n",
      "All perceptions with BETO (average)                 0.89(*)                            0.17     0.57     0.56     0.99(*)                            0.0       0.5       0.5       0.98(*)                            0.13(**)  0.56(**)  0.54(**)  0.95(*)                                    0.1       0.54     0.53    0.98(*)                         0.0      0.49     0.5      0.77                                            0.19     0.59     0.58     0.9                                               0.01     0.49      0.5        0.92     0.09  0.53   0.53\n",
      "All perceptions (BETO) + diagnosis (average)        0.88                               0.1      0.53     0.53     0.99(*)                            0.0       0.5       0.5       0.98(*)                            0.13(**)  0.56(**)  0.54(**)  0.95(*)                                    0.19      0.59     0.56    0.98(*)                         0.0      0.49     0.5      0.78(*)                                         0.22     0.61     0.59     0.9                                               0.01     0.49      0.5        0.92     0.09  0.54   0.53\n",
      "Different perceptions with BETO (average)           0.87                               0.28(*)  0.64(*)  0.62(*)  0.99(*)                            0.22      0.61      0.57      0.97                               -0.01     0.49      0.5       0.94                                       0.22      0.61     0.59    0.98(*)                         -0.01    0.49     0.5      0.76                                            0.3      0.65     0.65     0.9                                               0.25(*)  0.62(**)  0.6(*)     0.92     0.18  0.59   0.58\n",
      "Different perceptions (BETO) + diagnosis (average)  0.87                               0.28(*)  0.64(*)  0.62(*)  0.99(*)                            0.25      0.62      0.57      0.97                               -0.01     0.49      0.5       0.94                                       0.26(**)  0.63(*)  0.6(*)  0.98(*)                         -0.01    0.49     0.5      0.77                                            0.33(*)  0.66(*)  0.67(*)  0.9                                               0.24     0.62(**)  0.59       0.92     0.19  0.59   0.58\n",
      "Sentence BERT embedding                             0.89(*)                            0.15     0.56     0.55     0.99(*)                            0.25      0.62      0.57      0.98(*)                            0.13(**)  0.56(**)  0.54(**)  0.95(*)                                    0.14      0.56     0.54    0.98(*)                         0.12     0.56(*)  0.54(*)  0.77                                            0.17     0.57     0.57     0.9                                               0.01     0.49      0.5        0.92     0.14  0.56   0.54\n",
      "Sentence + diagnosis                                0.89(*)                            0.17     0.57     0.55     0.99(*)                            0.44(**)  0.72(**)  0.64(**)  0.98(*)                            0.13(**)  0.56(**)  0.54(**)  0.95(*)                                    0.14      0.56     0.54    0.98(*)                         0.13(*)  0.56(*)  0.54(*)  0.78(*)                                         0.22     0.6      0.59     0.9                                               0.01     0.49      0.5        0.92     0.18  0.58   0.56\n",
      "Different perceptions                               0.88                               0.28(*)  0.64(*)  0.62(*)  0.99(*)                            0.0       0.5       0.5       0.98(*)                            -0.0      0.49      0.5       0.93                                       0.05      0.52     0.52    0.97                            0.09     0.54     0.53     0.76                                            0.27     0.64     0.63     0.9                                               0.16     0.58      0.56       0.92     0.12  0.56   0.55\n",
      "Different + diagnosis                               0.87                               0.27     0.63     0.61     0.99(*)                            0.0       0.5       0.5       0.98(*)                            -0.0      0.49      0.5       0.94                                       0.26(**)  0.63(*)  0.6(*)  0.97                            0.09     0.54     0.53     0.77                                            0.31     0.65     0.65     0.9                                               0.18     0.58      0.57       0.92     0.16  0.57   0.57\n"
     ]
    }
   ],
   "source": [
    "print(make_table_for_latex(most_unbalanced_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRrGycV0kxyk",
    "outputId": "ad389a62-3be2-4498-9712-bebb4d68c601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experimentando para estrategia: Apoyo Pedagógico en asignaturas\n",
      "\t1° experimento\n",
      "\t2° experimento\n",
      "\t3° experimento\n",
      "\t4° experimento\n",
      "\t5° experimento\n",
      "\t6° experimento\n",
      "\t7° experimento\n",
      "\t8° experimento\n",
      "\t9° experimento\n",
      "experimentando para estrategia: Apoyo pedagógico personal\n",
      "\t1° experimento\n",
      "\t2° experimento\n",
      "\t3° experimento\n",
      "\t4° experimento\n",
      "\t5° experimento\n",
      "\t6° experimento\n",
      "\t7° experimento\n",
      "\t8° experimento\n",
      "\t9° experimento\n",
      "experimentando para estrategia: Hacer a la familia partícipe del proceso\n",
      "\t1° experimento\n",
      "\t2° experimento\n",
      "\t3° experimento\n",
      "\t4° experimento\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-30952a36ebfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mless_unbalanced_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mless_unbalanced_strategies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-2298d65e4414>\u001b[0m in \u001b[0;36mexecute_experiments\u001b[0;34m(X_train, Y_train, X_val, Y_val, selected_strategies, experiments)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             transformed_train_perceptions = list(map(\n\u001b[0;32m--> 144\u001b[0;31m                 lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_train[input['name']]))\n\u001b[0m\u001b[1;32m    145\u001b[0m             transformed_val_perceptions = list(map(\n\u001b[1;32m    146\u001b[0m                 lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_val[input['name']]))\n",
      "\u001b[0;32m<ipython-input-24-2298d65e4414>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(perception)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             transformed_train_perceptions = list(map(\n\u001b[0;32m--> 144\u001b[0;31m                 lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_train[input['name']]))\n\u001b[0m\u001b[1;32m    145\u001b[0m             transformed_val_perceptions = list(map(\n\u001b[1;32m    146\u001b[0m                 lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_val[input['name']]))\n",
      "\u001b[0;32m<ipython-input-21-1034a61ea3ef>\u001b[0m in \u001b[0;36mtransform_perception_to_feature_vector\u001b[0;34m(perception, mode)\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mpartial_modified_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mmini_perception\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdivided_perceptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmini_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBETO_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_perception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mpartial_modified_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_feature_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/pipelines.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mnested\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0mcomputed\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \"\"\"\n\u001b[0;32m--> 734\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/pipelines.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_and_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/pipelines.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, inputs, return_tensors)\u001b[0m\n\u001b[1;32m    655\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m         )\n\u001b[1;32m    850\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    481\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m                 )\n\u001b[1;32m    485\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         )\n\u001b[1;32m    404\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         )\n\u001b[1;32m    341\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_probs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "less_unbalanced_results = execute_experiments(X_train, Y_train, X_val, Y_val, less_unbalanced_strategies, experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARsoM_fuqKR3"
   },
   "outputs": [],
   "source": [
    "print(make_table_for_latex(less_unbalanced_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FuC0oBm7kz2i"
   },
   "outputs": [],
   "source": [
    "all_strats_results = execute_experiments(X_train, Y_train, X_val, Y_val, y_keys, experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyHZSOi3wMUY"
   },
   "outputs": [],
   "source": [
    "print(make_table_for_latex(all_strats_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrdTIcbHAGro"
   },
   "outputs": [],
   "source": [
    "ml_experiments = [\n",
    "               [{'name': 'All perceptions', 'type': 'BETO_string', 'transformation': 0}],\n",
    "               [{'name': 'All perceptions', 'type': 'BETO_string', 'transformation': 0}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'set'},\n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'm'}\n",
    "                ],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'set'},\n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'm'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}\n",
    "                ],\n",
    "               [{'name': 'All perceptions', 'type': 'sentence_embedding'}],\n",
    "               [{'name': 'All perceptions', 'type': 'sentence_embedding'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'sentence_embedding'}],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'sentence_embedding'},\n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}\n",
    "                ]\n",
    "               ]\n",
    "ml_experiments_names = [\n",
    "                     \"All perceptions with BETO (average)\",\n",
    "                     \"All perceptions (BETO) + diagnosis (average)\",\n",
    "                     \"Different perceptions with BETO (average)\",\n",
    "                     \"Different perceptions (BETO) + diagnosis (average)\",\n",
    "                     \"Sentence BERT embedding\",\n",
    "                     \"Sentence + diagnosis\",\n",
    "                     \"Different perceptions\",\n",
    "                     \"Different + diagnosis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-zlDMfotxCi"
   },
   "outputs": [],
   "source": [
    "def classifier_chain_experiments(X_train, Y_train, X_val, Y_val, y_keys, experiments):\n",
    "  preds = []\n",
    "  for experiment in experiments:\n",
    "    print(\"\\t\"+str(i+1)+'° experimento')\n",
    "    i += 1\n",
    "    if len(experiment) > 0:\n",
    "      base_lr = LogisticRegression(penalty='l2', dual=True, solver='liblinear', max_iter=10000)\n",
    "      classifier = ClassifierChain(base_lr, order='random', random_state=1)\n",
    "      X_train_transformed = pd.DataFrame()\n",
    "      X_val_transformed = pd.DataFrame()\n",
    "      for input in experiment:\n",
    "        # Encoding diagnosis as categorical attribute\n",
    "        if input['type'] == 'categorical_diagnostic':\n",
    "          enc = OneHotEncoder(handle_unknown='ignore')\n",
    "          enc.fit(np.asarray(X_train[input['name']].append(X_val[input['name']])).reshape(-1, 1))\n",
    "\n",
    "          train_arrays = enc.transform(np.asarray(X_train[input['name']]).reshape(-1,1)).toarray()\n",
    "          temp_train_df = pd.DataFrame(train_arrays, columns=list(diagnoses_codes.keys()))\n",
    "\n",
    "          val_arrays = enc.transform(np.asarray(X_val[input['name']]).reshape(-1,1)).toarray()\n",
    "          temp_val_df = pd.DataFrame(val_arrays, columns=list(diagnoses_codes.keys()))\n",
    "          \n",
    "          X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "          X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "          del temp_train_df, temp_val_df\n",
    "\n",
    "        # Copying numeric and binary attributes\n",
    "        if input['type'] == 'numeric' or input['type'] == 'binary':\n",
    "          X_train_transformed[input['name']] = X_train[input['name']].to_numpy()\n",
    "          X_val_transformed[input['name']] = X_val[input['name']].to_numpy()\n",
    "\n",
    "        # Encoding strings\n",
    "        if input['type'] == 'string':\n",
    "          vectorizer = CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=stopwords, ngram_range=(1,3), max_df=0.8, min_df=0.05)\n",
    "          vectorizer.fit(X_train[input['name']])\n",
    "          print(vectorizer.get_feature_names())\n",
    "          train_arrays = vectorizer.transform(X_train[input['name']]).toarray()\n",
    "          temp_train_df = pd.DataFrame(train_arrays, columns=vectorizer.get_feature_names())\n",
    "          \n",
    "          val_arrays = vectorizer.transform(X_val[input['name']]).toarray()\n",
    "          temp_val_df = pd.DataFrame(val_arrays, columns=vectorizer.get_feature_names())\n",
    "          \n",
    "          X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "          X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "          del temp_train_df, temp_val_df\n",
    "\n",
    "        # Encoding strings with special tokens\n",
    "        if input['type'] == 'special_string':\n",
    "          tokenzr = custom_tokenizer(input['special_token'])\n",
    "          vectorizer = CountVectorizer(strip_accents='unicode',\n",
    "                                      tokenizer=tokenzr,\n",
    "                                      lowercase=True,\n",
    "                                      stop_words=list(map(lambda word: input['special_token']+ \"_\" + word, stopwords)),\n",
    "                                      ngram_range=(1,3),\n",
    "                                      max_df=0.8,\n",
    "                                      min_df=0.05)\n",
    "          vectorizer.fit(X_train[input['name']])\n",
    "          train_arrays = vectorizer.transform(X_train[input['name']]).toarray()\n",
    "          temp_train_df = pd.DataFrame(train_arrays, columns=vectorizer.get_feature_names())\n",
    "          \n",
    "          val_arrays = vectorizer.transform(X_val[input['name']]).toarray()\n",
    "          temp_val_df = pd.DataFrame(val_arrays, columns=vectorizer.get_feature_names())\n",
    "          \n",
    "          X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "          X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "          del temp_train_df, temp_val_df\n",
    "\n",
    "        if input['type'] == \"embed_string\":\n",
    "          c_tokenizer = custom_tokenizer(input['special_token'])\n",
    "          embedding_model = Word2Vec(\n",
    "              list(map(lambda doc: c_tokenizer(doc), X_train[input['name']])),\n",
    "              min_count=1, \n",
    "              window=3, \n",
    "              sg=1, \n",
    "              size=input['n_features'])\n",
    "          vocab = embedding_model.wv.vocab\n",
    "          tokenized_train_perceptions = list(map(lambda doc: c_tokenizer(doc), X_train[input['name']]))\n",
    "          tokenized_val_perceptions = list(map(lambda doc: c_tokenizer(doc), X_val[input['name']]))\n",
    "          if input['transformation'] == 0:\n",
    "            transformed_train_perceptions = list(map(\n",
    "                lambda tokenized_perception: normalize_word_vectors(tokenized_perception,\n",
    "                                                                  embedding_model, \n",
    "                                                                  vocab, \n",
    "                                                                  input['n_features']), tokenized_train_perceptions))\n",
    "            transformed_val_perceptions = list(map(\n",
    "                lambda tokenized_perception: normalize_word_vectors(tokenized_perception,\n",
    "                                                                  embedding_model, \n",
    "                                                                  vocab, \n",
    "                                                                  input['n_features']), tokenized_val_perceptions))\n",
    "          if input['transformation'] == 1:\n",
    "            transformed_train_perceptions = list(map(\n",
    "                lambda tokenized_perception: average_word_vectors(tokenized_perception,\n",
    "                                                                  embedding_model, \n",
    "                                                                  vocab, \n",
    "                                                                  input['n_features']), tokenized_train_perceptions))\n",
    "            transformed_val_perceptions = list(map(\n",
    "                lambda tokenized_perception: average_word_vectors(tokenized_perception,\n",
    "                                                                  embedding_model, \n",
    "                                                                  vocab, \n",
    "                                                                  input['n_features']), tokenized_val_perceptions))\n",
    "          \n",
    "\n",
    "          temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(input['n_features'])])\n",
    "          temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(input['n_features'])])\n",
    "          \n",
    "          X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "          X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "          del temp_train_df, temp_val_df\n",
    "\n",
    "        if input['type'] == \"BETO_string\":\n",
    "\n",
    "          transformed_train_perceptions = list(map(\n",
    "              lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_train[input['name']]))\n",
    "          transformed_val_perceptions = list(map(\n",
    "              lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_val[input['name']]))\n",
    "\n",
    "          temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_train_perceptions[0]))])\n",
    "          temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_val_perceptions[0]))])\n",
    "          \n",
    "          X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "          X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "          del temp_train_df, temp_val_df\n",
    "\n",
    "        if input['type'] == \"sentence_embedding\":\n",
    "\n",
    "          transformed_train_perceptions = list(map(\n",
    "              lambda perception: sentence_model.encode(perception), X_train[input['name']]))\n",
    "          transformed_val_perceptions = list(map(\n",
    "              lambda perception: sentence_model.encode(perception), X_val[input['name']]))\n",
    "\n",
    "          temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_train_perceptions[0]))])\n",
    "          temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_val_perceptions[0]))])\n",
    "          \n",
    "          X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "          X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "          del temp_train_df, temp_val_df\n",
    "            \n",
    "\n",
    "      classifier.fit(X_train_transformed, Y_train)\n",
    "      Y_pred = classifier.predict(X_val_transformed)\n",
    "      preds.append(Y_pred)\n",
    "      del X_train_transformed, X_val_transformed\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUmnZyhmKt5o"
   },
   "outputs": [],
   "source": [
    "ml_results = classifier_chain_experiments(X_train, Y_train, X_val, Y_val, y_keys, ml_experiments)\n",
    "np.save('/content/gdrive/MyDrive/magister/ml_results.npy', ml_results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Experiments2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01213c1a832d4470a2fa43f44eadcefb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_186e00ec9711432f800dad7208ee934d",
      "max": 456,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9dca32ff2034723a27234c65831f250",
      "value": 456
     }
    },
    "0c35f97ff67f46028bf7db0153978d1b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10ea299972b24d80a33531ae521f5d22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7045a41d27824c51899ec0f187ec3139",
       "IPY_MODEL_9c21c394de054d06a58d6271acaab139"
      ],
      "layout": "IPY_MODEL_31dc8f9280794864ade21dbcd69f3928"
     }
    },
    "12d4ec0e41b547f18081ac98130311c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "151161a54c47429bb719f4c261ad6084": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15ac0fb85b884b9ebe812dc54e3e3d61": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee3989d9c8eb487fae77a1ad38e37626",
       "IPY_MODEL_b6d3d01f10d64925b106d73c7cfb6f51"
      ],
      "layout": "IPY_MODEL_d56faf744e1a4bcb8810f8d76709206b"
     }
    },
    "17cdce25665c4aadb77751942e38a756": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "186e00ec9711432f800dad7208ee934d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1906c14c542743d9a23f1975de6385dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_01213c1a832d4470a2fa43f44eadcefb",
       "IPY_MODEL_80275da53562465b9ccc99ffc44a577d"
      ],
      "layout": "IPY_MODEL_6300c62468154b78be4b083a7930a077"
     }
    },
    "1c4fb33be96e440199f8cf044a345bd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e1a828789ab64aa29b39b91572b13973",
       "IPY_MODEL_eb9b8662da6e4695953c51bd95ab11f8"
      ],
      "layout": "IPY_MODEL_b22811169771464f851a48d1d46319aa"
     }
    },
    "1cf09e75e7294f54bb3ffb1bb168c00f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1db4c30f7431453e89004c3473d61676": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2f5980dcea214cd5982a97a3e0f72109": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31dc8f9280794864ade21dbcd69f3928": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bdba093eef54e5a97c4e601a1e93345": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be44a211f3394357beef2d0801462a24",
      "max": 42,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f2be2d3551ad406e9f56cabd5c07fee6",
      "value": 42
     }
    },
    "416e2afaa86a4909a7ec7a2380edccfb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f7a5f01dbc847408a61e02eefc813a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5371dc7f483949d5a9b10b58fc86d268": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57afa95252b84bab88bc788afba2bca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7310f750736b490cbdf3c67ec6deb4a0",
       "IPY_MODEL_baf4fa2efecd4051897dcbc219cf367e"
      ],
      "layout": "IPY_MODEL_de0ebe4d5e6d4d17ac0504e3b46bcb9e"
     }
    },
    "6300c62468154b78be4b083a7930a077": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e19da41b1c44f938d5fd023830c18ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7045a41d27824c51899ec0f187ec3139": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f5980dcea214cd5982a97a3e0f72109",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5a13f99464b46ad93a4ba53c03a6bc6",
      "value": 112
     }
    },
    "7310f750736b490cbdf3c67ec6deb4a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_151161a54c47429bb719f4c261ad6084",
      "max": 441944381,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1db4c30f7431453e89004c3473d61676",
      "value": 441944381
     }
    },
    "7456e6c6654d4879a8877963af04c18f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80275da53562465b9ccc99ffc44a577d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_416e2afaa86a4909a7ec7a2380edccfb",
      "placeholder": "​",
      "style": "IPY_MODEL_de294721cb3d443b81ba0b630c097ed7",
      "value": " 456/456 [00:01&lt;00:00, 381B/s]"
     }
    },
    "84ec795d79514a35b132a7ba107841f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94ae206a4a0b438a874e656fe89cc103": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7456e6c6654d4879a8877963af04c18f",
      "placeholder": "​",
      "style": "IPY_MODEL_cfd33404c83e409f98070ffdd70e14c2",
      "value": " 42.0/42.0 [00:00&lt;00:00, 308B/s]"
     }
    },
    "9c21c394de054d06a58d6271acaab139": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5371dc7f483949d5a9b10b58fc86d268",
      "placeholder": "​",
      "style": "IPY_MODEL_bd1c33748983407da09c5809f01829ce",
      "value": " 112/112 [00:00&lt;00:00, 336B/s]"
     }
    },
    "b22811169771464f851a48d1d46319aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d3d01f10d64925b106d73c7cfb6f51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17cdce25665c4aadb77751942e38a756",
      "placeholder": "​",
      "style": "IPY_MODEL_84ec795d79514a35b132a7ba107841f8",
      "value": " 248k/248k [00:00&lt;00:00, 730kB/s]"
     }
    },
    "baf4fa2efecd4051897dcbc219cf367e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ffb467ff52bf4c94921575a7afceb2bc",
      "placeholder": "​",
      "style": "IPY_MODEL_f863635ea3474dc697f698fcd80aeb2b",
      "value": " 442M/442M [00:12&lt;00:00, 35.4MB/s]"
     }
    },
    "bd1c33748983407da09c5809f01829ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be44a211f3394357beef2d0801462a24": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfd33404c83e409f98070ffdd70e14c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d56faf744e1a4bcb8810f8d76709206b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d62de3eda1bd43ceb760f2e26ee8515e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "de0ebe4d5e6d4d17ac0504e3b46bcb9e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de294721cb3d443b81ba0b630c097ed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1a828789ab64aa29b39b91572b13973": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f7a5f01dbc847408a61e02eefc813a4",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1cf09e75e7294f54bb3ffb1bb168c00f",
      "value": 2
     }
    },
    "eb9b8662da6e4695953c51bd95ab11f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2bf38d48c8141bca58806d4d4b781eb",
      "placeholder": "​",
      "style": "IPY_MODEL_12d4ec0e41b547f18081ac98130311c4",
      "value": " 2.00/2.00 [08:12&lt;00:00, 246s/B]"
     }
    },
    "ee3989d9c8eb487fae77a1ad38e37626": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e19da41b1c44f938d5fd023830c18ae",
      "max": 248047,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d62de3eda1bd43ceb760f2e26ee8515e",
      "value": 248047
     }
    },
    "f2be2d3551ad406e9f56cabd5c07fee6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f2bf38d48c8141bca58806d4d4b781eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5a13f99464b46ad93a4ba53c03a6bc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f863635ea3474dc697f698fcd80aeb2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9dca32ff2034723a27234c65831f250": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "faf93418916648688fa1ccd2a04ce4f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3bdba093eef54e5a97c4e601a1e93345",
       "IPY_MODEL_94ae206a4a0b438a874e656fe89cc103"
      ],
      "layout": "IPY_MODEL_0c35f97ff67f46028bf7db0153978d1b"
     }
    },
    "ffb467ff52bf4c94921575a7afceb2bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
