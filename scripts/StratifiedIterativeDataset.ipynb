{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Orb2eLYb_yO",
    "outputId": "a7536982-665c-44da-efc8-2a2dc1b1a1c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0aVDLvRV6NI",
    "outputId": "50c3f392-232a-46ea-e245-b16d976bd0c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2MB 1.8MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2020.11.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Installing collected packages: gensim\n",
      "  Found existing installation: gensim 3.6.0\n",
      "    Uninstalling gensim-3.6.0:\n",
      "      Successfully uninstalled gensim-3.6.0\n",
      "Successfully installed gensim-3.8.3\n",
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 4.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Collecting sentencepiece==0.1.91\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 13.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 15.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Collecting tokenizers==0.9.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 27.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=16d1442fd2f5be24353bd2c435976a8ec626fe7ce9a5bebf28aed66697529396\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n",
      "Collecting sentence-transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/5a/6e41e8383913dd2ba923cdcd02be2e03911595f4d2f9de559ecbed80d2d3/sentence-transformers-0.3.9.tar.gz (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 3.4MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: transformers<3.6.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.7.0+cu101)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (0.8)\n",
      "Requirement already satisfied, skipping upgrade: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (3.12.4)\n",
      "Requirement already satisfied, skipping upgrade: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (0.1.91)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (0.9.3)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<3.6.0,>=3.1.0->sentence-transformers) (50.3.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (2020.11.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.6.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.6.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.9-cp36-none-any.whl size=101036 sha256=10a06f28f5ec226dea24916cc81eabb199f5b2561bd2b2d077f09c62e966c658\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/89/43/f2f5bc00b03ef9724b0f6254a97eaf159a4c4ddc024b33e07a\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-0.3.9\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim\n",
    "!pip install transformers\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OcoVA1wTNwz",
    "outputId": "44b40b33-66a5-4472-d02a-84968e0dff21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, f1_score, roc_auc_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, FeatureExtractionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAWH2vr1Rj15",
    "outputId": "b3e22a6d-7319-43da-905f-88435e4f149a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'Diagnoses', 'Special Education Teacher Perceptions',\n",
       "       'Psychological Perceptions', 'Medical Perceptions',\n",
       "       'Speech Therapist Perceptions', 'Written Strategies',\n",
       "       'Encoded Strategies'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_strats = pd.read_csv('gdrive/My Drive/magister/anonimized_dataset.csv')\n",
    "columns = students_strats.columns\n",
    "for var in columns:\n",
    "    if var != 'Diagnoses' and var != 'Index':\n",
    "        students_strats[var] = students_strats[var].apply(ast.literal_eval)\n",
    "students_strats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3nCeNfxMhoJ"
   },
   "outputs": [],
   "source": [
    "joined_perceptions = []\n",
    "joined_set_perceptions = []\n",
    "joined_st_perceptions = []\n",
    "joined_p_perceptions = []\n",
    "joined_m_perceptions = []\n",
    "\n",
    "amount_set_perceptions = []\n",
    "amount_st_perceptions = []\n",
    "amount_p_perceptions = []\n",
    "amount_m_perceptions = []\n",
    "\n",
    "has_set = []\n",
    "has_st = []\n",
    "has_p = []\n",
    "has_m = []\n",
    "\n",
    "for index in students_strats['Index']:\n",
    "  text = \"\"\n",
    "  \n",
    "  set_text = \"\"\n",
    "  st_text = \"\"\n",
    "  p_text = \"\"\n",
    "  m_text = \"\"\n",
    "  \n",
    "  amount_set = 0\n",
    "  for perception in students_strats['Special Education Teacher Perceptions'][index]:\n",
    "    text += perception + \" \"\n",
    "    set_text += perception + \" \"\n",
    "    amount_set += 1\n",
    "\n",
    "  amount_st = 0\n",
    "  for perception in students_strats['Speech Therapist Perceptions'][index]:\n",
    "    text += perception + \" \"\n",
    "    st_text += perception + \" \"\n",
    "    amount_st += 1\n",
    "\n",
    "  amount_p = 0\n",
    "  for perception in students_strats['Psychological Perceptions'][index]:\n",
    "    text += perception + \" \"\n",
    "    p_text += perception + \" \"\n",
    "    amount_p += 1\n",
    "\n",
    "  amount_m = 0\n",
    "  for perception in students_strats['Medical Perceptions'][index]:\n",
    "    text += perception + \" \"\n",
    "    m_text += perception + \" \"\n",
    "    amount_m += 1\n",
    "\n",
    "  joined_perceptions.append(text)\n",
    "\n",
    "  joined_set_perceptions.append(set_text)\n",
    "  joined_st_perceptions.append(st_text)\n",
    "  joined_p_perceptions.append(p_text)\n",
    "  joined_m_perceptions.append(m_text)\n",
    "\n",
    "  amount_set_perceptions.append(amount_set)\n",
    "  amount_st_perceptions.append(amount_st)\n",
    "  amount_p_perceptions.append(amount_p)\n",
    "  amount_m_perceptions.append(amount_m)\n",
    "\n",
    "  has_set.append(1 if amount_set > 0 else 0)\n",
    "  has_st.append(1 if amount_st > 0 else 0)\n",
    "  has_p.append(1 if amount_p > 0 else 0)\n",
    "  has_m.append(1 if amount_m > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KxW0v4bN3AE"
   },
   "outputs": [],
   "source": [
    "categories_number_words = {\n",
    "        1: \"Apoyo Pedagógico en asignaturas\",\n",
    "        3: \"Apoyo pedagógico personal\",\n",
    "        4: \"Tutoría entre pares\",\n",
    "        7: \"Hacer a la familia partícipe del proceso\",\n",
    "        8: \"Apoyo psicóloga(o)\",\n",
    "        9: \"Apoyo fonoaudióloga(o)\",\n",
    "        10: \"Apoyo Educador(a) Diferencial\",\n",
    "        11: \"Apoyo Kinesióloga(o)\",\n",
    "        12: \"Apoyo Médico General\",\n",
    "        13: \"Apoyo Terapeuta Ocupacional\",\n",
    "        14: \"Control Neurólogo\",\n",
    "        15: \"Apoyo Interdisciplinario\",\n",
    "        16: \"Adecuación curricular de acceso\",\n",
    "        17: \"Adecuación curricular de objetivos\"\n",
    "    }\n",
    "categories_words_number = {v: k for k, v in categories_number_words.items()}\n",
    "\n",
    "diagnoses_codes = {\n",
    "    \"Trastorno específico del lenguaje\": 0,\n",
    "    \"Trastorno por déficit atencional\": 1,\n",
    "    \"Dificultad específica de aprendizaje\": 2,\n",
    "    \"Discapacidad intelectual\": 3,\n",
    "    \"Discapacidad visual\": 4,\n",
    "    \"Trastorno del espectro autista\": 5,\n",
    "    \"Discapacidad auditiva - Hipoacusia\": 6,\n",
    "    \"Funcionamiento intelectual limítrofe\": 7,\n",
    "    \"Síndrome de Down\": 8,\n",
    "    \"Trastorno motor\": 9,\n",
    "    \"Multidéficit\": 10,\n",
    "    \"Retraso global del desarrollo\": 11\n",
    "}\n",
    "\n",
    "strat_present = {\n",
    "    strat: [] for strat in list(categories_words_number.keys())\n",
    "}\n",
    "diag_codes = []\n",
    "for index in students_strats['Index']:\n",
    "  diag = students_strats['Diagnoses'][index]\n",
    "  diag_codes.append(diagnoses_codes[diag])\n",
    "  for strat_number in categories_number_words:\n",
    "    if strat_number in students_strats['Encoded Strategies'][index]:\n",
    "      strat_present[categories_number_words[strat_number]].append(1)\n",
    "    else:\n",
    "      strat_present[categories_number_words[strat_number]].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gytoAKKDLXM8"
   },
   "outputs": [],
   "source": [
    "new_dataset_to_export = {\n",
    "    'Encoded Diagnosis': diag_codes,\n",
    "    'Diagnosis': students_strats['Diagnoses'],\n",
    "    'All perceptions': joined_perceptions,\n",
    "    'Special Education Teacher Perceptions': joined_set_perceptions,\n",
    "    'Speech Therapist Perceptions': joined_st_perceptions,\n",
    "    'Psychologist Perceptions': joined_p_perceptions,\n",
    "    'Medical Perceptions': joined_m_perceptions,\n",
    "    'Amount of SET perceptions': amount_set_perceptions,\n",
    "    'Amount of ST perceptions': amount_st_perceptions,\n",
    "    'Amount of P perceptions': amount_p_perceptions,\n",
    "    'Amount of M perceptions': amount_m_perceptions,\n",
    "    'Has SET perceptions': has_set,\n",
    "    'Has ST perceptions': has_st,\n",
    "    'Has P perceptions': has_p,\n",
    "    'Has M perceptions': has_m,\n",
    "}\n",
    "x_keys = list(new_dataset_to_export.keys())\n",
    "new_dataset_to_export.update(strat_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uN-rTL91SpDf",
    "outputId": "e8b55905-b215-45e2-e968-b5f4adafe839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Diagnosis 3035\n",
      "Diagnosis 3035\n",
      "All perceptions 3035\n",
      "Special Education Teacher Perceptions 3035\n",
      "Speech Therapist Perceptions 3035\n",
      "Psychologist Perceptions 3035\n",
      "Medical Perceptions 3035\n",
      "Amount of SET perceptions 3035\n",
      "Amount of ST perceptions 3035\n",
      "Amount of P perceptions 3035\n",
      "Amount of M perceptions 3035\n",
      "Has SET perceptions 3035\n",
      "Has ST perceptions 3035\n",
      "Has P perceptions 3035\n",
      "Has M perceptions 3035\n",
      "Apoyo Pedagógico en asignaturas 3035\n",
      "Apoyo pedagógico personal 3035\n",
      "Tutoría entre pares 3035\n",
      "Hacer a la familia partícipe del proceso 3035\n",
      "Apoyo psicóloga(o) 3035\n",
      "Apoyo fonoaudióloga(o) 3035\n",
      "Apoyo Educador(a) Diferencial 3035\n",
      "Apoyo Kinesióloga(o) 3035\n",
      "Apoyo Médico General 3035\n",
      "Apoyo Terapeuta Ocupacional 3035\n",
      "Control Neurólogo 3035\n",
      "Apoyo Interdisciplinario 3035\n",
      "Adecuación curricular de acceso 3035\n",
      "Adecuación curricular de objetivos 3035\n"
     ]
    }
   ],
   "source": [
    "for key in new_dataset_to_export:\n",
    "  print(key, len(new_dataset_to_export[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKl49oD67ApW"
   },
   "outputs": [],
   "source": [
    "y_keys = list(strat_present.keys())\n",
    "df = pd.DataFrame(data=new_dataset_to_export)\n",
    "X = df\n",
    "Y = df[y_keys]\n",
    "strats_amounts = {\n",
    "              'Adecuación curricular de acceso': 2264,\n",
    "              'Hacer a la familia partícipe del proceso': 2048,\n",
    "              'Apoyo Interdisciplinario': 1441, \n",
    "              'Apoyo Educador(a) Diferencial': 1311,\n",
    "              'Apoyo pedagógico personal': 1240,\n",
    "              'Apoyo fonoaudióloga(o)': 378,\n",
    "              'Apoyo psicóloga(o)': 588,\n",
    "              'Apoyo Terapeuta Ocupacional': 153,\n",
    "              'Tutoría entre pares': 350,\n",
    "              'Control Neurólogo': 63,\n",
    "              'Apoyo Médico General': 64,\n",
    "              'Apoyo Kinesióloga(o)': 32,\n",
    "              'Adecuación curricular de objetivos': 281,\n",
    "              'Apoyo Pedagógico en asignaturas': 1314\n",
    "}\n",
    "most_unbalanced_strategies = [strategy for strategy in y_keys if (strats_amounts[strategy] < len(X)*0.15 or strats_amounts[strategy] > len(X)*0.85)]\n",
    "less_unbalanced_strategies = [strategy for strategy in y_keys if strategy not in most_unbalanced_strategies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jW-o5ARW2KR"
   },
   "outputs": [],
   "source": [
    "def iterative_stratification(X, y_labels, train_d, val_d, test_d):\n",
    "  train_partition = pd.DataFrame(columns=X.columns)\n",
    "  val_partition = pd.DataFrame(columns=X.columns)\n",
    "  test_partition = pd.DataFrame(columns=X.columns)\n",
    "\n",
    "  train_examples = X.shape[0]*train_d\n",
    "  val_examples = X.shape[0]*val_d\n",
    "  test_examples = X.shape[0]*test_d\n",
    "\n",
    "  train_examples_per_label = {}\n",
    "  val_examples_per_label = {}\n",
    "  test_examples_per_label = {}\n",
    "  for label in y_labels:\n",
    "    number_of_occurrences = X[label].value_counts()[1]\n",
    "    train_examples_per_label[label] = number_of_occurrences*train_d\n",
    "    val_examples_per_label[label] = number_of_occurrences*val_d\n",
    "    test_examples_per_label[label] = number_of_occurrences*test_d\n",
    "\n",
    "  while X.shape[0] > 0:\n",
    "    print(X.shape[0])\n",
    "\n",
    "    min_occurs = 999999999\n",
    "    min_label = None\n",
    "    for label in y_labels:\n",
    "      if 1 in X[label].value_counts():\n",
    "        occs = X[label].value_counts()[1]\n",
    "        if occs < min_occurs:\n",
    "          min_occurs = occs\n",
    "          min_label = label\n",
    "    min_label_dataset = X[X[min_label]==1]\n",
    "    print(min_label)\n",
    "\n",
    "    for index, row in min_label_dataset.iterrows():\n",
    "      if ((train_examples_per_label[min_label] > val_examples_per_label[min_label] \n",
    "          and train_examples_per_label[min_label] > test_examples_per_label[min_label]) or\n",
    "          (train_examples_per_label[min_label] > val_examples_per_label[min_label] \n",
    "          and train_examples_per_label[min_label] == test_examples_per_label[min_label]) or\n",
    "          (train_examples_per_label[min_label] == val_examples_per_label[min_label] \n",
    "          and train_examples_per_label[min_label] > test_examples_per_label[min_label])):\n",
    "        train_partition = train_partition.append(row, ignore_index=True)\n",
    "        X = X.drop(index)\n",
    "        for label in y_labels:\n",
    "          if row[label] == 1:\n",
    "            train_examples_per_label[label] = train_examples_per_label[label] - 1\n",
    "        train_examples -= 1\n",
    "\n",
    "      elif ((val_examples_per_label[min_label] > train_examples_per_label[min_label] \n",
    "          and val_examples_per_label[min_label] > test_examples_per_label[min_label]) or\n",
    "          (val_examples_per_label[min_label] > train_examples_per_label[min_label] \n",
    "          and val_examples_per_label[min_label] == test_examples_per_label[min_label])):\n",
    "        val_partition = val_partition.append(row, ignore_index=True)\n",
    "        X = X.drop(index)\n",
    "        for label in y_labels:\n",
    "          if row[label] == 1:\n",
    "            val_examples_per_label[label] = val_examples_per_label[label] - 1\n",
    "        val_examples -= 1\n",
    "\n",
    "      else:\n",
    "        test_partition = test_partition.append(row, ignore_index=True)\n",
    "        X = X.drop(index)\n",
    "        for label in y_labels:\n",
    "          if row[label] == 1:\n",
    "            test_examples_per_label[label] = test_examples_per_label[label] - 1\n",
    "        test_examples -= 1\n",
    "\n",
    "  return train_partition, val_partition, test_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKGYZyP3sLnh",
    "outputId": "192ecf2e-33e1-4891-da66-8003795afb32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035\n",
      "Apoyo Kinesióloga(o)\n",
      "3003\n",
      "Control Neurólogo\n",
      "2942\n",
      "Apoyo Médico General\n",
      "2883\n",
      "Apoyo Terapeuta Ocupacional\n",
      "2757\n",
      "Adecuación curricular de objetivos\n",
      "2494\n",
      "Tutoría entre pares\n",
      "2214\n",
      "Apoyo fonoaudióloga(o)\n",
      "1914\n",
      "Apoyo psicóloga(o)\n",
      "1516\n",
      "Apoyo pedagógico personal\n",
      "869\n",
      "Apoyo Educador(a) Diferencial\n",
      "491\n",
      "Apoyo Pedagógico en asignaturas\n",
      "336\n",
      "Apoyo Interdisciplinario\n",
      "188\n",
      "Hacer a la familia partícipe del proceso\n",
      "23\n",
      "Adecuación curricular de acceso\n"
     ]
    }
   ],
   "source": [
    "train, val, test = iterative_stratification(X, y_keys, 0.6, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5rYKm7DGyx0a",
    "outputId": "65daddb6-5333-4aa4-d444-6ab017cafbc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1836, 29)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "id": "YZA6Z3VgzArz",
    "outputId": "c66b2b3d-9699-42e1-b0ea-488a720e44ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encoded Diagnosis</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>All perceptions</th>\n",
       "      <th>Special Education Teacher Perceptions</th>\n",
       "      <th>Speech Therapist Perceptions</th>\n",
       "      <th>Psychologist Perceptions</th>\n",
       "      <th>Medical Perceptions</th>\n",
       "      <th>Amount of SET perceptions</th>\n",
       "      <th>Amount of ST perceptions</th>\n",
       "      <th>Amount of P perceptions</th>\n",
       "      <th>Amount of M perceptions</th>\n",
       "      <th>Has SET perceptions</th>\n",
       "      <th>Has ST perceptions</th>\n",
       "      <th>Has P perceptions</th>\n",
       "      <th>Has M perceptions</th>\n",
       "      <th>Apoyo Pedagógico en asignaturas</th>\n",
       "      <th>Apoyo pedagógico personal</th>\n",
       "      <th>Tutoría entre pares</th>\n",
       "      <th>Hacer a la familia partícipe del proceso</th>\n",
       "      <th>Apoyo psicóloga(o)</th>\n",
       "      <th>Apoyo fonoaudióloga(o)</th>\n",
       "      <th>Apoyo Educador(a) Diferencial</th>\n",
       "      <th>Apoyo Kinesióloga(o)</th>\n",
       "      <th>Apoyo Médico General</th>\n",
       "      <th>Apoyo Terapeuta Ocupacional</th>\n",
       "      <th>Control Neurólogo</th>\n",
       "      <th>Apoyo Interdisciplinario</th>\n",
       "      <th>Adecuación curricular de acceso</th>\n",
       "      <th>Adecuación curricular de objetivos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Discapacidad intelectual</td>\n",
       "      <td>En cuanto a Lenguaje y Comunicacion, [ESTUDIAN...</td>\n",
       "      <td>En cuanto a Lenguaje y Comunicacion, [ESTUDIAN...</td>\n",
       "      <td></td>\n",
       "      <td>-Establece relaciones sociales principalmente ...</td>\n",
       "      <td>Estudiante con atenciones medicas debido a su ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Discapacidad intelectual</td>\n",
       "      <td>En cuanto a Lenguaje y Comunicacion, [ESTUDIAN...</td>\n",
       "      <td>En cuanto a Lenguaje y Comunicacion, [ESTUDIAN...</td>\n",
       "      <td></td>\n",
       "      <td>-Establece relaciones sociales principalmente ...</td>\n",
       "      <td>-Estudiante con atenciones medicas debido a su...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Discapacidad intelectual</td>\n",
       "      <td>Habilidades (Cognitivas, comunicativas, social...</td>\n",
       "      <td>Habilidades (Cognitivas, comunicativas, social...</td>\n",
       "      <td></td>\n",
       "      <td>Comunica sus deseos y emociones de manera mas ...</td>\n",
       "      <td>Controles periodicos al dia. Equipo multidisci...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Discapacidad intelectual</td>\n",
       "      <td>scar, no presenta dificultades en el desarroll...</td>\n",
       "      <td>scar, no presenta dificultades en el desarroll...</td>\n",
       "      <td></td>\n",
       "      <td>[ESTUDIANTE], es un niño entusiasta y colabora...</td>\n",
       "      <td>Estudiante con un estado sano de salud, pero c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Trastorno motor</td>\n",
       "      <td>En [ESTUDIANTE] se evidencia preferencia por e...</td>\n",
       "      <td>En [ESTUDIANTE] se evidencia preferencia por e...</td>\n",
       "      <td></td>\n",
       "      <td>Estudiante cariñoso y respetuoso con sus compa...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Encoded Diagnosis  ... Adecuación curricular de objetivos\n",
       "0                 3  ...                                  0\n",
       "1                 3  ...                                  0\n",
       "2                 3  ...                                  0\n",
       "3                 3  ...                                  0\n",
       "4                 9  ...                                  0\n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fl_mBkJly2Xq",
    "outputId": "74f5648e-6035-4242-c08d-f98bc705d5bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 29)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acPziRRPy6ON",
    "outputId": "83a03f93-969f-428e-b5e8-6321d6f419ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607, 29)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxoaU4fh6r64"
   },
   "outputs": [],
   "source": [
    "train.to_csv('train_ds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFimqvsd-FXT"
   },
   "outputs": [],
   "source": [
    "test.to_csv('test_ds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2blclYW-KT-"
   },
   "outputs": [],
   "source": [
    "val.to_csv('val_ds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUQVJbSm-5wo",
    "outputId": "358dbc45-d921-41ea-89d7-bf84d594d600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apoyo Pedagógico en asignaturas\n",
      "788 263 263\n",
      "Apoyo pedagógico personal\n",
      "744 248 248\n",
      "Tutoría entre pares\n",
      "210 70 70\n",
      "Hacer a la familia partícipe del proceso\n",
      "1229 410 409\n",
      "Apoyo psicóloga(o)\n",
      "353 118 117\n",
      "Apoyo fonoaudióloga(o)\n",
      "227 76 75\n",
      "Apoyo Educador(a) Diferencial\n",
      "786 262 262\n",
      "Apoyo Kinesióloga(o)\n",
      "19 7 6\n",
      "Apoyo Médico General\n",
      "38 13 12\n",
      "Apoyo Terapeuta Ocupacional\n",
      "91 31 30\n",
      "Control Neurólogo\n",
      "38 13 12\n",
      "Apoyo Interdisciplinario\n",
      "865 288 288\n",
      "Adecuación curricular de acceso\n",
      "1333 474 455\n",
      "Adecuación curricular de objetivos\n",
      "169 56 56\n"
     ]
    }
   ],
   "source": [
    "for strat in y_keys:\n",
    "  print(strat)\n",
    "  print(train[strat].value_counts()[1], val[strat].value_counts()[1], test[strat].value_counts()[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "StratifiedIterativeDataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
