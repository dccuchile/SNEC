{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Orb2eLYb_yO",
    "outputId": "b0758468-b7b5-4452-ec5f-06e0f484acf2"
   },
   "outputs": [],
   "source": [
    "# Mount drive connection if required\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "id": "z0aVDLvRV6NI",
    "outputId": "8a7294cc-b26b-461e-d51e-ab8bc075b548"
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install --upgrade gensim\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OcoVA1wTNwz",
    "outputId": "58d642af-7c47-4dcf-b747-140c518271cc"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, f1_score, roc_auc_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, FeatureExtractionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMgf1hFH-wCr"
   },
   "source": [
    "## Cosas BETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWUPVHlljf43"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n",
    "model = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n",
    "model.eval()\n",
    "BETO_features = FeatureExtractionPipeline(model, tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXRnCc5Pegy2"
   },
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daW8jCneDpK3"
   },
   "outputs": [],
   "source": [
    "# Interventions code - label dictionary\n",
    "categories_number_words = {\n",
    "        1: \"Apoyo Pedagógico en asignaturas\",\n",
    "        3: \"Apoyo pedagógico personal\",\n",
    "        4: \"Tutoría entre pares\",\n",
    "        7: \"Hacer a la familia partícipe del proceso\",\n",
    "        8: \"Apoyo psicóloga(o)\",\n",
    "        9: \"Apoyo fonoaudióloga(o)\",\n",
    "        10: \"Apoyo Educador(a) Diferencial\",\n",
    "        11: \"Apoyo Kinesióloga(o)\",\n",
    "        12: \"Apoyo Médico General\",\n",
    "        13: \"Apoyo Terapeuta Ocupacional\",\n",
    "        14: \"Control Neurólogo\",\n",
    "        15: \"Apoyo Interdisciplinario\",\n",
    "        16: \"Adecuación curricular de acceso\",\n",
    "        17: \"Adecuación curricular de objetivos\"\n",
    "    }\n",
    "# Inverse above dictionary\n",
    "categories_words_number = {v: k for k, v in categories_number_words.items()}\n",
    "\n",
    "# Diagnoses label - code dictionary\n",
    "diagnoses_codes = {\n",
    "    \"Trastorno específico del lenguaje\": 0,\n",
    "    \"Trastorno por déficit atencional\": 1,\n",
    "    \"Dificultad específica de aprendizaje\": 2,\n",
    "    \"Discapacidad intelectual\": 3,\n",
    "    \"Discapacidad visual\": 4,\n",
    "    \"Trastorno del espectro autista\": 5,\n",
    "    \"Discapacidad auditiva - Hipoacusia\": 6,\n",
    "    \"Funcionamiento intelectual limítrofe\": 7,\n",
    "    \"Síndrome de Down\": 8,\n",
    "    \"Trastorno motor\": 9,\n",
    "    \"Multidéficit\": 10,\n",
    "    \"Retraso global del desarrollo\": 11\n",
    "}\n",
    "stopwords = set(nltk.corpus.stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yphNKf9AsBE"
   },
   "source": [
    "### Datasets preseparados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmmX--YS_Sf7"
   },
   "outputs": [],
   "source": [
    "# Datasets built with Stratified iterative algorithm\n",
    "train_dataset = pd.read_csv('gdrive/My Drive/magister/train_ds.csv', keep_default_na=False)\n",
    "val_dataset = pd.read_csv('gdrive/My Drive/magister/val_ds.csv', keep_default_na=False)\n",
    "test_dataset = pd.read_csv('gdrive/My Drive/magister/test_ds.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJQwRwNTIqyd",
    "outputId": "cb13e29e-3afb-46d4-b6b8-d99929ed71a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1836, 29)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "id": "pSL2yxz5JIdW",
    "outputId": "eefb96cd-7856-4c43-97db-53b2d2e35913"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encoded Diagnosis</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>All perceptions</th>\n",
       "      <th>Special Education Teacher Perceptions</th>\n",
       "      <th>Speech Therapist Perceptions</th>\n",
       "      <th>Psychologist Perceptions</th>\n",
       "      <th>Medical Perceptions</th>\n",
       "      <th>Amount of SET perceptions</th>\n",
       "      <th>Amount of ST perceptions</th>\n",
       "      <th>Amount of P perceptions</th>\n",
       "      <th>Amount of M perceptions</th>\n",
       "      <th>Has SET perceptions</th>\n",
       "      <th>Has ST perceptions</th>\n",
       "      <th>Has P perceptions</th>\n",
       "      <th>Has M perceptions</th>\n",
       "      <th>Apoyo Pedagógico en asignaturas</th>\n",
       "      <th>Apoyo pedagógico personal</th>\n",
       "      <th>Tutoría entre pares</th>\n",
       "      <th>Hacer a la familia partícipe del proceso</th>\n",
       "      <th>Apoyo psicóloga(o)</th>\n",
       "      <th>Apoyo fonoaudióloga(o)</th>\n",
       "      <th>Apoyo Educador(a) Diferencial</th>\n",
       "      <th>Apoyo Kinesióloga(o)</th>\n",
       "      <th>Apoyo Médico General</th>\n",
       "      <th>Apoyo Terapeuta Ocupacional</th>\n",
       "      <th>Control Neurólogo</th>\n",
       "      <th>Apoyo Interdisciplinario</th>\n",
       "      <th>Adecuación curricular de acceso</th>\n",
       "      <th>Adecuación curricular de objetivos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Discapacidad intelectual</td>\n",
       "      <td>En cuanto a Lenguaje y Comunicacion, [ESTUDIAN...</td>\n",
       "      <td>En cuanto a Lenguaje y Comunicacion, [ESTUDIAN...</td>\n",
       "      <td></td>\n",
       "      <td>-Establece relaciones sociales principalmente ...</td>\n",
       "      <td>Estudiante con atenciones medicas debido a su ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Discapacidad intelectual</td>\n",
       "      <td>En cuanto a Lenguaje y Comunicacion, [ESTUDIAN...</td>\n",
       "      <td>En cuanto a Lenguaje y Comunicacion, [ESTUDIAN...</td>\n",
       "      <td></td>\n",
       "      <td>-Establece relaciones sociales principalmente ...</td>\n",
       "      <td>-Estudiante con atenciones medicas debido a su...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Discapacidad intelectual</td>\n",
       "      <td>Habilidades (Cognitivas, comunicativas, social...</td>\n",
       "      <td>Habilidades (Cognitivas, comunicativas, social...</td>\n",
       "      <td></td>\n",
       "      <td>Comunica sus deseos y emociones de manera mas ...</td>\n",
       "      <td>Controles periodicos al dia. Equipo multidisci...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Discapacidad intelectual</td>\n",
       "      <td>scar, no presenta dificultades en el desarroll...</td>\n",
       "      <td>scar, no presenta dificultades en el desarroll...</td>\n",
       "      <td></td>\n",
       "      <td>[ESTUDIANTE], es un niño entusiasta y colabora...</td>\n",
       "      <td>Estudiante con un estado sano de salud, pero c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Trastorno motor</td>\n",
       "      <td>En [ESTUDIANTE] se evidencia preferencia por e...</td>\n",
       "      <td>En [ESTUDIANTE] se evidencia preferencia por e...</td>\n",
       "      <td></td>\n",
       "      <td>Estudiante cariñoso y respetuoso con sus compa...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Encoded Diagnosis  ... Adecuación curricular de objetivos\n",
       "0                  3  ...                                  0\n",
       "1                  3  ...                                  0\n",
       "2                  3  ...                                  0\n",
       "3                  3  ...                                  0\n",
       "4                  9  ...                                  0\n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYt8D0PFAxw0"
   },
   "source": [
    "### Datasets creados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAWH2vr1Rj15",
    "outputId": "020137a9-7929-4ecc-d5f3-c07744947b74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'Diagnoses', 'Special Education Teacher Perceptions',\n",
       "       'Psychological Perceptions', 'Medical Perceptions',\n",
       "       'Speech Therapist Perceptions', 'Written Strategies',\n",
       "       'Encoded Strategies'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not stratified dataset\n",
    "students_strats = pd.read_csv('gdrive/My Drive/magister/anonimized_dataset.csv')\n",
    "columns = students_strats.columns\n",
    "for var in columns:\n",
    "    if var != 'Diagnoses' and var != 'Index':\n",
    "        students_strats[var] = students_strats[var].apply(ast.literal_eval)\n",
    "students_strats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3nCeNfxMhoJ"
   },
   "outputs": [],
   "source": [
    "# Building features arrays for not stratified dataset\n",
    "\n",
    "joined_perceptions = []\n",
    "joined_set_perceptions = []\n",
    "joined_st_perceptions = []\n",
    "joined_p_perceptions = []\n",
    "joined_m_perceptions = []\n",
    "\n",
    "amount_set_perceptions = []\n",
    "amount_st_perceptions = []\n",
    "amount_p_perceptions = []\n",
    "amount_m_perceptions = []\n",
    "\n",
    "has_set = []\n",
    "has_st = []\n",
    "has_p = []\n",
    "has_m = []\n",
    "\n",
    "for index in students_strats['Index']:\n",
    "  text = \"\"\n",
    "  \n",
    "  set_text = \"\"\n",
    "  st_text = \"\"\n",
    "  p_text = \"\"\n",
    "  m_text = \"\"\n",
    "  \n",
    "  amount_set = 0\n",
    "  for perception in students_strats['Special Education Teacher Perceptions'][index]:\n",
    "    text += perception + \" \"\n",
    "    set_text += perception + \" \"\n",
    "    amount_set += 1\n",
    "\n",
    "  amount_st = 0\n",
    "  for perception in students_strats['Speech Therapist Perceptions'][index]:\n",
    "    text += perception + \" \"\n",
    "    st_text += perception + \" \"\n",
    "    amount_st += 1\n",
    "\n",
    "  amount_p = 0\n",
    "  for perception in students_strats['Psychological Perceptions'][index]:\n",
    "    text += perception + \" \"\n",
    "    p_text += perception + \" \"\n",
    "    amount_p += 1\n",
    "\n",
    "  amount_m = 0\n",
    "  for perception in students_strats['Medical Perceptions'][index]:\n",
    "    text += perception + \" \"\n",
    "    m_text += perception + \" \"\n",
    "    amount_m += 1\n",
    "\n",
    "  joined_perceptions.append(text)\n",
    "\n",
    "  joined_set_perceptions.append(set_text)\n",
    "  joined_st_perceptions.append(st_text)\n",
    "  joined_p_perceptions.append(p_text)\n",
    "  joined_m_perceptions.append(m_text)\n",
    "\n",
    "  amount_set_perceptions.append(amount_set)\n",
    "  amount_st_perceptions.append(amount_st)\n",
    "  amount_p_perceptions.append(amount_p)\n",
    "  amount_m_perceptions.append(amount_m)\n",
    "\n",
    "  has_set.append(1 if amount_set > 0 else 0)\n",
    "  has_st.append(1 if amount_st > 0 else 0)\n",
    "  has_p.append(1 if amount_p > 0 else 0)\n",
    "  has_m.append(1 if amount_m > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5X5zPg8MQbC",
    "outputId": "f7556574-d442-495d-8f28-936cb91b62a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(has_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KxW0v4bN3AE"
   },
   "outputs": [],
   "source": [
    "strat_present = {\n",
    "    strat: [] for strat in list(categories_words_number.keys())\n",
    "}\n",
    "\n",
    "diag_codes = []\n",
    "for index in students_strats['Index']:\n",
    "  diag = students_strats['Diagnoses'][index]\n",
    "  diag_codes.append(diagnoses_codes[diag])\n",
    "  for strat_number in categories_number_words:\n",
    "    if strat_number in students_strats['Encoded Strategies'][index]:\n",
    "      strat_present[categories_number_words[strat_number]].append(1)\n",
    "    else:\n",
    "      strat_present[categories_number_words[strat_number]].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gytoAKKDLXM8"
   },
   "outputs": [],
   "source": [
    "new_dataset_to_export = {\n",
    "    'Encoded Diagnosis': diag_codes,\n",
    "    'Diagnosis': students_strats['Diagnoses'],\n",
    "    'All perceptions': joined_perceptions,\n",
    "    'Special Education Teacher Perceptions': joined_set_perceptions,\n",
    "    'Speech Therapist Perceptions': joined_st_perceptions,\n",
    "    'Psychologist Perceptions': joined_p_perceptions,\n",
    "    'Medical Perceptions': joined_m_perceptions,\n",
    "    'Amount of SET perceptions': amount_set_perceptions,\n",
    "    'Amount of ST perceptions': amount_st_perceptions,\n",
    "    'Amount of P perceptions': amount_p_perceptions,\n",
    "    'Amount of M perceptions': amount_m_perceptions,\n",
    "    'Has SET perceptions': has_set,\n",
    "    'Has ST perceptions': has_st,\n",
    "    'Has P perceptions': has_p,\n",
    "    'Has M perceptions': has_m,\n",
    "}\n",
    "x_keys = list(new_dataset_to_export.keys())\n",
    "new_dataset_to_export.update(strat_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uN-rTL91SpDf",
    "outputId": "19d7d795-a1e4-4596-8b9b-7564c56c1ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Diagnosis 3035\n",
      "Diagnosis 3035\n",
      "All perceptions 3035\n",
      "Special Education Teacher Perceptions 3035\n",
      "Speech Therapist Perceptions 3035\n",
      "Psychologist Perceptions 3035\n",
      "Medical Perceptions 3035\n",
      "Amount of SET perceptions 3035\n",
      "Amount of ST perceptions 3035\n",
      "Amount of P perceptions 3035\n",
      "Amount of M perceptions 3035\n",
      "Has SET perceptions 3035\n",
      "Has ST perceptions 3035\n",
      "Has P perceptions 3035\n",
      "Has M perceptions 3035\n",
      "Apoyo Pedagógico en asignaturas 3035\n",
      "Apoyo pedagógico personal 3035\n",
      "Tutoría entre pares 3035\n",
      "Hacer a la familia partícipe del proceso 3035\n",
      "Apoyo psicóloga(o) 3035\n",
      "Apoyo fonoaudióloga(o) 3035\n",
      "Apoyo Educador(a) Diferencial 3035\n",
      "Apoyo Kinesióloga(o) 3035\n",
      "Apoyo Médico General 3035\n",
      "Apoyo Terapeuta Ocupacional 3035\n",
      "Control Neurólogo 3035\n",
      "Apoyo Interdisciplinario 3035\n",
      "Adecuación curricular de acceso 3035\n",
      "Adecuación curricular de objetivos 3035\n"
     ]
    }
   ],
   "source": [
    "for key in new_dataset_to_export:\n",
    "  print(key, len(new_dataset_to_export[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixUpVQAIDwEy"
   },
   "source": [
    "## Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKl49oD67ApW"
   },
   "outputs": [],
   "source": [
    "y_keys = list(categories_words_number.keys())\n",
    "# df = pd.DataFrame(data=new_dataset_to_export)\n",
    "# X = df\n",
    "# Y = df[y_keys]\n",
    "X_train = train_dataset.drop(y_keys, axis=1)\n",
    "Y_train = train_dataset[y_keys]\n",
    "X_val = val_dataset.drop(y_keys, axis=1)\n",
    "Y_val = val_dataset[y_keys]\n",
    "X_test = test_dataset.drop(y_keys, axis=1)\n",
    "Y_test = test_dataset[y_keys]\n",
    "strats_amounts = {\n",
    "              'Adecuación curricular de acceso': 2264,\n",
    "              'Hacer a la familia partícipe del proceso': 2048,\n",
    "              'Apoyo Interdisciplinario': 1441, \n",
    "              'Apoyo Educador(a) Diferencial': 1311,\n",
    "              'Apoyo pedagógico personal': 1240,\n",
    "              'Apoyo fonoaudióloga(o)': 378,\n",
    "              'Apoyo psicóloga(o)': 588,\n",
    "              'Apoyo Terapeuta Ocupacional': 153,\n",
    "              'Tutoría entre pares': 350,\n",
    "              'Control Neurólogo': 63,\n",
    "              'Apoyo Médico General': 64,\n",
    "              'Apoyo Kinesióloga(o)': 32,\n",
    "              'Adecuación curricular de objetivos': 281,\n",
    "              'Apoyo Pedagógico en asignaturas': 1314\n",
    "}\n",
    "# most_unbalanced_strategies = [strategy for strategy in y_keys if (strats_amounts[strategy] < len(X)*0.15 or strats_amounts[strategy] > len(X)*0.85)]\n",
    "# less_unbalanced_strategies = [strategy for strategy in y_keys if strategy not in most_unbalanced_strategies]\n",
    "most_unbalanced_strategies = [strategy for strategy in y_keys if (strats_amounts[strategy] < (len(X_train)+len(X_val)+len(X_test))*0.15 or strats_amounts[strategy] > (len(X_train)+len(X_val)+len(X_test))*0.85)]\n",
    "less_unbalanced_strategies = [strategy for strategy in y_keys if strategy not in most_unbalanced_strategies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqma6YpgQwzP"
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "               [],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Amount of SET perceptions', 'type': 'numeric'},\n",
    "                {'name': 'Amount of ST perceptions', 'type': 'numeric'},\n",
    "                {'name': 'Amount of P perceptions', 'type': 'numeric'},\n",
    "                {'name': 'Amount of M perceptions', 'type': 'numeric'}\n",
    "                ],\n",
    "               [{'name': 'Has SET perceptions', 'type': 'binary'},\n",
    "                {'name': 'Has ST perceptions', 'type': 'binary'},\n",
    "                {'name': 'Has P perceptions', 'type': 'binary'},\n",
    "                {'name': 'Has M perceptions', 'type': 'binary'}\n",
    "                ],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}],\n",
    "               [{'name': 'Medical Perceptions', 'type': 'string'}],\n",
    "               [{'name': 'Psychologist Perceptions', 'type': 'string'}],\n",
    "               [{'name': 'Speech Therapist Perceptions', 'type': 'string'}],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'string'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'}],\n",
    "               [{'name': 'Medical Perceptions', 'type': 'string'}, {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Psychologist Perceptions', 'type': 'string'}, {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Speech Therapist Perceptions', 'type': 'string'}, {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'string'}, {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Other Perceptions', 'type': 'binary_labels'}],\n",
    "               [{'name': 'Other Perceptions', 'type': 'binary_labels'}, {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Other Perceptions', 'type': 'binary_labels'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Other Perceptions', 'type': 'binary_labels'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Apoyo Pedagógico en asignaturas', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'}, \n",
    "                {'name': 'Apoyo Pedagógico en asignaturas', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Apoyo pedagógico personal', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Apoyo pedagógico personal', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Tutoría entre pares', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Tutoría entre pares', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Hacer a la familia partícipe del proceso', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Hacer a la familia partícipe del proceso', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Apoyo psicóloga(o)', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Apoyo psicóloga(o)', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Apoyo fonoaudióloga(o)', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Apoyo fonoaudióloga(o)', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Apoyo Educador(a) Diferencial', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Apoyo Educador(a) Diferencial', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Apoyo Kinesióloga(o)', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Apoyo Kinesióloga(o)', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Apoyo Médico General', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Apoyo Médico General', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Apoyo Terapeuta Ocupacional', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Apoyo Terapeuta Ocupacional', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Control Neurólogo', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Control Neurólogo', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Apoyo Interdisciplinario', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Apoyo Interdisciplinario', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Adecuación curricular de acceso', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Adecuación curricular de acceso', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}, \n",
    "                {'name': 'Adecuación curricular de objetivos', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'},\n",
    "                {'name': 'Adecuación curricular de objetivos', 'type': 'binary_single_label'}],\n",
    "               [{'name': 'All perceptions', 'type': 'embed_string', 'n_features': 100, 'special_token': '', 'transformation': 0}],\n",
    "               [{'name': 'All perceptions', 'type': 'embed_string', 'n_features': 100, 'special_token': '', 'transformation': 0}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "              #  [{'name': 'All perceptions', 'type': 'BETO_string', 'transformation': 0}],\n",
    "              #  [{'name': 'All perceptions', 'type': 'BETO_string', 'transformation': 0}, \n",
    "              #   {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}]\n",
    "               ]\n",
    "experiments_names = [\n",
    "                     \"Most frequent\",\n",
    "                     \"Only diagnosis (OHE)\",\n",
    "                     \"Amount of perceptions (numeric attributes)\",\n",
    "                     \"Has perceptions? (binary attributes)\",\n",
    "                     \"All joined perceptions (string attribute)\",\n",
    "                     \"Medical perceptions only (string attribute)\",\n",
    "                     \"Psychologist perceptions only (string attribute)\",\n",
    "                     \"Speech therapist perceptions only (string attribute)\",\n",
    "                     \"Special education teacher perceptions only (string attribute)\",\n",
    "                     \"All joined perceptions (string attribute) and encoded diagnosis\",\n",
    "                     \"Perceptions (string attribute) with special token to differentiate them\",\n",
    "                     \"Perceptions (string attribute) with special token and encoded diagnosis\",\n",
    "                     \"Medical perceptions + diagnosis\",\n",
    "                     \"Psychologist perceptions + diagnosis\",\n",
    "                     \"Speech therapist perceptions + diagnosis\",\n",
    "                     \"Special education teacher + diagnosis\",\n",
    "                     \"All other strategies\",\n",
    "                     \"All other strategies + diagnosis\",\n",
    "                     \"All joined perceptions + diagnosis + all other strategies\",\n",
    "                     \"Perceptions with tokens + diagnosis + all other strategies\",\n",
    "                     \"All joined perceptions + diagnosis + Apoyo Pedagógico en asignaturas\",\n",
    "                     \"Perceptions with tokens + diagnosis + Apoyo Pedagógico en asignaturas\",\n",
    "                     \"All joined perceptions + diagnosis + Apoyo pedagógico personal\",\n",
    "                     \"Perceptions with tokens + diagnosis + Apoyo pedagógico personal\",\n",
    "                     \"All joined perceptions + diagnosis + Tutoría entre pares\",\n",
    "                     \"Perceptions with tokens + diagnosis + Tutoría entre pares\",\n",
    "                     \"All joined perceptions + diagnosis + Hacer a la familia partícipe del proceso\",\n",
    "                     \"Perceptions with tokens + diagnosis + Hacer a la familia partícipe del proceso\",\n",
    "                     \"All joined perceptions + diagnosis + Apoyo psicóloga(o)\",\n",
    "                     \"Perceptions with tokens + diagnosis + Apoyo psicóloga(o)\",\n",
    "                     \"All joined perceptions + diagnosis + Apoyo fonoaudióloga(o)\",\n",
    "                     \"Perceptions with tokens + diagnosis + Apoyo fonoaudióloga(o)\",\n",
    "                     \"All joined perceptions + diagnosis + Apoyo Educador(a) Diferencial\",\n",
    "                     \"Perceptions with tokens + diagnosis + Apoyo Educador(a) Diferencial\",\n",
    "                     \"All joined perceptions + diagnosis + Apoyo Kinesióloga(o)\",\n",
    "                     \"Perceptions with tokens + diagnosis + Apoyo Kinesióloga(o)\",\n",
    "                     \"All joined perceptions + diagnosis + Apoyo Médico General\",\n",
    "                     \"Perceptions with tokens + diagnosis + Apoyo Médico General\",\n",
    "                     \"All joined perceptions + diagnosis + Apoyo Terapeuta Ocupacional\",\n",
    "                     \"Perceptions with tokens + diagnosis + Apoyo Terapeuta Ocupacional\",\n",
    "                     \"All joined perceptions + diagnosis + Control Neurólogo\",\n",
    "                     \"Perceptions with tokens + diagnosis + Control Neurólogo\",\n",
    "                     \"All joined perceptions + diagnosis + Apoyo Interdisciplinario\",\n",
    "                     \"Perceptions with tokens + diagnosis + Apoyo Interdisciplinario\",\n",
    "                     \"All joined perceptions + diagnosis + Adecuación curricular de acceso\",\n",
    "                     \"Perceptions with tokens + diagnosis + Adecuación curricular de acceso\",\n",
    "                     \"All joined perceptions + diagnosis + Adecuación curricular de objetivos\",\n",
    "                     \"Perceptions with tokens + diagnosis + Adecuación curricular de objetivos\",\n",
    "                     \"All perceptions with word embedding\",\n",
    "                     \"All perceptions (word embedding) + diagnosis\",\n",
    "                    #  \"All perceptions with BETO (average)\",\n",
    "                    #  \"All perceptions (BETO) + diagnosis (average)\"\n",
    "]\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sAzRyHDYPrf"
   },
   "outputs": [],
   "source": [
    "def custom_tokenizer(special_token=\"\", use_clean=True):\n",
    "  def tokenize(sentence):\n",
    "    clean_sentence = re.sub(r'[^\\w\\s[]]', '', str(sentence).lower().strip()) if use_clean else sentence\n",
    "    if special_token != \"\":\n",
    "      return list(map(lambda word: special_token+ \"_\" + word, clean_sentence.split()))\n",
    "    else:\n",
    "      return clean_sentence.split()\n",
    "  return tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvxmLARGoYP3"
   },
   "outputs": [],
   "source": [
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akzmBhPSqnuk"
   },
   "outputs": [],
   "source": [
    "def normalize_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    cap = []\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            cap.append(model[word])\n",
    "    cap_vec = np.sum(np.array(cap), axis=0)\n",
    "    cap_vec = cap_vec / np.sqrt(cap_vec.dot(cap_vec))\n",
    "        \n",
    "    return cap_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9kJn29uI7Je"
   },
   "outputs": [],
   "source": [
    "def average_feature_vectors(vectors):\n",
    "  feature_vector = np.zeros((len(vectors[0]),),dtype=\"float64\")\n",
    "  \n",
    "  for vector in vectors:\n",
    "    feature_vector = np.add(feature_vector, vector)\n",
    "\n",
    "  feature_vector = np.divide(feature_vector, len(vectors))\n",
    "      \n",
    "  return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UzfzCAOKbxJ"
   },
   "outputs": [],
   "source": [
    "def normalize_feature_vectors(vectors):\n",
    "  cap_vec = np.sum(np.array(vectors), axis=0)\n",
    "  cap_vec = cap_vec / np.sqrt(cap_vec.dot(cap_vec))\n",
    "        \n",
    "  return cap_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_nFWRNDnrKi"
   },
   "outputs": [],
   "source": [
    "def split_list(alist, wanted_parts=1):\n",
    "    length = len(alist)\n",
    "    return [ alist[i*length // wanted_parts: (i+1)*length // wanted_parts] \n",
    "             for i in range(wanted_parts) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0ISNAIinvNy",
    "outputId": "716dae74-67ee-4a44-966d-acbad3db050a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2], [3], [4]]"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_array = split_list([1,2,3,4], 4)\n",
    "new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FO-gW5ZDR0uu"
   },
   "outputs": [],
   "source": [
    "def transform_perception_to_feature_vector(perception, mode):\n",
    "  aproved = False\n",
    "  divide_exponent = 0\n",
    "  splitted_perception = perception.split()\n",
    "  while not aproved:\n",
    "    amount_aproved = 0\n",
    "    divided_array = split_list(splitted_perception, 2**divide_exponent)\n",
    "    separator = \" \"\n",
    "    divided_perceptions = [separator.join(words) for words in divided_array]\n",
    "    for mini_perception in divided_perceptions:\n",
    "      try:\n",
    "        perception_features = BETO_features(mini_perception)\n",
    "        amount_aproved += 1\n",
    "      except Exception:\n",
    "        pass \n",
    "    if amount_aproved == len(divided_perceptions):\n",
    "      aproved = True\n",
    "    else:\n",
    "      divide_exponent += 1\n",
    "  partial_modified_vector = []\n",
    "  for mini_perception in divided_perceptions:\n",
    "    mini_features = BETO_features(mini_perception)[0]\n",
    "    if mode == 0:\n",
    "      partial_modified_vector.append(average_feature_vectors(mini_features))\n",
    "    if mode == 1:\n",
    "      partial_modified_vector.append(normalize_feature_vectors(mini_features))\n",
    "  if mode == 0:\n",
    "    return average_feature_vectors(partial_modified_vector)\n",
    "  if mode == 1:\n",
    "    return normalize_feature_vectors(partial_modified_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pICBKZTXGvY1"
   },
   "outputs": [],
   "source": [
    "def make_top_tables(features, coeffs, top_n=10):\n",
    "  ordered_coeffs, ordered_features = zip(*sorted(zip(coeffs, features), reverse=True))\n",
    "  for i in range(top_n if len(features) > top_n else len(features)):\n",
    "    print(i+1, ordered_features[i], ordered_coeffs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BN94NJo3ag0w"
   },
   "outputs": [],
   "source": [
    "def make_bottom_tables(features, coeffs, top_n=10):\n",
    "  ordered_coeffs, ordered_features = zip(*sorted(zip(coeffs, features), reverse=True))\n",
    "  for i in range(top_n if len(features) > top_n else len(features)):\n",
    "    print(i+1, ordered_features[(i+1)*-1], ordered_coeffs[(i+1)*-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skLRZ0_-RJxD"
   },
   "outputs": [],
   "source": [
    "def execute_experiments(X_train, Y_train, X_val, Y_val, selected_strategies, experiments):\n",
    "  all_results = []\n",
    "  for strategy in selected_strategies:\n",
    "    i = 0\n",
    "    print('experimentando para estrategia: '+strategy)\n",
    "    strat_acc = []\n",
    "    strat_kappa = []\n",
    "    strat_f1 = []\n",
    "    strat_auc = []\n",
    "    strat_coefs = []\n",
    "    strat_features = []\n",
    "    for experiment in experiments:\n",
    "      print(\"\\t\"+str(i+1)+'° experimento')\n",
    "      i += 1\n",
    "      # y = df[strategy]\n",
    "      y_train = Y_train[strategy]\n",
    "      y_val = Y_val[strategy]\n",
    "      # X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "      #                                                     y,\n",
    "      #                                                     test_size=0.2,\n",
    "      #                                                     random_state=1)\n",
    "      # X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "      #                                                   y_train,\n",
    "      #                                                   stratify=y_train,\n",
    "      #                                                   test_size=0.25,\n",
    "      #                                                   random_state=1)\n",
    "      if len(experiment) > 0:\n",
    "        classifier = LogisticRegression(penalty='l2', dual=True, solver='liblinear', max_iter=10000)\n",
    "        X_train_transformed = pd.DataFrame()\n",
    "        X_val_transformed = pd.DataFrame()\n",
    "        for input in experiment:\n",
    "          # Encoding diagnosis as categorical attribute\n",
    "          if input['type'] == 'categorical_diagnostic':\n",
    "            enc = OneHotEncoder(handle_unknown='ignore')\n",
    "            enc.fit(np.asarray(X_train[input['name']].append(X_val[input['name']])).reshape(-1, 1))\n",
    "\n",
    "            train_arrays = enc.transform(np.asarray(X_train[input['name']]).reshape(-1,1)).toarray()\n",
    "            temp_train_df = pd.DataFrame(train_arrays, columns=list(diagnoses_codes.keys()))\n",
    "\n",
    "            val_arrays = enc.transform(np.asarray(X_val[input['name']]).reshape(-1,1)).toarray()\n",
    "            temp_val_df = pd.DataFrame(val_arrays, columns=list(diagnoses_codes.keys()))\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          # Copying numeric and binary attributes\n",
    "          if input['type'] == 'numeric' or input['type'] == 'binary':\n",
    "            X_train_transformed[input['name']] = X_train[input['name']].to_numpy()\n",
    "            X_val_transformed[input['name']] = X_val[input['name']].to_numpy()\n",
    "\n",
    "          # Encoding strings\n",
    "          if input['type'] == 'string':\n",
    "            vectorizer = CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=stopwords, ngram_range=(1,3), max_df=0.8, min_df=0.05)\n",
    "            vectorizer.fit(X_train[input['name']])\n",
    "            print(vectorizer.get_feature_names())\n",
    "            train_arrays = vectorizer.transform(X_train[input['name']]).toarray()\n",
    "            temp_train_df = pd.DataFrame(train_arrays, columns=vectorizer.get_feature_names())\n",
    "            \n",
    "            val_arrays = vectorizer.transform(X_val[input['name']]).toarray()\n",
    "            temp_val_df = pd.DataFrame(val_arrays, columns=vectorizer.get_feature_names())\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          # Encoding strings with special tokens\n",
    "          if input['type'] == 'special_string':\n",
    "            tokenizer = custom_tokenizer(input['special_token'])\n",
    "            vectorizer = CountVectorizer(strip_accents='unicode',\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        lowercase=True,\n",
    "                                        stop_words=list(map(lambda word: input['special_token']+ \"_\" + word, stopwords)),\n",
    "                                        ngram_range=(1,3),\n",
    "                                        max_df=0.8,\n",
    "                                        min_df=0.05)\n",
    "            vectorizer.fit(X_train[input['name']])\n",
    "            train_arrays = vectorizer.transform(X_train[input['name']]).toarray()\n",
    "            temp_train_df = pd.DataFrame(train_arrays, columns=vectorizer.get_feature_names())\n",
    "            \n",
    "            val_arrays = vectorizer.transform(X_val[input['name']]).toarray()\n",
    "            temp_val_df = pd.DataFrame(val_arrays, columns=vectorizer.get_feature_names())\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          if input['type'] == \"binary_labels\":\n",
    "            for other_label in list(Y_train.columns):\n",
    "              if other_label != strategy:\n",
    "                X_train_transformed[other_label] = Y_train[other_label].to_numpy()\n",
    "                X_val_transformed[other_label] = Y_val[other_label].to_numpy()\n",
    "\n",
    "          if input['type'] == \"binary_single_label\":\n",
    "              if input['name'] != strategy:\n",
    "                X_train_transformed[input['name']] = Y_train[input['name']].to_numpy()\n",
    "                X_val_transformed[input['name']] = Y_val[input['name']].to_numpy()\n",
    "\n",
    "          if input['type'] == \"embed_string\":\n",
    "            c_tokenizer = custom_tokenizer(input['special_token'])\n",
    "            embedding_model = Word2Vec(\n",
    "                list(map(lambda doc: c_tokenizer(doc), X_train[input['name']])),\n",
    "                min_count=1, \n",
    "                window=3, \n",
    "                sg=1, \n",
    "                size=input['n_features'])\n",
    "            vocab = embedding_model.wv.vocab\n",
    "            tokenized_train_perceptions = list(map(lambda doc: c_tokenizer(doc), X_train[input['name']]))\n",
    "            tokenized_val_perceptions = list(map(lambda doc: c_tokenizer(doc), X_val[input['name']]))\n",
    "            if input['transformation'] == 0:\n",
    "              transformed_train_perceptions = list(map(\n",
    "                  lambda tokenized_perception: normalize_word_vectors(tokenized_perception,\n",
    "                                                                    embedding_model, \n",
    "                                                                    vocab, \n",
    "                                                                    input['n_features']), tokenized_train_perceptions))\n",
    "              transformed_val_perceptions = list(map(\n",
    "                  lambda tokenized_perception: normalize_word_vectors(tokenized_perception,\n",
    "                                                                    embedding_model, \n",
    "                                                                    vocab, \n",
    "                                                                    input['n_features']), tokenized_val_perceptions))\n",
    "            if input['transformation'] == 1:\n",
    "              transformed_train_perceptions = list(map(\n",
    "                  lambda tokenized_perception: average_word_vectors(tokenized_perception,\n",
    "                                                                    embedding_model, \n",
    "                                                                    vocab, \n",
    "                                                                    input['n_features']), tokenized_train_perceptions))\n",
    "              transformed_val_perceptions = list(map(\n",
    "                  lambda tokenized_perception: average_word_vectors(tokenized_perception,\n",
    "                                                                    embedding_model, \n",
    "                                                                    vocab, \n",
    "                                                                    input['n_features']), tokenized_val_perceptions))\n",
    "            \n",
    "\n",
    "            temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(input['n_features'])])\n",
    "            temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(input['n_features'])])\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "\n",
    "          if input['type'] == \"BETO_string\":\n",
    "\n",
    "            transformed_train_perceptions = list(map(\n",
    "                lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_train[input['name']]))\n",
    "            transformed_val_perceptions = list(map(\n",
    "                lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_val[input['name']]))\n",
    "\n",
    "            temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_train_perceptions[0]))])\n",
    "            temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_val_perceptions[0]))])\n",
    "            \n",
    "            X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "            X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "            del temp_train_df, temp_val_df\n",
    "              \n",
    "\n",
    "        classifier.fit(X_train_transformed, y_train)\n",
    "        y_pred = classifier.predict(X_val_transformed)\n",
    "        strat_acc.append(round(accuracy_score(y_val, y_pred), 2))\n",
    "        strat_kappa.append(round(cohen_kappa_score(y_val, y_pred), 2))\n",
    "        strat_f1.append(round((f1_score(y_val, y_pred, pos_label=1) + f1_score(y_val, y_pred, pos_label=0))/2, 2))\n",
    "        strat_auc.append(round(roc_auc_score(y_val, y_pred), 2))\n",
    "        strat_coefs.append(classifier.coef_)\n",
    "        strat_features.append(list(X_train_transformed.columns))\n",
    "        del X_train_transformed, X_val_transformed\n",
    "      else:\n",
    "        classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "        classifier.fit(X_train['Diagnosis'], y_train)\n",
    "        y_pred = classifier.predict(X_val['Diagnosis'])\n",
    "        strat_acc.append(round(accuracy_score(y_val, y_pred), 2))\n",
    "        strat_kappa.append(round(cohen_kappa_score(y_val, y_pred), 2))\n",
    "        strat_f1.append(round((f1_score(y_val, y_pred, pos_label=1) + f1_score(y_val, y_pred, pos_label=0))/2, 2))\n",
    "        strat_auc.append(round(roc_auc_score(y_val, y_pred), 2))\n",
    "\n",
    "    all_results.append({'name': strategy, 'accs': strat_acc, 'kappas': strat_kappa, 'f1s': strat_f1, 'aucs': strat_auc, 'coefs': strat_coefs, 'features': strat_features})\n",
    "  return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VRnFhrGmZvSD",
    "outputId": "04bd8e14-9a68-4beb-b164-65b6bb7bb2a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre    1                  2\n",
      "--------  -----------------  -----------------\n",
      "label     hola  chao  perro  hola  chao  perro\n"
     ]
    }
   ],
   "source": [
    "mini_table = tabulate([[\"hola\", \"chao\", \"perro\"]], tablefmt=\"plain\")\n",
    "\n",
    "table = tabulate([[\"label\", mini_table, mini_table]], headers=[\"nombre\", \"1\", \"2\"])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7COdCBk2enL"
   },
   "outputs": [],
   "source": [
    "def make_table_for_python(strats_results, difference_val=0.04):\n",
    "  header_columns = ['Experiment names']\n",
    "  experiments = [[name] for name in experiments_names] \n",
    "  for strat_result in strats_results:\n",
    "    marks = [\"(*)\", \"(**)\"] \n",
    "    sorted_accs = sorted(list(set(strat_result['accs'])), reverse=True)\n",
    "    sorted_kappas = sorted(list(set(strat_result['kappas'])), reverse=True)\n",
    "    sorted_f1s = sorted(list(set(strat_result['f1s'])), reverse=True)\n",
    "    sorted_aucs = sorted(list(set(strat_result['aucs'])), reverse=True)\n",
    "    for i in range(len(strat_result['accs'])):\n",
    "      exp_results = []\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['accs'][i] == sorted_accs[0]:\n",
    "        if len(sorted_accs) > 1 and strat_result['accs'][i] >= sorted_accs[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      exp_results.append((str(strat_result['accs'][i]) if strat_result['accs'][i]>0 else \"0.00\")+chosen_mark)\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['kappas'][i] == sorted_kappas[0]:\n",
    "        if len(sorted_kappas) > 1 and strat_result['kappas'][i] >= sorted_kappas[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      exp_results.append((str(strat_result['kappas'][i]) if strat_result['kappas'][i]>0 else \"0.00\")+chosen_mark)\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['f1s'][i] == sorted_f1s[0]:\n",
    "        if len(sorted_f1s) > 1 and strat_result['f1s'][i] >= sorted_f1s[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      exp_results.append((str(strat_result['f1s'][i]) if strat_result['f1s'][i]>0 else \"0.00\")+chosen_mark)\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['aucs'][i] == sorted_aucs[0]:\n",
    "        if len(sorted_aucs) > 1 and strat_result['aucs'][i] >= sorted_aucs[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      exp_results.append((str(strat_result['aucs'][i]) if strat_result['aucs'][i]>0 else \"0.00\")+chosen_mark)\n",
    "      experiments[i].append(tabulate([exp_results], tablefmt=\"plain\"))\n",
    "    header_columns.append(\n",
    "        strat_result['name'])\n",
    "  return tabulate(experiments, headers=header_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSmAFPgRm3El"
   },
   "outputs": [],
   "source": [
    "def make_table_for_latex(strats_results, difference_val=0.04):\n",
    "  header_columns = ['Experiment names']\n",
    "  experiments = [[name] for name in experiments_names] \n",
    "  experiments_means = [[0, 0, 0, 0] for name in experiments_names]\n",
    "  for strat_result in strats_results:\n",
    "    marks = [\"(*)\", \"(**)\"] \n",
    "    sorted_accs = sorted(list(set(strat_result['accs'])), reverse=True)\n",
    "    sorted_kappas = sorted(list(set(strat_result['kappas'])), reverse=True)\n",
    "    sorted_f1s = sorted(list(set(strat_result['f1s'])), reverse=True)\n",
    "    sorted_aucs = sorted(list(set(strat_result['aucs'])), reverse=True)\n",
    "    for i in range(len(strat_result['accs'])):\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['accs'][i] == sorted_accs[0]:\n",
    "        if len(sorted_accs) > 1 and strat_result['accs'][i] >= sorted_accs[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      experiments[i].append(str(strat_result['accs'][i])+chosen_mark)\n",
    "      experiments_means[i][0] += strat_result['accs'][i]\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['kappas'][i] == sorted_kappas[0]:\n",
    "        if len(sorted_kappas) > 1 and strat_result['kappas'][i] >= sorted_kappas[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      experiments[i].append(str(strat_result['kappas'][i])+chosen_mark)\n",
    "      experiments_means[i][1] += strat_result['kappas'][i]\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['f1s'][i] == sorted_f1s[0]:\n",
    "        if len(sorted_f1s) > 1 and strat_result['f1s'][i] >= sorted_f1s[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      experiments[i].append(str(strat_result['f1s'][i])+chosen_mark)\n",
    "      experiments_means[i][2] += strat_result['f1s'][i]\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['aucs'][i] == sorted_aucs[0]:\n",
    "        if len(sorted_aucs) > 1 and strat_result['aucs'][i] >= sorted_aucs[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      experiments[i].append(str(strat_result['aucs'][i])+chosen_mark)\n",
    "      experiments_means[i][3] += strat_result['aucs'][i]\n",
    "    header_columns.extend(\n",
    "        [strat_result['name']+(\" (\"+str(strats_amounts[strat_result['name']])+\" cases)\"), 'Kappa', 'F1', 'AUC'])\n",
    "  for i in range(len(experiments_means)):\n",
    "    experiments[i].append(round(experiments_means[i][0]/len(strats_results), 2))\n",
    "    experiments[i].append(round(experiments_means[i][1]/len(strats_results), 2))\n",
    "    experiments[i].append(round(experiments_means[i][2]/len(strats_results), 2))\n",
    "    experiments[i].append(round(experiments_means[i][3]/len(strats_results), 2))\n",
    "  header_columns.extend(\n",
    "        [\"Means\", 'Kappa', 'F1', 'AUC'])\n",
    "  return tabulate(experiments, headers=header_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0La0vjCZNZc",
    "outputId": "1dba72ae-1130-4725-9a3f-d9010611e9ef"
   },
   "outputs": [],
   "source": [
    "most_unbalanced_results = execute_experiments(X_train, Y_train, X_val, Y_val, most_unbalanced_strategies, experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4EzuZsm7MHV",
    "outputId": "8e863438-71f8-4f70-9fe4-580406e21973"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'accs', 'kappas', 'f1s', 'aucs', 'coefs', 'features'])"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_unbalanced_results[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wH9yeNQOeGI",
    "outputId": "3f34be9c-0c5a-47ab-8735-1773435169df"
   },
   "outputs": [],
   "source": [
    "for result in most_unbalanced_results:\n",
    "  strat_name = result['name']\n",
    "  print('--------- Resultados para '+strat_name+' -----------')\n",
    "  for i in range(len(result['coefs'])):\n",
    "    print('++++++++++ Experimento: '+experiments_names[i+1] + '+++++++++++')\n",
    "    make_top_tables(result['features'][i], result['coefs'][i][0], 10)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vkkFkyIwbAit",
    "outputId": "856a9e0a-de15-4251-fe40-a0ef5bd88805"
   },
   "outputs": [],
   "source": [
    "for result in most_unbalanced_results:\n",
    "  strat_name = result['name']\n",
    "  print('--------- Resultados para '+strat_name+' -----------')\n",
    "  for i in range(len(result['coefs'])):\n",
    "    print('++++++++++ Experimento: '+experiments_names[i+1] + '+++++++++++')\n",
    "    make_bottom_tables(result['features'][i], result['coefs'][i][0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbFsbtqH7gNU",
    "outputId": "effb00ff-27fb-4197-c863-401093de11b8"
   },
   "outputs": [],
   "source": [
    "print(make_table_for_python(most_unbalanced_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiPNXaUywlQ2",
    "outputId": "4100bf63-4d95-4fac-c7ad-159f47ef67f6"
   },
   "outputs": [],
   "source": [
    "print('Number of features')\n",
    "for strategy in most_unbalanced_results:\n",
    "  print(strategy['name'])\n",
    "  for i in range(1, len(experiments_names)):\n",
    "    print(experiments_names[i], ':', len(strategy['features'][i-1]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfdGBJaUGjYY",
    "outputId": "fae4ecda-e42f-4f11-af7a-422d5d435e9e"
   },
   "outputs": [],
   "source": [
    "print(make_table_for_latex(most_unbalanced_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRrGycV0kxyk",
    "outputId": "9578c3b2-0883-4905-d76a-cb7f095913e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "less_unbalanced_results = execute_experiments(X_train, Y_train, X_val, Y_val, less_unbalanced_strategies, experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ARsoM_fuqKR3",
    "outputId": "836c2c42-35bb-4f49-f26d-8e8a5291f4cb"
   },
   "outputs": [],
   "source": [
    "print(make_table_for_latex(less_unbalanced_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuC0oBm7kz2i",
    "outputId": "5796fd0c-dccf-410e-ca39-9b9ab948b3bd"
   },
   "outputs": [],
   "source": [
    "all_strats_results = execute_experiments(X_train, Y_train, X_val, Y_val, y_keys, experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IyHZSOi3wMUY",
    "outputId": "342e092f-e0c1-465e-8c27-6ef71c8fc1cb"
   },
   "outputs": [],
   "source": [
    "print(make_table_for_latex(all_strats_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KABAP86ezqrH"
   },
   "outputs": [],
   "source": [
    "ml_experiments = [\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Amount of SET perceptions', 'type': 'numeric'},\n",
    "                {'name': 'Amount of ST perceptions', 'type': 'numeric'},\n",
    "                {'name': 'Amount of P perceptions', 'type': 'numeric'},\n",
    "                {'name': 'Amount of M perceptions', 'type': 'numeric'}\n",
    "                ],\n",
    "               [{'name': 'Has SET perceptions', 'type': 'binary'},\n",
    "                {'name': 'Has ST perceptions', 'type': 'binary'},\n",
    "                {'name': 'Has P perceptions', 'type': 'binary'},\n",
    "                {'name': 'Has M perceptions', 'type': 'binary'}\n",
    "                ],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}],\n",
    "               [{'name': 'Medical Perceptions', 'type': 'string'}],\n",
    "               [{'name': 'Psychologist Perceptions', 'type': 'string'}],\n",
    "               [{'name': 'Speech Therapist Perceptions', 'type': 'string'}],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'string'}],\n",
    "               [{'name': 'All perceptions', 'type': 'string'}, {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'}],\n",
    "               [{'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'},\n",
    "                {'name': 'Special Education Teacher Perceptions', 'type': 'special_string', 'special_token': 'set'}, \n",
    "                {'name': 'Speech Therapist Perceptions', 'type': 'special_string', 'special_token': 'st'},\n",
    "                {'name': 'Psychologist Perceptions', 'type': 'special_string', 'special_token': 'p'},\n",
    "                {'name': 'Medical Perceptions', 'type': 'special_string', 'special_token': 'm'}],\n",
    "               [{'name': 'Medical Perceptions', 'type': 'string'}, {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Psychologist Perceptions', 'type': 'string'}, {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Speech Therapist Perceptions', 'type': 'string'}, {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'Special Education Teacher Perceptions', 'type': 'string'}, {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "               [{'name': 'All perceptions', 'type': 'embed_string', 'n_features': 100, 'special_token': '', 'transformation': 0}],\n",
    "               [{'name': 'All perceptions', 'type': 'embed_string', 'n_features': 100, 'special_token': '', 'transformation': 0}, \n",
    "                {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "              #  [{'name': 'All perceptions', 'type': 'BETO_string', 'transformation': 0}],\n",
    "              #  [{'name': 'All perceptions', 'type': 'BETO_string', 'transformation': 0}, \n",
    "              #   {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "              #  [{'name': 'Special Education Teacher Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'set'},\n",
    "              #   {'name': 'Speech Therapist Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'st'},\n",
    "              #   {'name': 'Psychologist Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'p'},\n",
    "              #   {'name': 'Medical Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'm'}\n",
    "              #   ],\n",
    "              #  [{'name': 'Special Education Teacher Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'set'},\n",
    "              #   {'name': 'Speech Therapist Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'st'},\n",
    "              #   {'name': 'Psychologist Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'p'},\n",
    "              #   {'name': 'Medical Perceptions', 'type': 'BETO_string', 'transformation': 0, 'code': 'm'}, \n",
    "              #   {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}\n",
    "              #   ],\n",
    "              #  [{'name': 'All perceptions', 'type': 'sentence_embedding'}],\n",
    "              #  [{'name': 'All perceptions', 'type': 'sentence_embedding'}, \n",
    "              #   {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}],\n",
    "              #  [{'name': 'Special Education Teacher Perceptions', 'type': 'sentence_embedding'},\n",
    "              #   {'name': 'Speech Therapist Perceptions', 'type': 'sentence_embedding'},\n",
    "              #   {'name': 'Psychologist Perceptions', 'type': 'sentence_embedding'},\n",
    "              #   {'name': 'Medical Perceptions', 'type': 'sentence_embedding'}],\n",
    "              #  [{'name': 'Special Education Teacher Perceptions', 'type': 'sentence_embedding'},\n",
    "              #   {'name': 'Speech Therapist Perceptions', 'type': 'sentence_embedding'},\n",
    "              #   {'name': 'Psychologist Perceptions', 'type': 'sentence_embedding'},\n",
    "              #   {'name': 'Medical Perceptions', 'type': 'sentence_embedding'},\n",
    "              #   {'name': 'Encoded Diagnosis', 'type': 'categorical_diagnostic'}\n",
    "              #   ]\n",
    "               ]\n",
    "ml_experiments_names = [\n",
    "                     \"Only diagnosis (OHE)\",\n",
    "                     \"Amount of perceptions (numeric attributes)\",\n",
    "                     \"Has perceptions? (binary attributes)\",\n",
    "                     \"All joined perceptions (string attribute)\",\n",
    "                     \"Medical perceptions only (string attribute)\",\n",
    "                     \"Psychologist perceptions only (string attribute)\",\n",
    "                     \"Speech therapist perceptions only (string attribute)\",\n",
    "                     \"Special education teacher perceptions only (string attribute)\",\n",
    "                     \"All joined perceptions (string attribute) and encoded diagnosis\",\n",
    "                     \"Perceptions (string attribute) with special token to differentiate them\",\n",
    "                     \"Perceptions (string attribute) with special token and encoded diagnosis\",\n",
    "                     \"Medical perceptions + diagnosis\",\n",
    "                     \"Psychologist perceptions + diagnosis\",\n",
    "                     \"Speech therapist perceptions + diagnosis\",\n",
    "                     \"Special education teacher + diagnosis\",\n",
    "                     \"All perceptions with word embedding\",\n",
    "                     \"All perceptions (word embedding) + diagnosis\",\n",
    "                    #  \"All perceptions with BETO (average)\",\n",
    "                    #  \"All perceptions (BETO) + diagnosis (average)\",\n",
    "                    #  \"Different perceptions with BETO (average)\",\n",
    "                    #  \"Different perceptions (BETO) + diagnosis (average)\",\n",
    "                    #  \"Sentence BERT embedding\",\n",
    "                    #  \"Sentence + diagnosis\",\n",
    "                    #  \"Different perceptions\",\n",
    "                    #  \"Different + diagnosis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mQxwGyiz0Pc"
   },
   "outputs": [],
   "source": [
    "def classifier_chain_experiments(X_train, Y_train, X_val, Y_val, y_keys, experiments, order):\n",
    "  preds = []\n",
    "  i = 0\n",
    "  for experiment in experiments:\n",
    "    print(\"\\t\"+str(i+1)+'° experimento')\n",
    "    i += 1\n",
    "    if len(experiment) > 0:\n",
    "      base_lr = LogisticRegression(penalty='l2', dual=True, solver='liblinear', max_iter=10000)\n",
    "      classifier = ClassifierChain(base_lr, order=order)\n",
    "      X_train_transformed = pd.DataFrame()\n",
    "      X_val_transformed = pd.DataFrame()\n",
    "      for input in experiment:\n",
    "        # Encoding diagnosis as categorical attribute\n",
    "        if input['type'] == 'categorical_diagnostic':\n",
    "          enc = OneHotEncoder(handle_unknown='ignore')\n",
    "          enc.fit(np.asarray(X_train[input['name']].append(X_val[input['name']])).reshape(-1, 1))\n",
    "\n",
    "          train_arrays = enc.transform(np.asarray(X_train[input['name']]).reshape(-1,1)).toarray()\n",
    "          temp_train_df = pd.DataFrame(train_arrays, columns=list(diagnoses_codes.keys()))\n",
    "\n",
    "          val_arrays = enc.transform(np.asarray(X_val[input['name']]).reshape(-1,1)).toarray()\n",
    "          temp_val_df = pd.DataFrame(val_arrays, columns=list(diagnoses_codes.keys()))\n",
    "          \n",
    "          X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "          X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "          del temp_train_df, temp_val_df\n",
    "\n",
    "        # Copying numeric and binary attributes\n",
    "        if input['type'] == 'numeric' or input['type'] == 'binary':\n",
    "          X_train_transformed[input['name']] = X_train[input['name']].to_numpy()\n",
    "          X_val_transformed[input['name']] = X_val[input['name']].to_numpy()\n",
    "\n",
    "        # Encoding strings\n",
    "        if input['type'] == 'string':\n",
    "          vectorizer = CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=stopwords, ngram_range=(1,3), max_df=0.8, min_df=0.05)\n",
    "          vectorizer.fit(X_train[input['name']])\n",
    "          print(vectorizer.get_feature_names())\n",
    "          train_arrays = vectorizer.transform(X_train[input['name']]).toarray()\n",
    "          temp_train_df = pd.DataFrame(train_arrays, columns=vectorizer.get_feature_names())\n",
    "          \n",
    "          val_arrays = vectorizer.transform(X_val[input['name']]).toarray()\n",
    "          temp_val_df = pd.DataFrame(val_arrays, columns=vectorizer.get_feature_names())\n",
    "          \n",
    "          X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "          X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "          del temp_train_df, temp_val_df\n",
    "\n",
    "        # Encoding strings with special tokens\n",
    "        if input['type'] == 'special_string':\n",
    "          tokenzr = custom_tokenizer(input['special_token'])\n",
    "          vectorizer = CountVectorizer(strip_accents='unicode',\n",
    "                                      tokenizer=tokenzr,\n",
    "                                      lowercase=True,\n",
    "                                      stop_words=list(map(lambda word: input['special_token']+ \"_\" + word, stopwords)),\n",
    "                                      ngram_range=(1,3),\n",
    "                                      max_df=0.8,\n",
    "                                      min_df=0.05)\n",
    "          vectorizer.fit(X_train[input['name']])\n",
    "          train_arrays = vectorizer.transform(X_train[input['name']]).toarray()\n",
    "          temp_train_df = pd.DataFrame(train_arrays, columns=vectorizer.get_feature_names())\n",
    "          \n",
    "          val_arrays = vectorizer.transform(X_val[input['name']]).toarray()\n",
    "          temp_val_df = pd.DataFrame(val_arrays, columns=vectorizer.get_feature_names())\n",
    "          \n",
    "          X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "          X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "          del temp_train_df, temp_val_df\n",
    "\n",
    "        # if input['type'] == \"binary_labels\":\n",
    "        #   for other_label in list(Y_train.columns):\n",
    "        #     if other_label != strategy:\n",
    "        #       X_train_transformed[other_label] = Y_train[other_label].to_numpy()\n",
    "        #       X_val_transformed[other_label] = Y_val[other_label].to_numpy()\n",
    "\n",
    "        # if input['type'] == \"binary_single_label\":\n",
    "        #     if input['name'] != strategy:\n",
    "        #       X_train_transformed[input['name']] = Y_train[input['name']].to_numpy()\n",
    "        #       X_val_transformed[input['name']] = Y_val[input['name']].to_numpy()\n",
    "\n",
    "        if input['type'] == \"embed_string\":\n",
    "          c_tokenizer = custom_tokenizer(input['special_token'])\n",
    "          embedding_model = Word2Vec(\n",
    "              list(map(lambda doc: c_tokenizer(doc), X_train[input['name']])),\n",
    "              min_count=1, \n",
    "              window=3, \n",
    "              sg=1, \n",
    "              size=input['n_features'])\n",
    "          vocab = embedding_model.wv.vocab\n",
    "          tokenized_train_perceptions = list(map(lambda doc: c_tokenizer(doc), X_train[input['name']]))\n",
    "          tokenized_val_perceptions = list(map(lambda doc: c_tokenizer(doc), X_val[input['name']]))\n",
    "          if input['transformation'] == 0:\n",
    "            transformed_train_perceptions = list(map(\n",
    "                lambda tokenized_perception: normalize_word_vectors(tokenized_perception,\n",
    "                                                                  embedding_model, \n",
    "                                                                  vocab, \n",
    "                                                                  input['n_features']), tokenized_train_perceptions))\n",
    "            transformed_val_perceptions = list(map(\n",
    "                lambda tokenized_perception: normalize_word_vectors(tokenized_perception,\n",
    "                                                                  embedding_model, \n",
    "                                                                  vocab, \n",
    "                                                                  input['n_features']), tokenized_val_perceptions))\n",
    "          if input['transformation'] == 1:\n",
    "            transformed_train_perceptions = list(map(\n",
    "                lambda tokenized_perception: average_word_vectors(tokenized_perception,\n",
    "                                                                  embedding_model, \n",
    "                                                                  vocab, \n",
    "                                                                  input['n_features']), tokenized_train_perceptions))\n",
    "            transformed_val_perceptions = list(map(\n",
    "                lambda tokenized_perception: average_word_vectors(tokenized_perception,\n",
    "                                                                  embedding_model, \n",
    "                                                                  vocab, \n",
    "                                                                  input['n_features']), tokenized_val_perceptions))\n",
    "          \n",
    "\n",
    "          temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(input['n_features'])])\n",
    "          temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(input['n_features'])])\n",
    "          \n",
    "          X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "          X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "          del temp_train_df, temp_val_df\n",
    "\n",
    "        if input['type'] == \"BETO_string\":\n",
    "\n",
    "          transformed_train_perceptions = list(map(\n",
    "              lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_train[input['name']]))\n",
    "          transformed_val_perceptions = list(map(\n",
    "              lambda perception: transform_perception_to_feature_vector(perception, input['transformation']), X_val[input['name']]))\n",
    "\n",
    "          temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_train_perceptions[0]))])\n",
    "          temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_val_perceptions[0]))])\n",
    "          \n",
    "          X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "          X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "          del temp_train_df, temp_val_df\n",
    "\n",
    "        if input['type'] == \"sentence_embedding\":\n",
    "\n",
    "          transformed_train_perceptions = list(map(\n",
    "              lambda perception: sentence_model.encode(perception), X_train[input['name']]))\n",
    "          transformed_val_perceptions = list(map(\n",
    "              lambda perception: sentence_model.encode(perception), X_val[input['name']]))\n",
    "\n",
    "          temp_train_df = pd.DataFrame(transformed_train_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_train_perceptions[0]))])\n",
    "          temp_val_df = pd.DataFrame(transformed_val_perceptions, columns=[str(i+1)+'_feature' for i in range(len(transformed_val_perceptions[0]))])\n",
    "          \n",
    "          X_train_transformed = pd.concat([X_train_transformed, temp_train_df], axis=1)\n",
    "          X_val_transformed = pd.concat([X_val_transformed, temp_val_df], axis=1)\n",
    "          del temp_train_df, temp_val_df\n",
    "            \n",
    "\n",
    "      classifier.fit(X_train_transformed, Y_train)\n",
    "      Y_pred = classifier.predict(X_val_transformed)\n",
    "      # strat_acc.append(round(accuracy_score(y_val, y_pred), 2))\n",
    "      # strat_kappa.append(round(cohen_kappa_score(y_val, y_pred), 2))\n",
    "      # strat_f1.append(round((f1_score(y_val, y_pred, pos_label=1) + f1_score(y_val, y_pred, pos_label=0))/2, 2))\n",
    "      # strat_auc.append(round(roc_auc_score(y_val, y_pred), 2))\n",
    "      # strat_coefs.append(classifier.coef_)\n",
    "      # strat_features.append(list(X_train_transformed.columns))\n",
    "      preds.append(Y_pred)\n",
    "      del X_train_transformed, X_val_transformed\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-wMMlrT1Neb",
    "outputId": "68437993-60ac-4abf-93a9-fb7b87847daa"
   },
   "outputs": [],
   "source": [
    "order = []\n",
    "for strat in most_unbalanced_strategies:\n",
    "    order.append(list(Y_val.columns).index(strat))\n",
    "for strat in less_unbalanced_strategies:\n",
    "    order.append(list(Y_val.columns).index(strat))\n",
    "print(order)\n",
    "ml_results = classifier_chain_experiments(X_train, Y_train, X_val, Y_val, y_keys, ml_experiments, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EDc9hnr1ONM"
   },
   "outputs": [],
   "source": [
    "def make_table_for_latex_multi_label_experiments(experiment_preds, Y_vals, labels_to_eval, exps_names, difference_val=0.04):\n",
    "  all_results = []\n",
    "  for strategy in labels_to_eval:\n",
    "    i = 0\n",
    "    strat_acc = []\n",
    "    strat_kappa = []\n",
    "    strat_f1 = []\n",
    "    strat_auc = []\n",
    "    for preds in experiment_preds:\n",
    "      label_index = list(Y_vals.columns).index(strategy)\n",
    "      y_val = Y_vals[strategy]\n",
    "      y_pred = preds[:, label_index]\n",
    "      strat_acc.append(round(accuracy_score(y_val, y_pred), 2))\n",
    "      strat_kappa.append(round(cohen_kappa_score(y_val, y_pred), 2))\n",
    "      strat_f1.append(round((f1_score(y_val, y_pred, pos_label=1) + f1_score(y_val, y_pred, pos_label=0))/2, 2))\n",
    "      strat_auc.append(round(roc_auc_score(y_val, y_pred), 2))\n",
    "\n",
    "    all_results.append({'name': strategy, 'accs': strat_acc, 'kappas': strat_kappa, 'f1s': strat_f1, 'aucs': strat_auc})\n",
    "  strats_results = all_results\n",
    "  \n",
    "  header_columns = ['Experiment names']\n",
    "  experiments = [[name] for name in exps_names] \n",
    "  experiments_means = [[0, 0, 0, 0] for name in exps_names]\n",
    "  for strat_result in strats_results:\n",
    "    marks = [\"(*)\", \"(**)\"] \n",
    "    sorted_accs = sorted(list(set(strat_result['accs'])), reverse=True)\n",
    "    sorted_kappas = sorted(list(set(strat_result['kappas'])), reverse=True)\n",
    "    sorted_f1s = sorted(list(set(strat_result['f1s'])), reverse=True)\n",
    "    sorted_aucs = sorted(list(set(strat_result['aucs'])), reverse=True)\n",
    "    for i in range(len(strat_result['accs'])):\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['accs'][i] == sorted_accs[0]:\n",
    "        if len(sorted_accs) > 1 and strat_result['accs'][i] >= sorted_accs[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      experiments[i].append(str(strat_result['accs'][i])+chosen_mark)\n",
    "      experiments_means[i][0] += strat_result['accs'][i]\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['kappas'][i] == sorted_kappas[0]:\n",
    "        if len(sorted_kappas) > 1 and strat_result['kappas'][i] >= sorted_kappas[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      experiments[i].append(str(strat_result['kappas'][i])+chosen_mark)\n",
    "      experiments_means[i][1] += strat_result['kappas'][i]\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['f1s'][i] == sorted_f1s[0]:\n",
    "        if len(sorted_f1s) > 1 and strat_result['f1s'][i] >= sorted_f1s[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      experiments[i].append(str(strat_result['f1s'][i])+chosen_mark)\n",
    "      experiments_means[i][2] += strat_result['f1s'][i]\n",
    "\n",
    "      chosen_mark = \"\"\n",
    "      if strat_result['aucs'][i] == sorted_aucs[0]:\n",
    "        if len(sorted_aucs) > 1 and strat_result['aucs'][i] >= sorted_aucs[1] + difference_val:\n",
    "          chosen_mark = marks[1]\n",
    "        else:\n",
    "          chosen_mark = marks[0]\n",
    "      experiments[i].append(str(strat_result['aucs'][i])+chosen_mark)\n",
    "      experiments_means[i][3] += strat_result['aucs'][i]\n",
    "    header_columns.extend(\n",
    "        [strat_result['name']+(\" (\"+str(strats_amounts[strat_result['name']])+\" cases)\"), 'Kappa', 'F1', 'AUC'])\n",
    "  for i in range(len(experiments_means)):\n",
    "    experiments[i].append(round(experiments_means[i][0]/len(strats_results), 2))\n",
    "    experiments[i].append(round(experiments_means[i][1]/len(strats_results), 2))\n",
    "    experiments[i].append(round(experiments_means[i][2]/len(strats_results), 2))\n",
    "    experiments[i].append(round(experiments_means[i][3]/len(strats_results), 2))\n",
    "  header_columns.extend(\n",
    "        [\"Means\", 'Kappa', 'F1', 'AUC'])\n",
    "  return tabulate(experiments, headers=header_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSy4biHq1tEt",
    "outputId": "91de420a-7122-45f6-a822-861ef2d54127"
   },
   "outputs": [],
   "source": [
    "print(make_table_for_latex_multi_label_experiments(ml_results, Y_val, less_unbalanced_strategies, ml_experiments_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GkJAEwxVNuAH",
    "outputId": "71b45e2d-a6a1-4921-9fda-7bd9320ba9bf"
   },
   "outputs": [],
   "source": [
    "print(make_table_for_latex_multi_label_experiments(ml_results, Y_val, most_unbalanced_strategies, ml_experiments_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0q8nUFyGNvUn",
    "outputId": "d5e82529-83c4-4f04-b162-1bb8f7c125ed"
   },
   "outputs": [],
   "source": [
    "print(make_table_for_latex_multi_label_experiments(ml_results, Y_val, y_keys, ml_experiments_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FJpULNALBso",
    "outputId": "58bfaeb7-19e7-49ac-fd91-552aabceaea5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tutoría entre pares',\n",
       " 'Apoyo fonoaudióloga(o)',\n",
       " 'Apoyo Kinesióloga(o)',\n",
       " 'Apoyo Médico General',\n",
       " 'Apoyo Terapeuta Ocupacional',\n",
       " 'Control Neurólogo',\n",
       " 'Adecuación curricular de objetivos']"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_unbalanced_strategies"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
