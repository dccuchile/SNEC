{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSTMDividedWord.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj9ptIGwtvUt",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "# # !pip install --upgrade gensim\n",
        "# !pip install transformers\n",
        "# # !pip install -U sentence-transformers\n",
        "# # !pip install kornia\n",
        "# # # # !pip install \"torch==1.7.0\"\n",
        "# !pip install flair\n",
        "# !pip install captum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoZY0qQktvU0",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, hamming_loss, confusion_matrix\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertModel, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "# from kornia.losses import BinaryFocalLossWithLogits\n",
        "\n",
        "# from captum.attr import LayerIntegratedGradients\n",
        "# from captum.attr import visualization as viz\n",
        "\n",
        "# import flair\n",
        "# from flair.data import Sentence\n",
        "# from flair.embeddings import (\n",
        "#     TransformerDocumentEmbeddings, \n",
        "#     SentenceTransformerDocumentEmbeddings, \n",
        "#     FlairEmbeddings, \n",
        "#     StackedEmbeddings, \n",
        "#     CharacterEmbeddings, \n",
        "#     DocumentPoolEmbeddings,\n",
        "#     WordEmbeddings,\n",
        "#     TransformerWordEmbeddings)\n",
        "\n",
        "import warnings\n",
        "import traceback\n",
        "\n",
        "import logging\n",
        "# logger = logging.getLogger('flair')\n",
        "# logger.setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypzJyW9AtvU1",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "12a1b0c4-6c4e-43d2-cd14-48e059901583"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jun 23 21:05:40 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  GeForce RTX 2080    Off  | 00000000:03:00.0 Off |                  N/A |\n",
            "|  0%   41C    P0    40W / 260W |      0MiB /  7982MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  GeForce RTX 2080    Off  | 00000000:05:00.0 Off |                  N/A |\n",
            "|  0%   40C    P0    30W / 260W |      0MiB /  7982MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G2-fISXQyfr",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "bf07649a-b407-4cac-bad6-3e5923bff97f"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda:0\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "torch.backends.cudnn.enabled=False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 2 GPU(s) available.\n",
            "We will use the GPU: GeForce RTX 2080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RonQHx7OJfXj"
      },
      "source": [
        "## Preparing Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUgSQCJlNl2r"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdipkFQDJi6p",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "categories_number_words = {\n",
        "        1: \"Apoyo Pedagógico en asignaturas\",\n",
        "        3: \"Apoyo pedagógico personal\",\n",
        "        4: \"Tutoría entre pares\",\n",
        "        7: \"Hacer a la familia partícipe del proceso\",\n",
        "        8: \"Apoyo psicóloga(o)\",\n",
        "        9: \"Apoyo fonoaudióloga(o)\",\n",
        "        10: \"Apoyo Educador(a) Diferencial\",\n",
        "        11: \"Apoyo Kinesióloga(o)\",\n",
        "        12: \"Apoyo Médico General\",\n",
        "        13: \"Apoyo Terapeuta Ocupacional\",\n",
        "        14: \"Control Neurólogo\",\n",
        "        15: \"Apoyo Interdisciplinario\",\n",
        "        16: \"Adecuación curricular de acceso\",\n",
        "        17: \"Adecuación curricular de objetivos\"\n",
        "    }\n",
        "categories_words_number = {v: k for k, v in categories_number_words.items()}\n",
        "\n",
        "diagnoses_codes = {\n",
        "    \"Trastorno específico del lenguaje\": 0,\n",
        "    \"Trastorno por déficit atencional\": 1,\n",
        "    \"Dificultad específica de aprendizaje\": 2,\n",
        "    \"Discapacidad intelectual\": 3,\n",
        "    \"Discapacidad visual\": 4,\n",
        "    \"Trastorno del espectro autista\": 5,\n",
        "    \"Discapacidad auditiva - Hipoacusia\": 6,\n",
        "    \"Funcionamiento intelectual limítrofe\": 7,\n",
        "    \"Síndrome de Down\": 8,\n",
        "    \"Trastorno motor\": 9,\n",
        "    \"Multidéficit\": 10,\n",
        "    \"Retraso global del desarrollo\": 11\n",
        "}\n",
        "\n",
        "diagnoses_keys = list(diagnoses_codes.keys())\n",
        "\n",
        "def transform_diag_to_array(code):\n",
        "    arr = np.zeros(len(diagnoses_keys), dtype=int)\n",
        "    for (index, label) in enumerate(diagnoses_keys):\n",
        "        if diagnoses_codes[label]==code:\n",
        "            arr[index] = 1\n",
        "    return arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69bH3NpmMBFs",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "train_dataset = pd.read_csv('/research/jamunoz/datasets/train_ds.csv', keep_default_na=False)\n",
        "val_dataset = pd.read_csv('/research/jamunoz/datasets/val_ds.csv', keep_default_na=False)\n",
        "test_dataset = pd.read_csv('/research/jamunoz/datasets/test_ds.csv', keep_default_na=False)\n",
        "# train_dataset = pd.read_csv('gdrive/My Drive/magister/train_ds.csv', keep_default_na=False)\n",
        "# val_dataset = pd.read_csv('gdrive/My Drive/magister/val_ds.csv', keep_default_na=False)\n",
        "# test_dataset = pd.read_csv('gdrive/My Drive/magister/test_ds.csv', keep_default_na=False)\n",
        "\n",
        "\n",
        "# Add OHE diagnosis\n",
        "train_OHE_diags = []\n",
        "for diag in train_dataset['Encoded Diagnosis']:\n",
        "    train_OHE_diags.append(transform_diag_to_array(diag))\n",
        "temp_train_diags_df = pd.DataFrame(train_OHE_diags, columns=diagnoses_keys)\n",
        "train_dataset = pd.concat([train_dataset, temp_train_diags_df], axis=1)\n",
        "\n",
        "val_OHE_diags = []\n",
        "for diag in val_dataset['Encoded Diagnosis']:\n",
        "    val_OHE_diags.append(transform_diag_to_array(diag))\n",
        "temp_val_diags_df = pd.DataFrame(val_OHE_diags, columns=diagnoses_keys)\n",
        "val_dataset = pd.concat([val_dataset, temp_val_diags_df], axis=1)\n",
        "\n",
        "test_OHE_diags = []\n",
        "for diag in test_dataset['Encoded Diagnosis']:\n",
        "    test_OHE_diags.append(transform_diag_to_array(diag))\n",
        "temp_test_diags_df = pd.DataFrame(test_OHE_diags, columns=diagnoses_keys)\n",
        "test_dataset = pd.concat([test_dataset, temp_test_diags_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CsWWAVbMHrI",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "# y_keys = list(strat_present.keys())\n",
        "Y_KEYS = list(categories_words_number.keys())\n",
        "\n",
        "# df = pd.DataFrame(data=new_dataset_to_export)\n",
        "# X = df\n",
        "# Y = df[y_keys]\n",
        "X_train = train_dataset.drop(Y_KEYS, axis=1)\n",
        "Y_train = train_dataset[Y_KEYS]\n",
        "X_val = val_dataset.drop(Y_KEYS, axis=1)\n",
        "Y_val = val_dataset[Y_KEYS]\n",
        "X_test = test_dataset.drop(Y_KEYS, axis=1)\n",
        "Y_test = test_dataset[Y_KEYS]\n",
        "\n",
        "strats_amounts = {\n",
        "              'Adecuación curricular de acceso': 2264,\n",
        "              'Hacer a la familia partícipe del proceso': 2048,\n",
        "              'Apoyo Interdisciplinario': 1441, \n",
        "              'Apoyo Educador(a) Diferencial': 1311,\n",
        "              'Apoyo pedagógico personal': 1240,\n",
        "              'Apoyo fonoaudióloga(o)': 378,\n",
        "              'Apoyo psicóloga(o)': 588,\n",
        "              'Apoyo Terapeuta Ocupacional': 153,\n",
        "              'Tutoría entre pares': 350,\n",
        "              'Control Neurólogo': 63,\n",
        "              'Apoyo Médico General': 64,\n",
        "              'Apoyo Kinesióloga(o)': 32,\n",
        "              'Adecuación curricular de objetivos': 281,\n",
        "              'Apoyo Pedagógico en asignaturas': 1314\n",
        "}\n",
        "most_unbalanced_strategies = [strategy for strategy in Y_KEYS if (\n",
        "    strats_amounts[strategy] < (len(X_train) + len(X_val) + len(X_test))*0.15 or strats_amounts[strategy] > (len(X_train) + len(X_val) + len(X_test))*0.85)]\n",
        "less_unbalanced_strategies = [strategy for strategy in Y_KEYS if strategy not in most_unbalanced_strategies]\n",
        "only_one_strat = [Y_KEYS[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONu-YYe8PIlF"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9skDES6aId3",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nymd7231RqJJ",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "class AllJoinedObservationsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      data_row = self.data.iloc[idx]\n",
        "      labels =  data_row[Y_KEYS]\n",
        "\n",
        "      tensor_labels = torch.tensor(labels, dtype=torch.int)\n",
        "      tensor_diags = torch.tensor(data_row[diagnoses_keys], dtype=torch.int)\n",
        "\n",
        "      all_tokens = tokenizer.encode(data_row['All perceptions'],\n",
        "                                    add_special_tokens=False,\n",
        "                                    max_length=tokenizer.model_max_length,\n",
        "                                    padding='max_length',\n",
        "                                    truncation=True,\n",
        "                                    return_tensors=\"pt\")\n",
        "\n",
        "      if data_row['Special Education Teacher Perceptions'] != \"\":\n",
        "        sne_tokens = tokenizer.encode(data_row['Special Education Teacher Perceptions'],\n",
        "                                    add_special_tokens=False,\n",
        "                                    max_length=tokenizer.model_max_length,\n",
        "                                    padding='max_length',\n",
        "                                    truncation=True,\n",
        "                                    return_tensors=\"pt\")\n",
        "      else:\n",
        "        sne_tokens = tokenizer.encode(\"[PAD]\",\n",
        "                                    add_special_tokens=False,\n",
        "                                    max_length=tokenizer.model_max_length,\n",
        "                                    padding='max_length',\n",
        "                                    truncation=True,\n",
        "                                    return_tensors=\"pt\")\n",
        "\n",
        "      if data_row['Speech Therapist Perceptions'] != \"\":\n",
        "        st_tokens = tokenizer.encode(data_row['Speech Therapist Perceptions'],\n",
        "                                    add_special_tokens=False,\n",
        "                                    max_length=tokenizer.model_max_length,\n",
        "                                    padding='max_length',\n",
        "                                    truncation=True,\n",
        "                                    return_tensors=\"pt\")\n",
        "      else:\n",
        "        st_tokens = tokenizer.encode(\"[PAD]\",\n",
        "                                    add_special_tokens=False,\n",
        "                                    max_length=tokenizer.model_max_length,\n",
        "                                    padding='max_length',\n",
        "                                    truncation=True,\n",
        "                                    return_tensors=\"pt\")\n",
        "        \n",
        "      if data_row['Medical Perceptions'] != \"\":\n",
        "        m_tokens = tokenizer.encode(data_row['Medical Perceptions'],\n",
        "                                      add_special_tokens=False,\n",
        "                                      max_length=tokenizer.model_max_length,\n",
        "                                      padding='max_length',\n",
        "                                      truncation=True,\n",
        "                                      return_tensors=\"pt\")\n",
        "      else:\n",
        "        m_tokens = tokenizer.encode(\"[PAD]\",\n",
        "                                      add_special_tokens=False,\n",
        "                                      max_length=tokenizer.model_max_length,\n",
        "                                      padding='max_length',\n",
        "                                      truncation=True,\n",
        "                                      return_tensors=\"pt\")\n",
        "        \n",
        "      if data_row['Psychologist Perceptions'] != \"\":\n",
        "        p_tokens = tokenizer.encode(data_row['Psychologist Perceptions'],\n",
        "                                    add_special_tokens=False,\n",
        "                                    max_length=tokenizer.model_max_length,\n",
        "                                    padding='max_length',\n",
        "                                    truncation=True,\n",
        "                                    return_tensors=\"pt\")\n",
        "      else:\n",
        "        p_tokens = tokenizer.encode(\"[PAD]\",\n",
        "                                    add_special_tokens=False,\n",
        "                                    max_length=tokenizer.model_max_length,\n",
        "                                    padding='max_length',\n",
        "                                    truncation=True,\n",
        "                                    return_tensors=\"pt\")\n",
        "\n",
        "      dict_to_return = dict(\n",
        "          all_tokens=all_tokens,\n",
        "          sne_tokens=sne_tokens,\n",
        "          st_tokens=st_tokens,\n",
        "          p_tokens=p_tokens,\n",
        "          m_tokens=m_tokens,\n",
        "          labels=tensor_labels,\n",
        "          diagnostics=tensor_diags\n",
        "      )\n",
        "\n",
        "      return dict_to_return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kXynftO6NNr"
      },
      "source": [
        "### Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m96W-bR1Is2",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "TRAIN_BATCH_SIZE=1\n",
        "\n",
        "def my_collate1(batches):\n",
        "  modified_batches = []\n",
        "  for batch in batches:\n",
        "    batch_dict = {}\n",
        "    for key, value in batch.items():\n",
        "      batch_dict[key] = value\n",
        "    modified_batches.append(batch_dict)\n",
        "  return modified_batches\n",
        "\n",
        "transformed_train_dataset=AllJoinedObservationsDataset(\n",
        "    train_dataset)\n",
        "\n",
        "transformed_val_dataset=AllJoinedObservationsDataset(\n",
        "    val_dataset)\n",
        "\n",
        "transformed_test_dataset=AllJoinedObservationsDataset(\n",
        "    test_dataset)\n",
        "\n",
        "train_data_loader=DataLoader(\n",
        "    transformed_train_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    collate_fn=my_collate1)\n",
        "\n",
        "val_data_loader=DataLoader(\n",
        "    transformed_val_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    collate_fn=my_collate1)\n",
        "\n",
        "test_data_loader=DataLoader(\n",
        "    transformed_test_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    collate_fn=my_collate1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOLV6bNeo9Fu"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxgILmMRpASj",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "import statistics\n",
        "\n",
        "def get_results(targets, outputs):\n",
        "  TN = 0\n",
        "  TP = 0\n",
        "  FP = 0\n",
        "  FN = 0\n",
        "  for (i, output) in enumerate(outputs):\n",
        "    if output==0:\n",
        "      if targets[i]==0:\n",
        "        TN += 1\n",
        "      else:\n",
        "        FN += 1\n",
        "    else:\n",
        "      if targets[i]==1:\n",
        "        TP += 1\n",
        "      else:\n",
        "        FP += 1\n",
        "  return TP, TN, FP, FN\n",
        "\n",
        "def findMinDiff(arr):\n",
        "    n = len(arr)\n",
        "    arr = sorted(arr)\n",
        "    diff = 0.5\n",
        "    for i in range(n-1):\n",
        "        if arr[i+1] - arr[i] > 0 and arr[i+1] - arr[i] < diff:\n",
        "            diff = arr[i+1] - arr[i]\n",
        "    return diff\n",
        "\n",
        "def get_thresholds(targets, outputs):\n",
        "  best_thresholds = []\n",
        "  for i in range(len(outputs[0])):\n",
        "    real_preds = outputs[:, i]\n",
        "    trues = targets[:, i]\n",
        "    max_g = 0\n",
        "#     max_f1 = 0\n",
        "    delta_threshold = 0.0001 # findMinDiff(real_preds)*0.9\n",
        "    positive_ratio = sum(trues)/len(trues)\n",
        "#     print('pr: ', positive_ratio)\n",
        "    if positive_ratio > 0.6:\n",
        "      local_best = 0\n",
        "      curr_threshold = min(real_preds)\n",
        "#       print(curr_threshold)\n",
        "      while curr_threshold < 1:\n",
        "        preds = [1 if pred > curr_threshold else 0 for pred in real_preds]\n",
        "        tp, tn, fp, fn = get_results(trues, preds)\n",
        "        recall = tp/(tp+fn)\n",
        "        specificity = tn/(tn+fp)\n",
        "        g_mean = np.sqrt(recall*specificity)\n",
        "#         f1 = f1_score(trues, preds)\n",
        "#         print(f1, max_f1, curr_threshold, local_best, tp, tn, fp, fn)\n",
        "        if tp < tn:\n",
        "          break\n",
        "        if g_mean > max_g:\n",
        "#         if f1 > max_f1:\n",
        "          max_g = g_mean\n",
        "#           max_f1 = f1\n",
        "          local_best = curr_threshold\n",
        "        curr_threshold += delta_threshold\n",
        "      best_thresholds.append(local_best)\n",
        "    elif positive_ratio < 0.4:\n",
        "      local_best = 1\n",
        "      curr_threshold = max(real_preds)\n",
        "      while curr_threshold > 0:\n",
        "        preds = [1 if pred > curr_threshold else 0 for pred in real_preds]\n",
        "        tp, tn, fp, fn = get_results(trues, preds)\n",
        "        recall = tp/(tp+fn)\n",
        "        specificity = tn/(tn+fp)\n",
        "        g_mean = np.sqrt(recall*specificity)\n",
        "#         f1 = f1_score(trues, preds)\n",
        "        if tn < tp:\n",
        "          break\n",
        "        if g_mean > max_g:\n",
        "#         if f1 > max_f1:\n",
        "          max_g = g_mean\n",
        "#           max_f1 = f1\n",
        "          local_best = curr_threshold\n",
        "        curr_threshold -= delta_threshold\n",
        "      best_thresholds.append(local_best)\n",
        "    else:\n",
        "      local_best = 0.5\n",
        "      best_thresholds.append(local_best)\n",
        "  return best_thresholds\n",
        "\n",
        "def get_individual_threshold(target, output):\n",
        "    real_preds = output\n",
        "    trues = target\n",
        "    max_g = 0\n",
        "    # max_f1 = 0\n",
        "    delta_threshold = 0.0001 # findMinDiff(real_preds)*0.9\n",
        "    positive_ratio = sum(trues)/len(trues)\n",
        "#     print('pr: ', positive_ratio)\n",
        "    if positive_ratio > 0.5:\n",
        "      local_best = 0\n",
        "      curr_threshold = min(real_preds)\n",
        "#       print(curr_threshold)\n",
        "      while curr_threshold < 1:\n",
        "        preds = [1 if pred > curr_threshold else 0 for pred in real_preds]\n",
        "        tp, tn, fp, fn = get_results(trues, preds)\n",
        "        recall = tp/(tp+fn)\n",
        "        specificity = tn/(tn+fp)\n",
        "        g_mean = np.sqrt(recall*specificity)\n",
        "        # f1 = f1_score(trues, preds)\n",
        "#         print(f1, max_f1, curr_threshold, local_best, tp, tn, fp, fn)\n",
        "        if tp < tn:\n",
        "          break\n",
        "        if g_mean > max_g:\n",
        "        # if f1 > max_f1:\n",
        "          max_g = g_mean\n",
        "          # max_f1 = f1\n",
        "          local_best = curr_threshold\n",
        "        curr_threshold += delta_threshold\n",
        "      return local_best\n",
        "    else:\n",
        "      local_best = 1\n",
        "      curr_threshold = max(real_preds)\n",
        "      while curr_threshold > 0:\n",
        "        preds = [1 if pred > curr_threshold else 0 for pred in real_preds]\n",
        "        tp, tn, fp, fn = get_results(trues, preds)\n",
        "        recall = tp/(tp+fn)\n",
        "        specificity = tn/(tn+fp)\n",
        "        g_mean = np.sqrt(recall*specificity)\n",
        "        # f1 = f1_score(trues, preds)\n",
        "        if tn < tp:\n",
        "          break\n",
        "        if g_mean > max_g:\n",
        "        # if f1 > max_f1:\n",
        "          max_g = g_mean\n",
        "          # max_f1 = f1\n",
        "          local_best = curr_threshold\n",
        "        curr_threshold -= delta_threshold\n",
        "      return local_best\n",
        "    # else:\n",
        "    #   local_best = 0.5\n",
        "    #   return local_best"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gSsCmTCo_Cd",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "def loss_fun(outputs, targets):\n",
        "    loss = nn.BCEWithLogitsLoss()\n",
        "    # loss = BinaryFocalLossWithLogits(alpha=0.25, reduction='mean')\n",
        "    try:\n",
        "      return loss(outputs, targets)\n",
        "    except Exception:\n",
        "      print(outputs, targets)\n",
        "      traceback.print_exc()\n",
        "    # return nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "def individual_evaluation(target, predicted):\n",
        "  individual = {}\n",
        "  for i in range(len(target[0])):\n",
        "    temp_t = target[:, i]\n",
        "    temp_p = predicted[:, i]\n",
        "    diction = dict(\n",
        "        accuracy=accuracy_score(temp_t, temp_p),\n",
        "        f1=f1_score(temp_t, temp_p)\n",
        "    )\n",
        "    individual[str(i)] = diction\n",
        "  return individual\n",
        "\n",
        "def evaluate(target, predicted):\n",
        "    thresholds = get_thresholds(target, predicted)\n",
        "    print('thresholds: ', thresholds)\n",
        "    true_predicted = np.array([[1 if val > thresholds[i] else 0 for (i, val) in enumerate(pred)] for pred in predicted])\n",
        "    accuracy = accuracy_score(target, true_predicted)\n",
        "    macro_f1 = f1_score(target, true_predicted, average='macro')\n",
        "    micro_f1 = f1_score(target, true_predicted, average='micro')\n",
        "    weighted_f1 = f1_score(target, true_predicted, average='weighted')\n",
        "    hl = hamming_loss(target, true_predicted)\n",
        "    js = jaccard_score(target, true_predicted)\n",
        "    macro_js = jaccard_score(target, true_predicted, average=\"macro\")\n",
        "    micro_js = jaccard_score(target, true_predicted, average=\"micro\")\n",
        "    individual = individual_evaluation(target, true_predicted)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"jaccard_score_average\": js,\n",
        "        \"jaccard_score_macro\": macro_js,\n",
        "        \"jaccard_score_micro\": micro_js,\n",
        "        \"macro-f1\": macro_f1,\n",
        "        \"micro-f1\": micro_f1,\n",
        "        \"Hamming Loss\": hl,\n",
        "        \"Individual\": individual\n",
        "    }\n",
        "\n",
        "def individual_evaluation(target, predicted):\n",
        "    threshold = get_individual_threshold(target, predicted)\n",
        "    print('threshold: ',threshold)\n",
        "    true_predicted = np.array([1 if val > threshold else 0 for val in predicted])\n",
        "    default_true_predicted = np.array([1 if val > 0.5 else 0 for val in predicted])\n",
        "    accuracy = accuracy_score(target, true_predicted)\n",
        "    f1 = f1_score(target, true_predicted)\n",
        "    tp, tn, fp, fn = get_results(target, true_predicted)\n",
        "    recall = tp/(tp+fn)\n",
        "    specificity = tn/(tn+fp)\n",
        "    pr = sum(target)/len(target)\n",
        "\n",
        "    default_accuracy = accuracy_score(target, default_true_predicted)\n",
        "    default_f1 = f1_score(target, default_true_predicted)\n",
        "    tp, tn, fp, fn = get_results(target, default_true_predicted)\n",
        "    default_recall = tp/(tp+fn)\n",
        "    default_specificity = tn/(tn+fp)\n",
        "    return {\n",
        "        \"Positive Rate\": pr,\n",
        "        \"threshold\": threshold[0],\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1\": f1,\n",
        "        \"recall\": recall,\n",
        "        \"specificity\": specificity,\n",
        "        \"default_accuracy\": default_accuracy,\n",
        "        \"default_f1\": default_f1,\n",
        "        \"default_recall\": default_recall,\n",
        "        \"default_specificity\": default_specificity,\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwyMs7HnU3px",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "def individual_test(target, predicted, threshold):\n",
        "    true_predicted = np.array([1 if val > threshold else 0 for val in predicted])\n",
        "    default_true_predicted = np.array([1 if val > 0.5 else 0 for val in predicted])\n",
        "    accuracy = accuracy_score(target, true_predicted)\n",
        "    f1 = f1_score(target, true_predicted)\n",
        "    tp, tn, fp, fn = get_results(target, true_predicted)\n",
        "    recall = tp/(tp+fn)\n",
        "    specificity = tn/(tn+fp)\n",
        "    pr = sum(target)/len(target)\n",
        "\n",
        "    default_accuracy = accuracy_score(target, default_true_predicted)\n",
        "    default_f1 = f1_score(target, default_true_predicted)\n",
        "    tp, tn, fp, fn = get_results(target, default_true_predicted)\n",
        "    default_recall = tp/(tp+fn)\n",
        "    default_specificity = tn/(tn+fp)\n",
        "    return {\n",
        "        \"Positive Rate\": pr,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1\": f1,\n",
        "        \"recall\": recall,\n",
        "        \"specificity\": specificity,\n",
        "        \"default_accuracy\": default_accuracy,\n",
        "        \"default_f1\": default_f1,\n",
        "        \"default_recall\": default_recall,\n",
        "        \"default_specificity\": default_specificity,\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X__QjVj_tqcO",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "def individual_eval_loop_fun1(data_loader, model, device, label_index=0):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    losses = []\n",
        "    for batch_idx, batch in enumerate(data_loader):\n",
        "        text = [Sentence(data[\"all_perceptions\"]) for data in batch]\n",
        "        labels = [data[\"labels\"][label_index] for data in batch]\n",
        "        targets = []\n",
        "        if len(labels) > 1:\n",
        "            for label_set in labels:\n",
        "              miniset = []\n",
        "              for label in label_set:\n",
        "                miniset.append(torch.tensor([label]))\n",
        "              targets.append(torch.stack(miniset))\n",
        "        else:\n",
        "            miniset = [torch.tensor([labels[0]])]\n",
        "            targets.append(torch.stack(miniset))\n",
        "        diagnostics = [data[\"diagnostics\"] for data in batch]\n",
        "\n",
        "        # text = torch.cat(text)\n",
        "        targets = torch.cat(targets)\n",
        "        diagnostics = torch.cat(diagnostics)\n",
        "\n",
        "        # ids = text.to(device, dtype=torch.long)\n",
        "        # mask = mask.to(device, dtype=torch.long)\n",
        "        # token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "        diagnostics = diagnostics.to(device, dtype=torch.long)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = torch.stack([model(sentence_inp=text, diagnostics=diagnostics)])\n",
        "            loss = loss_fun(outputs, targets)\n",
        "            losses.append(loss.item())\n",
        "            \n",
        "        outputs = torch.sigmoid(outputs)\n",
        "        fin_targets.append(targets.cpu().detach().numpy())\n",
        "        fin_outputs.append(outputs.cpu().detach().numpy())\n",
        "    return np.concatenate(fin_outputs), np.concatenate(fin_targets), losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO5SwlAgzAvB",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "def individual_test_loop_fun1(data_loader, model, device, label_index=0):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    for batch_idx, batch in enumerate(data_loader):\n",
        "        text = [Sentence(data[\"all_perceptions\"]) for data in batch]\n",
        "        labels = [data[\"labels\"][label_index] for data in batch]\n",
        "        targets = []\n",
        "        if len(labels) > 1:\n",
        "            for label_set in labels:\n",
        "              miniset = []\n",
        "              for label in label_set:\n",
        "                miniset.append(torch.tensor([label]))\n",
        "              targets.append(torch.stack(miniset))\n",
        "        else:\n",
        "            miniset = [torch.tensor([labels[0]])]\n",
        "            targets.append(torch.stack(miniset))\n",
        "        diagnostics = [data[\"diagnostics\"] for data in batch]\n",
        "\n",
        "        # text = torch.cat(text)\n",
        "        targets = torch.cat(targets)\n",
        "        diagnostics = torch.cat(diagnostics)\n",
        "\n",
        "        # ids = text.to(device, dtype=torch.long)\n",
        "        # mask = mask.to(device, dtype=torch.long)\n",
        "        # token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "        diagnostics = diagnostics.to(device, dtype=torch.long)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = torch.stack([model(sentence_inp=text, diagnostics=diagnostics)])\n",
        "            \n",
        "        outputs = torch.sigmoid(outputs)\n",
        "        fin_targets.append(targets.cpu().detach().numpy())\n",
        "        fin_outputs.append(outputs.cpu().detach().numpy())\n",
        "    return np.concatenate(fin_outputs), np.concatenate(fin_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6rXKHuhlRZS"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0JLVz_ulRZT",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "import statistics\n",
        "\n",
        "def get_results(targets, outputs):\n",
        "  TN = 0\n",
        "  TP = 0\n",
        "  FP = 0\n",
        "  FN = 0\n",
        "  for (i, output) in enumerate(outputs):\n",
        "    if output==0:\n",
        "      if targets[i]==0:\n",
        "        TN += 1\n",
        "      else:\n",
        "        FN += 1\n",
        "    else:\n",
        "      if targets[i]==1:\n",
        "        TP += 1\n",
        "      else:\n",
        "        FP += 1\n",
        "  return TP, TN, FP, FN\n",
        "\n",
        "def findMinDiff(arr):\n",
        "    n = len(arr)\n",
        "    arr = sorted(arr)\n",
        "    diff = 0.5\n",
        "    for i in range(n-1):\n",
        "        if arr[i+1] - arr[i] > 0 and arr[i+1] - arr[i] < diff:\n",
        "            diff = arr[i+1] - arr[i]\n",
        "    return diff\n",
        "\n",
        "def get_thresholds(targets, outputs):\n",
        "  best_thresholds = []\n",
        "  for i in range(len(outputs[0])):\n",
        "    real_preds = outputs[:, i]\n",
        "    trues = targets[:, i]\n",
        "    max_g = 0\n",
        "#     max_f1 = 0\n",
        "    delta_threshold = 0.0001 # findMinDiff(real_preds)*0.9\n",
        "    positive_ratio = sum(trues)/len(trues)\n",
        "#     print('pr: ', positive_ratio)\n",
        "    if positive_ratio > 0.6:\n",
        "      local_best = 0\n",
        "      curr_threshold = min(real_preds)\n",
        "#       print(curr_threshold)\n",
        "      while curr_threshold < 1:\n",
        "        preds = [1 if pred > curr_threshold else 0 for pred in real_preds]\n",
        "        tp, tn, fp, fn = get_results(trues, preds)\n",
        "        recall = tp/(tp+fn)\n",
        "        specificity = tn/(tn+fp)\n",
        "        g_mean = np.sqrt(recall*specificity)\n",
        "#         f1 = f1_score(trues, preds)\n",
        "#         print(f1, max_f1, curr_threshold, local_best, tp, tn, fp, fn)\n",
        "        if tp < tn:\n",
        "          break\n",
        "        if g_mean > max_g:\n",
        "#         if f1 > max_f1:\n",
        "          max_g = g_mean\n",
        "#           max_f1 = f1\n",
        "          local_best = curr_threshold\n",
        "        curr_threshold += delta_threshold\n",
        "      best_thresholds.append(local_best)\n",
        "    elif positive_ratio < 0.4:\n",
        "      local_best = 1\n",
        "      curr_threshold = max(real_preds)\n",
        "      while curr_threshold > 0:\n",
        "        preds = [1 if pred > curr_threshold else 0 for pred in real_preds]\n",
        "        tp, tn, fp, fn = get_results(trues, preds)\n",
        "        recall = tp/(tp+fn)\n",
        "        specificity = tn/(tn+fp)\n",
        "        g_mean = np.sqrt(recall*specificity)\n",
        "#         f1 = f1_score(trues, preds)\n",
        "        if tn < tp:\n",
        "          break\n",
        "        if g_mean > max_g:\n",
        "#         if f1 > max_f1:\n",
        "          max_g = g_mean\n",
        "#           max_f1 = f1\n",
        "          local_best = curr_threshold\n",
        "        curr_threshold -= delta_threshold\n",
        "      best_thresholds.append(local_best)\n",
        "    else:\n",
        "      local_best = 0.5\n",
        "      best_thresholds.append(local_best)\n",
        "  return best_thresholds\n",
        "\n",
        "def get_individual_threshold(target, output):\n",
        "    real_preds = output\n",
        "    trues = target\n",
        "    max_g = 0\n",
        "    # max_f1 = 0\n",
        "    delta_threshold = 0.0001 # findMinDiff(real_preds)*0.9\n",
        "    positive_ratio = sum(trues)/len(trues)\n",
        "#     print('pr: ', positive_ratio)\n",
        "    if positive_ratio > 0.5:\n",
        "      local_best = 0\n",
        "      curr_threshold = min(real_preds)\n",
        "#       print(curr_threshold)\n",
        "      while curr_threshold < 1:\n",
        "        preds = [1 if pred > curr_threshold else 0 for pred in real_preds]\n",
        "        tp, tn, fp, fn = get_results(trues, preds)\n",
        "        recall = tp/(tp+fn)\n",
        "        specificity = tn/(tn+fp)\n",
        "        g_mean = np.sqrt(recall*specificity)\n",
        "        # f1 = f1_score(trues, preds)\n",
        "#         print(f1, max_f1, curr_threshold, local_best, tp, tn, fp, fn)\n",
        "        if tp < tn:\n",
        "          break\n",
        "        if g_mean > max_g:\n",
        "        # if f1 > max_f1:\n",
        "          max_g = g_mean\n",
        "          # max_f1 = f1\n",
        "          local_best = curr_threshold\n",
        "        curr_threshold += delta_threshold\n",
        "      return local_best\n",
        "    else:\n",
        "      local_best = 1\n",
        "      curr_threshold = max(real_preds)\n",
        "      while curr_threshold > 0:\n",
        "        preds = [1 if pred > curr_threshold else 0 for pred in real_preds]\n",
        "        tp, tn, fp, fn = get_results(trues, preds)\n",
        "        recall = tp/(tp+fn)\n",
        "        specificity = tn/(tn+fp)\n",
        "        g_mean = np.sqrt(recall*specificity)\n",
        "        # f1 = f1_score(trues, preds)\n",
        "        if tn < tp:\n",
        "          break\n",
        "        if g_mean > max_g:\n",
        "        # if f1 > max_f1:\n",
        "          max_g = g_mean\n",
        "          # max_f1 = f1\n",
        "          local_best = curr_threshold\n",
        "        curr_threshold -= delta_threshold\n",
        "      return local_best\n",
        "    # else:\n",
        "    #   local_best = 0.5\n",
        "    #   return local_best"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV9R7Q4elRZU",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "def loss_fun(outputs, targets):\n",
        "    loss = nn.BCEWithLogitsLoss()\n",
        "    # loss = BinaryFocalLossWithLogits(alpha=0.25, reduction='mean')\n",
        "    try:\n",
        "      return loss(outputs, targets)\n",
        "    except Exception:\n",
        "      print(outputs, targets)\n",
        "      traceback.print_exc()\n",
        "    # return nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "def individual_evaluation(target, predicted):\n",
        "  individual = {}\n",
        "  for i in range(len(target[0])):\n",
        "    temp_t = target[:, i]\n",
        "    temp_p = predicted[:, i]\n",
        "    diction = dict(\n",
        "        accuracy=accuracy_score(temp_t, temp_p),\n",
        "        f1=f1_score(temp_t, temp_p)\n",
        "    )\n",
        "    individual[str(i)] = diction\n",
        "  return individual\n",
        "\n",
        "def evaluate(target, predicted):\n",
        "    thresholds = get_thresholds(target, predicted)\n",
        "    print('thresholds: ', thresholds)\n",
        "    true_predicted = np.array([[1 if val > thresholds[i] else 0 for (i, val) in enumerate(pred)] for pred in predicted])\n",
        "    accuracy = accuracy_score(target, true_predicted)\n",
        "    macro_f1 = f1_score(target, true_predicted, average='macro')\n",
        "    micro_f1 = f1_score(target, true_predicted, average='micro')\n",
        "    weighted_f1 = f1_score(target, true_predicted, average='weighted')\n",
        "    hl = hamming_loss(target, true_predicted)\n",
        "    js = jaccard_score(target, true_predicted)\n",
        "    macro_js = jaccard_score(target, true_predicted, average=\"macro\")\n",
        "    micro_js = jaccard_score(target, true_predicted, average=\"micro\")\n",
        "    individual = individual_evaluation(target, true_predicted)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"jaccard_score_average\": js,\n",
        "        \"jaccard_score_macro\": macro_js,\n",
        "        \"jaccard_score_micro\": micro_js,\n",
        "        \"macro-f1\": macro_f1,\n",
        "        \"micro-f1\": micro_f1,\n",
        "        \"Hamming Loss\": hl,\n",
        "        \"Individual\": individual\n",
        "    }\n",
        "\n",
        "def individual_evaluation(target, predicted):\n",
        "    threshold = get_individual_threshold(target, predicted)\n",
        "    print('threshold: ',threshold)\n",
        "    true_predicted = np.array([1 if val > threshold else 0 for val in predicted])\n",
        "    default_true_predicted = np.array([1 if val > 0.5 else 0 for val in predicted])\n",
        "    accuracy = accuracy_score(target, true_predicted)\n",
        "    f1 = f1_score(target, true_predicted)\n",
        "    tp, tn, fp, fn = get_results(target, true_predicted)\n",
        "    recall = tp/(tp+fn)\n",
        "    specificity = tn/(tn+fp)\n",
        "    pr = sum(target)/len(target)\n",
        "\n",
        "    default_accuracy = accuracy_score(target, default_true_predicted)\n",
        "    default_f1 = f1_score(target, default_true_predicted)\n",
        "    tp, tn, fp, fn = get_results(target, default_true_predicted)\n",
        "    default_recall = tp/(tp+fn)\n",
        "    default_specificity = tn/(tn+fp)\n",
        "    return {\n",
        "        \"Positive Rate\": pr,\n",
        "        \"threshold\": threshold[0],\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1\": f1,\n",
        "        \"recall\": recall,\n",
        "        \"specificity\": specificity,\n",
        "        \"default_accuracy\": default_accuracy,\n",
        "        \"default_f1\": default_f1,\n",
        "        \"default_recall\": default_recall,\n",
        "        \"default_specificity\": default_specificity,\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJWqxg5slRZW",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "def individual_test(target, predicted, threshold):\n",
        "    true_predicted = np.array([1 if val > threshold else 0 for val in predicted])\n",
        "    default_true_predicted = np.array([1 if val > 0.5 else 0 for val in predicted])\n",
        "    accuracy = accuracy_score(target, true_predicted)\n",
        "    f1 = f1_score(target, true_predicted)\n",
        "    tp, tn, fp, fn = get_results(target, true_predicted)\n",
        "    recall = tp/(tp+fn)\n",
        "    specificity = tn/(tn+fp)\n",
        "    pr = sum(target)/len(target)\n",
        "\n",
        "    default_accuracy = accuracy_score(target, default_true_predicted)\n",
        "    default_f1 = f1_score(target, default_true_predicted)\n",
        "    tp, tn, fp, fn = get_results(target, default_true_predicted)\n",
        "    default_recall = tp/(tp+fn)\n",
        "    default_specificity = tn/(tn+fp)\n",
        "    return {\n",
        "        \"Positive Rate\": pr,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1\": f1,\n",
        "        \"recall\": recall,\n",
        "        \"specificity\": specificity,\n",
        "        \"default_accuracy\": default_accuracy,\n",
        "        \"default_f1\": default_f1,\n",
        "        \"default_recall\": default_recall,\n",
        "        \"default_specificity\": default_specificity,\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WUZvwDfeUNH"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHnUFWgDNE3Y",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "class Divided_Model(nn.Module):\n",
        "\n",
        "  def __init__(self, embedding_model, n_diags):\n",
        "    super(Divided_Model, self).__init__()\n",
        "\n",
        "    # Pass the flair\n",
        "    self.embedding_model = embedding_model\n",
        "\n",
        "    self.n_diags = n_diags\n",
        "        \n",
        "    self.embedding_model.eval()\n",
        "    self.embedding_model.zero_grad()\n",
        "\n",
        "    self.lstm_output = 100\n",
        "\n",
        "    self.lstm = nn.LSTM(768, self.lstm_output, num_layers=1, bidirectional=True)\n",
        "    self.out = nn.Linear( self.lstm_output*2 + n_diags, 1)\n",
        "\n",
        "  def forward(self, input_ids_sne, input_ids_st, input_ids_p, input_ids_m, diags):\n",
        "    # print(input_ids_sne.size(), input_ids_st.size(), input_ids_p.size(), input_ids_m.size())\n",
        "    output_sne = self.embedding_model(input_ids=input_ids_sne).pooler_output\n",
        "    output_st = self.embedding_model(input_ids=input_ids_st).pooler_output\n",
        "    output_p = self.embedding_model(input_ids=input_ids_p).pooler_output\n",
        "    output_m = self.embedding_model(input_ids=input_ids_m).pooler_output\n",
        "\n",
        "    b = torch.stack([output_sne, output_st, output_p, output_m])\n",
        "\n",
        "    # b = sequence_output.transpose(0, 1)\n",
        "    packed_output, (h_t, h_c) = self.lstm(b, )\n",
        "    hidden = torch.cat((h_t[0],h_t[1]),dim=1)\n",
        "    output = torch.cat((hidden, diags), dim=1)\n",
        "    output = self.out(output)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQlIvkA_o2Pu",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "def individual_train_loop_fun1(data_loader, model, optimizer, device, grad_accs, scheduler=None, label_index=0):\n",
        "    model.train()\n",
        "    t0 = time.time()\n",
        "    losses = []\n",
        "    optimizer.zero_grad()\n",
        "    for batch_idx, batch in enumerate(data_loader):\n",
        "        text_sne = [data[\"sne_tokens\"] for data in batch]\n",
        "        text_st = [data[\"st_tokens\"] for data in batch]\n",
        "        text_p = [data[\"p_tokens\"] for data in batch]\n",
        "        text_m = [data[\"m_tokens\"] for data in batch]\n",
        "        labels = [data[\"labels\"][label_index] for data in batch]\n",
        "        targets = []\n",
        "        if len(labels) > 1:\n",
        "            for label_set in labels:\n",
        "              miniset = []\n",
        "              for label in label_set:\n",
        "                miniset.append(torch.tensor([label]))\n",
        "              targets.append(torch.stack(miniset))\n",
        "        else:\n",
        "            miniset = [torch.tensor([labels[0]])]\n",
        "            targets.append(torch.stack(miniset))\n",
        "        diagnostics = [data[\"diagnostics\"] for data in batch]\n",
        "\n",
        "        text_sne = torch.cat(text_sne)\n",
        "        text_sne = text_sne.to(device, dtype=torch.long)\n",
        "\n",
        "        text_st = torch.cat(text_st)\n",
        "        text_st = text_st.to(device, dtype=torch.long)\n",
        "        \n",
        "        text_p = torch.cat(text_p)\n",
        "        text_p = text_p.to(device, dtype=torch.long)\n",
        "        \n",
        "        text_m = torch.cat(text_m)\n",
        "        text_m = text_m.to(device, dtype=torch.long)\n",
        "\n",
        "        # text = torch.cat(text)\n",
        "        targets = torch.cat(targets)\n",
        "        diagnostics = torch.cat(diagnostics)\n",
        "        diagnostics = torch.stack([diagnostics])\n",
        "\n",
        "        # ids = text.to(device, dtype=torch.long)\n",
        "        # mask = mask.to(device, dtype=torch.long)\n",
        "        # token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "        diagnostics = diagnostics.to(device, dtype=torch.long)\n",
        "\n",
        "\n",
        "        outputs = model(input_ids_sne=text_sne, input_ids_st=text_st, input_ids_p=text_p, input_ids_m=text_m, diags=diagnostics)\n",
        "        # outputs = torch.cat(torch.unbind(outputs))\n",
        "        loss = loss_fun(outputs, targets)\n",
        "        (loss / grad_accs).backward()\n",
        "        model.float()\n",
        "        if (batch_idx + 1) % grad_accs == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            if scheduler:\n",
        "                scheduler.step()\n",
        "        losses.append(loss.item())\n",
        "        if batch_idx % 250 == 0:\n",
        "            print(\n",
        "                f\"___ batch index = {batch_idx} / {len(data_loader)} ({100*batch_idx / len(data_loader):.2f}%), loss = {np.mean(losses[-10:]):.4f}, time = {time.time()-t0:.2f} seconds ___\")\n",
        "            t0 = time.time()\n",
        "    return losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4PXFBR_0Kr3",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "def individual_eval_loop_fun1(data_loader, model, device, label_index=0):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    losses = []\n",
        "    for batch_idx, batch in enumerate(data_loader):\n",
        "        text_sne = [data[\"sne_tokens\"] for data in batch]\n",
        "        text_st = [data[\"st_tokens\"] for data in batch]\n",
        "        text_p = [data[\"p_tokens\"] for data in batch]\n",
        "        text_m = [data[\"m_tokens\"] for data in batch]\n",
        "        labels = [data[\"labels\"][label_index] for data in batch]\n",
        "        targets = []\n",
        "        if len(labels) > 1:\n",
        "            for label_set in labels:\n",
        "              miniset = []\n",
        "              for label in label_set:\n",
        "                miniset.append(torch.tensor([label]))\n",
        "              targets.append(torch.stack(miniset))\n",
        "        else:\n",
        "            miniset = [torch.tensor([labels[0]])]\n",
        "            targets.append(torch.stack(miniset))\n",
        "        diagnostics = [data[\"diagnostics\"] for data in batch]\n",
        "\n",
        "        text_sne = torch.cat(text_sne)\n",
        "        text_sne = text_sne.to(device, dtype=torch.long)\n",
        "\n",
        "        text_st = torch.cat(text_st)\n",
        "        text_st = text_st.to(device, dtype=torch.long)\n",
        "        \n",
        "        text_p = torch.cat(text_p)\n",
        "        text_p = text_p.to(device, dtype=torch.long)\n",
        "        \n",
        "        text_m = torch.cat(text_m)\n",
        "        text_m = text_m.to(device, dtype=torch.long)\n",
        "\n",
        "        # text = torch.cat(text)\n",
        "        targets = torch.cat(targets)\n",
        "        diagnostics = torch.cat(diagnostics)\n",
        "        diagnostics = torch.stack([diagnostics])\n",
        "\n",
        "        # ids = text.to(device, dtype=torch.long)\n",
        "        # mask = mask.to(device, dtype=torch.long)\n",
        "        # token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "        diagnostics = diagnostics.to(device, dtype=torch.long)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids_sne=text_sne, input_ids_st=text_st, input_ids_p=text_p, input_ids_m=text_m, diags=diagnostics)\n",
        "            loss = loss_fun(outputs, targets)\n",
        "            losses.append(loss.item())\n",
        "            \n",
        "        outputs = torch.sigmoid(outputs)\n",
        "        fin_targets.append(targets.cpu().detach().numpy())\n",
        "        fin_outputs.append(outputs.cpu().detach().numpy())\n",
        "    return np.concatenate(fin_outputs), np.concatenate(fin_targets), losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBuUOJQKSX3w",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "def individual_test_loop_fun1(data_loader, model, device, label_index=0):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    for batch_idx, batch in enumerate(data_loader):\n",
        "        text_sne = [data[\"sne_tokens\"] for data in batch]\n",
        "        text_st = [data[\"st_tokens\"] for data in batch]\n",
        "        text_p = [data[\"p_tokens\"] for data in batch]\n",
        "        text_m = [data[\"m_tokens\"] for data in batch]\n",
        "        labels = [data[\"labels\"][label_index] for data in batch]\n",
        "        targets = []\n",
        "        if len(labels) > 1:\n",
        "            for label_set in labels:\n",
        "              miniset = []\n",
        "              for label in label_set:\n",
        "                miniset.append(torch.tensor([label]))\n",
        "              targets.append(torch.stack(miniset))\n",
        "        else:\n",
        "            miniset = [torch.tensor([labels[0]])]\n",
        "            targets.append(torch.stack(miniset))\n",
        "        diagnostics = [data[\"diagnostics\"] for data in batch]\n",
        "\n",
        "        text_sne = torch.cat(text_sne)\n",
        "        text_sne = text_sne.to(device, dtype=torch.long)\n",
        "\n",
        "        text_st = torch.cat(text_st)\n",
        "        text_st = text_st.to(device, dtype=torch.long)\n",
        "        \n",
        "        text_p = torch.cat(text_p)\n",
        "        text_p = text_p.to(device, dtype=torch.long)\n",
        "        \n",
        "        text_m = torch.cat(text_m)\n",
        "        text_m = text_m.to(device, dtype=torch.long)\n",
        "\n",
        "        # text = torch.cat(text)\n",
        "        targets = torch.cat(targets)\n",
        "        diagnostics = torch.cat(diagnostics)\n",
        "        diagnostics = torch.stack([diagnostics])\n",
        "\n",
        "        # ids = text.to(device, dtype=torch.long)\n",
        "        # mask = mask.to(device, dtype=torch.long)\n",
        "        # token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "        diagnostics = diagnostics.to(device, dtype=torch.long)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids_sne=text_sne, input_ids_st=text_st, input_ids_p=text_p, input_ids_m=text_m, diags=diagnostics)\n",
        "            \n",
        "        outputs = torch.sigmoid(outputs)\n",
        "        fin_targets.append(targets.cpu().detach().numpy())\n",
        "        fin_outputs.append(outputs.cpu().detach().numpy())\n",
        "    return np.concatenate(fin_outputs), np.concatenate(fin_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW9_dVtuqyem",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "class Single_Flair_Model(nn.Module):\n",
        "    \"\"\" A Model for bert fine tuning \"\"\"\n",
        "\n",
        "    def __init__(self, n_diags, embedding):\n",
        "        super(Single_Flair_Model, self).__init__()\n",
        "        self.embedding = embedding\n",
        "        self.lstm = nn.LSTM(embedding.embedding_length, 100, num_layers=1, bidirectional=True)\n",
        "        self.out = nn.Linear(100 + n_diags, 1)\n",
        "\n",
        "    def forward(self, sentence_inp, diagnostics):\n",
        "        self.embedding.embed(sentence_inp)\n",
        "        emb = [sentence.get_embedding() for sentence in sentence_inp]\n",
        "        b = torch.stack([torch.stack(emb)])\n",
        "        b = b.transpose(0, 1)\n",
        "        packed_output, (h_t, h_c) = self.lstm(b, )\n",
        "        h_t = h_t.view(-1, 100)\n",
        "        output = torch.cat((h_t[0], diagnostics), dim=0)\n",
        "        output = self.out(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "r217R3FONVnB"
      },
      "source": [
        "class Single_Flair_Model_Divided(nn.Module):\n",
        "\n",
        "    def __init__(self, n_diags):\n",
        "        super(Single_Flair_Model_Divided, self).__init__()\n",
        "        self.embedding = TransformerDocumentEmbeddings(\"dccuchile/bert-base-spanish-wwm-cased\", fine_tune=True, layers='-1')\n",
        "        # self.lstm = nn.LSTM(768*4, 100, num_layers=1, bidirectional=True)\n",
        "        self.out = nn.Linear(768*4 + n_diags, 1)\n",
        "        # self.relu = nn.ReLU()\n",
        "        # self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, sentence_snt_inp, sentence_st_inp, sentence_p_inp, sentence_m_inp, diagnostics):\n",
        "        self.embedding.embed(sentence_snt_inp)\n",
        "        self.embedding.embed(sentence_st_inp)\n",
        "        self.embedding.embed(sentence_p_inp)\n",
        "        self.embedding.embed(sentence_m_inp)\n",
        "        emb = [torch.cat([\n",
        "                          sentence_snt_inp[i].get_embedding(), \n",
        "                          sentence_st_inp[i].get_embedding(),\n",
        "                          sentence_p_inp[i].get_embedding(),\n",
        "                          sentence_m_inp[i].get_embedding()]) for i in range(len(sentence_snt_inp))]\n",
        "        # b = torch.stack([torch.stack(emb)])\n",
        "        # b = b.transpose(0, 1)\n",
        "        #packed_output, (h_t, h_c) = self.lstm(b, )\n",
        "        # h_t = h_t.view(-1, 100)\n",
        "        # output = torch.cat((h_t[0], diagnostics), dim=0)\n",
        "        output = torch.stack(emb)\n",
        "        output = torch.cat((output, diagnostics), dim=1)\n",
        "        output = self.out(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AN5rzlrqj_O",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true,
        "outputId": "5db33bbd-02e8-4e1b-f675-5d455e53b8ef"
      },
      "source": [
        "EPOCH = 40\n",
        "GRADIENT_ACCUMULATIONS = 8\n",
        "lr = 1e-6\n",
        "labels_to_ignore = [7, 8, 9, 10]\n",
        "\n",
        "for (index, label) in enumerate(Y_KEYS):\n",
        "    if index not in labels_to_ignore:\n",
        "        print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Para label: ', label, ' ', index,'%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
        "        LABEL_INDEX = index\n",
        "        emb_model = torch.load(\"/research/jamunoz/models/flair_fine_tuning/d_model_ft_\"+str(LABEL_INDEX)+\".pt\", map_location=device)\n",
        "        num_training_steps=int(len(transformed_train_dataset) / TRAIN_BATCH_SIZE * EPOCH)\n",
        "\n",
        "        model=Divided_Model(embedding_model=emb_model.embedding.model, n_diags=len(diagnoses_keys)).to(device) # Bert_FT_Model(len(Y_KEYS)).to(device)\n",
        "        optimizer=AdamW(model.parameters(), lr=lr)\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps=0,\n",
        "                                              num_training_steps=num_training_steps)\n",
        "        val_losses=[]\n",
        "        batches_losses=[]\n",
        "        val_acc=[]\n",
        "\n",
        "        best_model = None\n",
        "        best_f1 = 0\n",
        "        best_th = 0\n",
        "\n",
        "        patience = 0\n",
        "\n",
        "        for epoch in range(EPOCH):\n",
        "          t0 = time.time()    \n",
        "          print(f\"\\n=============== EPOCH {epoch+1} / {EPOCH} ===============\\n\")\n",
        "          # Modify according to individual or all\n",
        "          batches_losses_tmp=individual_train_loop_fun1(train_data_loader, model, optimizer, device, GRADIENT_ACCUMULATIONS, scheduler=scheduler, label_index=LABEL_INDEX)\n",
        "          epoch_loss=np.mean(batches_losses_tmp)\n",
        "          print(f\"\\n*** avg_loss : {epoch_loss:.2f}, time : ~{(time.time()-t0)//60} min ({time.time()-t0:.2f} sec) ***\\n\")\n",
        "          t1=time.time()\n",
        "          # Modify according to individual or all\n",
        "          output, target, val_losses_tmp=individual_eval_loop_fun1(val_data_loader, model, device, label_index=LABEL_INDEX)\n",
        "          print(f\"==> evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {time.time()-t1:.2f} sec\\n\")\n",
        "          # Modify according to individual or all\n",
        "          tmp_evaluate=individual_evaluation(target, output)\n",
        "          if epoch == 0:\n",
        "              torch.save(model, \n",
        "                           f\"/research/jamunoz/models/flair_fine_tuning/d_lstm_model_\"+str(LABEL_INDEX)+\"_v4.pt\")\n",
        "        #       best_model = model\n",
        "        #       best_f1 = tmp_evaluate['f1']\n",
        "              best_th = tmp_evaluate['threshold']\n",
        "              best_f1 = tmp_evaluate['f1']\n",
        "          else:\n",
        "              if tmp_evaluate['f1'] > best_f1 and tmp_evaluate['recall'] != 0 and tmp_evaluate['specificity'] != 0:\n",
        "        #         del best_model\n",
        "        #         torch.cuda.empty_cache()\n",
        "        #         best_model = model\n",
        "                best_f1 = tmp_evaluate['f1']\n",
        "                os.remove(\"/research/jamunoz/models/flair_fine_tuning/d_lstm_model_\"+str(LABEL_INDEX)+\"_v4.pt\")\n",
        "                torch.save(model, \n",
        "                           f\"/research/jamunoz/models/flair_fine_tuning/d_lstm_model_\"+str(LABEL_INDEX)+\"_v4.pt\")\n",
        "                best_th = tmp_evaluate[\"threshold\"]\n",
        "              else:\n",
        "                patience += 1\n",
        "                if patience == 5:\n",
        "                    print(\"model did not progress for 5 followed epochs\")\n",
        "                    break\n",
        "          print(f\"=====>\\t{tmp_evaluate}\")\n",
        "          th = tmp_evaluate[\"threshold\"]\n",
        "          val_acc.append(tmp_evaluate['accuracy'])\n",
        "          val_losses.append(val_losses_tmp)\n",
        "          batches_losses.append(batches_losses_tmp)\n",
        "\n",
        "        del model, optimizer, scheduler\n",
        "        torch.cuda.empty_cache()\n",
        "        best_model = torch.load(\"/research/jamunoz/models/flair_fine_tuning/d_lstm_model_\"+str(LABEL_INDEX)+\"_v4.pt\", map_location=device)\n",
        "\n",
        "        output, target=individual_test_loop_fun1(test_data_loader, best_model, device, label_index=LABEL_INDEX)\n",
        "        tmp_test=individual_test(target, output, best_th)\n",
        "        print(\"-----------------BEST TH: \", th)\n",
        "        print(\"-----------------TEST EVALUATION\", tmp_test)\n",
        "        del best_model\n",
        "        torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Para label:  Apoyo Pedagógico en asignaturas   0 %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "\n",
            "=============== EPOCH 1 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.8678, time = 0.71 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.7692, time = 84.96 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6403, time = 84.78 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5678, time = 84.38 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7154, time = 85.17 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.6933, time = 84.50 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6757, time = 84.56 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7861, time = 85.16 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (623.47 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.68, time : 75.79 sec\n",
            "\n",
            "threshold:  [0.41853264]\n",
            "=====>\t{'Positive Rate': array([0.4332784], dtype=float32), 'threshold': 0.41853264, 'accuracy': 0.5354200988467874, 'f1': 0.5361842105263157, 'recall': 0.6197718631178707, 'specificity': 0.47093023255813954, 'default_accuracy': 0.57166392092257, 'default_f1': 0.029850746268656716, 'default_recall': 0.015209125475285171, 'default_specificity': 0.997093023255814}\n",
            "\n",
            "=============== EPOCH 2 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.5485, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.7913, time = 85.10 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6635, time = 84.82 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5621, time = 84.42 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7604, time = 85.23 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.6957, time = 84.57 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6813, time = 84.63 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7195, time = 85.21 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (623.55 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.67, time : 75.86 sec\n",
            "\n",
            "threshold:  [0.40944523]\n",
            "=====>\t{'Positive Rate': array([0.4332784], dtype=float32), 'threshold': 0.40944523, 'accuracy': 0.5387149917627677, 'f1': 0.5394736842105263, 'recall': 0.623574144486692, 'specificity': 0.4738372093023256, 'default_accuracy': 0.5749588138385503, 'default_f1': 0.044444444444444446, 'default_recall': 0.022813688212927757, 'default_specificity': 0.997093023255814}\n",
            "\n",
            "=============== EPOCH 3 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.5529, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.7960, time = 85.08 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6682, time = 84.80 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5661, time = 84.41 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7649, time = 85.22 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.6840, time = 84.92 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6777, time = 84.90 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7506, time = 85.48 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (624.48 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.67, time : 76.35 sec\n",
            "\n",
            "threshold:  [0.42754903]\n",
            "=====>\t{'Positive Rate': array([0.4332784], dtype=float32), 'threshold': 0.42754903, 'accuracy': 0.5683690280065898, 'f1': 0.5690789473684211, 'recall': 0.6577946768060836, 'specificity': 0.5, 'default_accuracy': 0.6177924217462932, 'default_f1': 0.24183006535947713, 'default_recall': 0.14068441064638784, 'default_specificity': 0.9825581395348837}\n",
            "\n",
            "=============== EPOCH 4 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.5835, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.8036, time = 85.48 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6664, time = 85.30 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5573, time = 84.90 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7579, time = 85.72 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.6983, time = 85.06 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6829, time = 85.11 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7224, time = 85.69 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (627.02 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.67, time : 76.71 sec\n",
            "\n",
            "threshold:  [0.405227]\n",
            "=====>\t{'Positive Rate': array([0.4332784], dtype=float32), 'threshold': 0.405227, 'accuracy': 0.5387149917627677, 'f1': 0.5394736842105263, 'recall': 0.623574144486692, 'specificity': 0.4738372093023256, 'default_accuracy': 0.6112026359143328, 'default_f1': 0.2236842105263158, 'default_recall': 0.12927756653992395, 'default_specificity': 0.9796511627906976}\n",
            "\n",
            "=============== EPOCH 5 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.5281, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.8027, time = 85.60 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6657, time = 85.31 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5551, time = 84.91 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7689, time = 85.72 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.6927, time = 85.06 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.7043, time = 85.11 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7416, time = 85.70 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (627.17 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.67, time : 76.73 sec\n",
            "\n",
            "threshold:  [0.43883175]\n",
            "=====>\t{'Positive Rate': array([0.4332784], dtype=float32), 'threshold': 0.43883175, 'accuracy': 0.5535420098846787, 'f1': 0.555008210180624, 'recall': 0.6425855513307985, 'specificity': 0.48546511627906974, 'default_accuracy': 0.642504118616145, 'default_f1': 0.45614035087719296, 'default_recall': 0.34600760456273766, 'default_specificity': 0.8691860465116279}\n",
            "\n",
            "=============== EPOCH 6 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.5977, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.7730, time = 85.58 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6654, time = 85.31 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5516, time = 84.92 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7761, time = 85.72 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.6855, time = 85.06 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6987, time = 85.11 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7183, time = 85.71 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (627.17 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.66, time : 76.72 sec\n",
            "\n",
            "threshold:  [0.42544407]\n",
            "=====>\t{'Positive Rate': array([0.4332784], dtype=float32), 'threshold': 0.42544407, 'accuracy': 0.556836902800659, 'f1': 0.5582922824302134, 'recall': 0.6463878326996197, 'specificity': 0.4883720930232558, 'default_accuracy': 0.6342668863261944, 'default_f1': 0.4307692307692308, 'default_recall': 0.3193916349809886, 'default_specificity': 0.875}\n",
            "\n",
            "=============== EPOCH 7 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.5563, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.7770, time = 85.58 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6715, time = 85.30 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5525, time = 84.91 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7791, time = 85.72 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.6905, time = 85.06 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6978, time = 85.12 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7090, time = 85.72 seconds ___\n",
            "\n",
            "*** avg_loss : 0.68, time : ~10.0 min (627.15 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.66, time : 76.72 sec\n",
            "\n",
            "threshold:  [0.41989005]\n",
            "=====>\t{'Positive Rate': array([0.4332784], dtype=float32), 'threshold': 0.41989005, 'accuracy': 0.5601317957166392, 'f1': 0.5615763546798029, 'recall': 0.6501901140684411, 'specificity': 0.49127906976744184, 'default_accuracy': 0.6392092257001647, 'default_f1': 0.42819843342036557, 'default_recall': 0.311787072243346, 'default_specificity': 0.8895348837209303}\n",
            "\n",
            "=============== EPOCH 8 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.5708, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.7654, time = 85.58 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6663, time = 85.31 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5513, time = 84.92 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7783, time = 85.73 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.6865, time = 85.07 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.7078, time = 85.10 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.6708, time = 85.71 seconds ___\n",
            "\n",
            "*** avg_loss : 0.68, time : ~10.0 min (627.14 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.66, time : 76.67 sec\n",
            "\n",
            "threshold:  [0.41623813]\n",
            "model did not progress for 5 followed epochs\n",
            "-----------------BEST TH:  0.41989005\n",
            "-----------------TEST EVALUATION {'Positive Rate': array([0.44425675], dtype=float32), 'accuracy': 0.5067567567567568, 'f1': 0.521311475409836, 'recall': 0.6045627376425855, 'specificity': 0.42857142857142855, 'default_accuracy': 0.5760135135135135, 'default_f1': 0.17704918032786887, 'default_recall': 0.10266159695817491, 'default_specificity': 0.9544072948328267}\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Para label:  Apoyo pedagógico personal   1 %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "\n",
            "=============== EPOCH 1 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.6660, time = 0.35 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6182, time = 85.60 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.5573, time = 85.29 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6768, time = 84.93 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.6339, time = 85.84 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.3184, time = 85.21 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.7564, time = 85.24 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.3530, time = 85.84 seconds ___\n",
            "\n",
            "*** avg_loss : 0.66, time : ~10.0 min (627.77 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.74, time : 76.79 sec\n",
            "\n",
            "threshold:  [0.24316774]\n",
            "=====>\t{'Positive Rate': array([0.4085667], dtype=float32), 'threshold': 0.24316774, 'accuracy': 0.46622734761120266, 'f1': 0.4688524590163935, 'recall': 0.5766129032258065, 'specificity': 0.38997214484679665, 'default_accuracy': 0.5914332784184514, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 2 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.2841, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6123, time = 85.81 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.5366, time = 85.33 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6748, time = 84.92 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.6241, time = 85.61 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.3176, time = 84.45 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6018, time = 84.40 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.3255, time = 85.00 seconds ___\n",
            "\n",
            "*** avg_loss : 0.63, time : ~10.0 min (625.08 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.75, time : 75.86 sec\n",
            "\n",
            "threshold:  [0.2358365]\n",
            "=====>\t{'Positive Rate': array([0.4085667], dtype=float32), 'threshold': 0.2358365, 'accuracy': 0.4958813838550247, 'f1': 0.4967105263157895, 'recall': 0.6088709677419355, 'specificity': 0.4178272980501393, 'default_accuracy': 0.5914332784184514, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 3 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.2713, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6136, time = 85.09 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.5861, time = 84.80 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6614, time = 84.42 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.6131, time = 85.21 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.2960, time = 84.56 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5741, time = 84.68 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.3059, time = 85.28 seconds ___\n",
            "\n",
            "*** avg_loss : 0.61, time : ~10.0 min (623.64 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.77, time : 75.93 sec\n",
            "\n",
            "threshold:  [0.22138752]\n",
            "=====>\t{'Positive Rate': array([0.4085667], dtype=float32), 'threshold': 0.22138752, 'accuracy': 0.46622734761120266, 'f1': 0.46710526315789475, 'recall': 0.5725806451612904, 'specificity': 0.39275766016713093, 'default_accuracy': 0.5914332784184514, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 4 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.2378, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6087, time = 85.12 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6019, time = 84.84 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6639, time = 84.52 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.6201, time = 85.59 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.3230, time = 84.89 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.7790, time = 84.96 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.4613, time = 85.54 seconds ___\n",
            "\n",
            "*** avg_loss : 0.67, time : ~10.0 min (625.16 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.69, time : 76.12 sec\n",
            "\n",
            "threshold:  [0.32405835]\n",
            "=====>\t{'Positive Rate': array([0.4085667], dtype=float32), 'threshold': 0.32405835, 'accuracy': 0.4975288303130148, 'f1': 0.4991789819376027, 'recall': 0.6129032258064516, 'specificity': 0.4178272980501393, 'default_accuracy': 0.5914332784184514, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 5 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.4310, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6096, time = 85.45 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.5249, time = 85.15 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6657, time = 84.75 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.9150, time = 85.54 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.3791, time = 84.90 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.4598, time = 84.93 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.2969, time = 85.53 seconds ___\n",
            "\n",
            "*** avg_loss : 0.64, time : ~10.0 min (625.95 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.77, time : 76.08 sec\n",
            "\n",
            "threshold:  [0.22151552]\n",
            "=====>\t{'Positive Rate': array([0.4085667], dtype=float32), 'threshold': 0.22151552, 'accuracy': 0.47611202635914335, 'f1': 0.4769736842105263, 'recall': 0.5846774193548387, 'specificity': 0.4011142061281337, 'default_accuracy': 0.5914332784184514, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 6 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.2454, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6235, time = 85.41 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.5086, time = 85.14 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6642, time = 84.75 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.5929, time = 85.56 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.3369, time = 84.90 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6060, time = 84.97 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.4636, time = 85.53 seconds ___\n",
            "\n",
            "*** avg_loss : 0.65, time : ~10.0 min (625.94 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.69, time : 76.07 sec\n",
            "\n",
            "threshold:  [0.3384143]\n",
            "=====>\t{'Positive Rate': array([0.4085667], dtype=float32), 'threshold': 0.3384143, 'accuracy': 0.500823723228995, 'f1': 0.5024630541871921, 'recall': 0.6169354838709677, 'specificity': 0.4206128133704735, 'default_accuracy': 0.5914332784184514, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 7 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.4391, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6073, time = 85.41 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.5368, time = 85.15 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6634, time = 84.74 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.9520, time = 85.54 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.7577, time = 84.90 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6027, time = 84.94 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.5198, time = 85.55 seconds ___\n",
            "\n",
            "*** avg_loss : 0.70, time : ~10.0 min (625.93 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.68, time : 76.04 sec\n",
            "\n",
            "threshold:  [0.38337985]\n",
            "=====>\t{'Positive Rate': array([0.4085667], dtype=float32), 'threshold': 0.38337985, 'accuracy': 0.471169686985173, 'f1': 0.47290640394088673, 'recall': 0.5806451612903226, 'specificity': 0.3955431754874652, 'default_accuracy': 0.5914332784184514, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 8 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.5180, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6168, time = 85.43 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.5509, time = 85.16 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6587, time = 84.77 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.9222, time = 85.49 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.7758, time = 84.68 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5978, time = 84.73 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.5305, time = 85.34 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (625.22 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.68, time : 76.10 sec\n",
            "\n",
            "threshold:  [0.39065433]\n",
            "=====>\t{'Positive Rate': array([0.4085667], dtype=float32), 'threshold': 0.39065433, 'accuracy': 0.4695222405271829, 'f1': 0.4703947368421053, 'recall': 0.5766129032258065, 'specificity': 0.3955431754874652, 'default_accuracy': 0.5914332784184514, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 9 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.5379, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6190, time = 85.42 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.5636, time = 85.17 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6629, time = 84.77 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.9161, time = 85.58 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.7865, time = 84.92 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5918, time = 84.95 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.5276, time = 85.55 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (626.07 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.68, time : 76.08 sec\n",
            "\n",
            "threshold:  [0.392507]\n",
            "model did not progress for 5 followed epochs\n",
            "-----------------BEST TH:  0.39065433\n",
            "-----------------TEST EVALUATION {'Positive Rate': array([0.4189189], dtype=float32), 'accuracy': 0.47635135135135137, 'f1': 0.4727891156462585, 'recall': 0.5604838709677419, 'specificity': 0.41569767441860467, 'default_accuracy': 0.581081081081081, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Para label:  Tutoría entre pares   2 %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "\n",
            "=============== EPOCH 1 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.6826, time = 0.34 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.5220, time = 85.42 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7441, time = 85.13 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.4566, time = 84.76 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.2909, time = 85.54 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.2119, time = 84.89 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1608, time = 84.91 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.1322, time = 85.52 seconds ___\n",
            "\n",
            "*** avg_loss : 0.41, time : ~10.0 min (625.87 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.36, time : 75.98 sec\n",
            "\n",
            "threshold:  [0.10295062]\n",
            "=====>\t{'Positive Rate': array([0.11532125], dtype=float32), 'threshold': 0.10295062, 'accuracy': 0.20098846787479407, 'f1': 0.20361247947454844, 'recall': 0.8857142857142857, 'specificity': 0.11173184357541899, 'default_accuracy': 0.8846787479406919, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 2 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1206, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.5461, time = 85.54 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6426, time = 85.39 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.4565, time = 85.00 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.2352, time = 85.79 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1805, time = 85.13 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1475, time = 85.18 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.1223, time = 85.79 seconds ___\n",
            "\n",
            "*** avg_loss : 0.40, time : ~10.0 min (627.60 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.36, time : 76.09 sec\n",
            "\n",
            "threshold:  [0.09600216]\n",
            "=====>\t{'Positive Rate': array([0.11532125], dtype=float32), 'threshold': 0.09600216, 'accuracy': 0.19934102141680396, 'f1': 0.20065789473684212, 'recall': 0.8714285714285714, 'specificity': 0.11173184357541899, 'default_accuracy': 0.8846787479406919, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 3 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1215, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.5479, time = 85.66 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.8333, time = 85.37 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.2962, time = 84.99 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1544, time = 85.80 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1221, time = 85.10 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1065, time = 85.16 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.0964, time = 85.74 seconds ___\n",
            "\n",
            "*** avg_loss : 0.36, time : ~10.0 min (627.59 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.36, time : 76.06 sec\n",
            "\n",
            "threshold:  [0.07709122]\n",
            "=====>\t{'Positive Rate': array([0.11532125], dtype=float32), 'threshold': 0.07709122, 'accuracy': 0.1927512355848435, 'f1': 0.19672131147540986, 'recall': 0.8571428571428571, 'specificity': 0.10614525139664804, 'default_accuracy': 0.8846787479406919, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 4 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.0934, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.5719, time = 85.68 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.8305, time = 85.37 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.4193, time = 84.86 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.2245, time = 85.63 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1636, time = 84.93 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1271, time = 84.99 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.1021, time = 85.58 seconds ___\n",
            "\n",
            "*** avg_loss : 0.40, time : ~10.0 min (626.75 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.36, time : 76.05 sec\n",
            "\n",
            "threshold:  [0.08345509]\n",
            "=====>\t{'Positive Rate': array([0.11532125], dtype=float32), 'threshold': 0.08345509, 'accuracy': 0.20593080724876442, 'f1': 0.20723684210526314, 'recall': 0.9, 'specificity': 0.1154562383612663, 'default_accuracy': 0.8846787479406919, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 5 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1063, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.5709, time = 85.53 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7756, time = 85.22 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.2560, time = 84.87 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1375, time = 85.65 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1212, time = 84.99 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1041, time = 85.04 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.0911, time = 85.60 seconds ___\n",
            "\n",
            "*** avg_loss : 0.37, time : ~10.0 min (626.60 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.36, time : 76.13 sec\n",
            "\n",
            "threshold:  [0.0748888]\n",
            "=====>\t{'Positive Rate': array([0.11532125], dtype=float32), 'threshold': 0.0748888, 'accuracy': 0.2042833607907743, 'f1': 0.2068965517241379, 'recall': 0.9, 'specificity': 0.11359404096834265, 'default_accuracy': 0.8846787479406919, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 6 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.0995, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.5709, time = 85.53 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6440, time = 85.24 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.2640, time = 84.84 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1264, time = 85.62 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1122, time = 84.99 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.0974, time = 85.02 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.0841, time = 85.60 seconds ___\n",
            "\n",
            "*** avg_loss : 0.32, time : ~10.0 min (626.57 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.37, time : 76.13 sec\n",
            "\n",
            "threshold:  [0.06880371]\n",
            "=====>\t{'Positive Rate': array([0.11532125], dtype=float32), 'threshold': 0.06880371, 'accuracy': 0.2042833607907743, 'f1': 0.2068965517241379, 'recall': 0.9, 'specificity': 0.11359404096834265, 'default_accuracy': 0.8846787479406919, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 7 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.0864, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.5849, time = 85.51 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.9676, time = 85.19 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.3815, time = 84.82 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1931, time = 85.64 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1615, time = 84.96 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1315, time = 85.03 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.1024, time = 85.63 seconds ___\n",
            "\n",
            "*** avg_loss : 0.41, time : ~10.0 min (626.51 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.36, time : 76.11 sec\n",
            "\n",
            "threshold:  [0.08081568]\n",
            "model did not progress for 5 followed epochs\n",
            "-----------------BEST TH:  0.06880371\n",
            "-----------------TEST EVALUATION {'Positive Rate': array([0.11824324], dtype=float32), 'accuracy': 0.20101351351351351, 'f1': 0.2023608768971332, 'recall': 0.8571428571428571, 'specificity': 0.11302681992337164, 'default_accuracy': 0.8817567567567568, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Para label:  Hacer a la familia partícipe del proceso   3 %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "\n",
            "=============== EPOCH 1 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.7477, time = 0.34 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6296, time = 85.45 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6282, time = 85.12 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5207, time = 84.71 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.8111, time = 85.53 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5534, time = 84.88 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.4932, time = 84.94 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.3761, time = 85.53 seconds ___\n",
            "\n",
            "*** avg_loss : 0.64, time : ~10.0 min (625.87 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.64, time : 75.93 sec\n",
            "\n",
            "threshold:  [0.75467044]\n",
            "=====>\t{'Positive Rate': array([0.67545307], dtype=float32), 'threshold': 0.75467044, 'accuracy': 0.44481054365733114, 'f1': 0.4429752066115702, 'recall': 0.32682926829268294, 'specificity': 0.6903553299492385, 'default_accuracy': 0.6754530477759473, 'default_f1': 0.8062930186823992, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "\n",
            "=============== EPOCH 2 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.4735, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6377, time = 85.48 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6292, time = 85.18 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5147, time = 84.81 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.8084, time = 85.60 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5449, time = 84.95 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.4983, time = 84.94 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.3746, time = 85.41 seconds ___\n",
            "\n",
            "*** avg_loss : 0.64, time : ~10.0 min (626.03 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.64, time : 76.07 sec\n",
            "\n",
            "threshold:  [0.7566538]\n",
            "=====>\t{'Positive Rate': array([0.67545307], dtype=float32), 'threshold': 0.7566538, 'accuracy': 0.46293245469522243, 'f1': 0.4620462046204621, 'recall': 0.34146341463414637, 'specificity': 0.7157360406091371, 'default_accuracy': 0.6754530477759473, 'default_f1': 0.8062930186823992, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "\n",
            "=============== EPOCH 3 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.4397, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.5964, time = 85.32 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6329, time = 85.02 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5063, time = 84.63 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.8058, time = 85.44 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5314, time = 84.76 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5017, time = 84.81 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.3843, time = 85.68 seconds ___\n",
            "\n",
            "*** avg_loss : 0.64, time : ~10.0 min (625.44 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.64, time : 76.67 sec\n",
            "\n",
            "threshold:  [0.7544172]\n",
            "=====>\t{'Positive Rate': array([0.67545307], dtype=float32), 'threshold': 0.7544172, 'accuracy': 0.44481054365733114, 'f1': 0.4429752066115702, 'recall': 0.32682926829268294, 'specificity': 0.6903553299492385, 'default_accuracy': 0.6754530477759473, 'default_f1': 0.8062930186823992, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "\n",
            "=============== EPOCH 4 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.4817, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6085, time = 86.03 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6330, time = 85.76 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5179, time = 85.31 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.8044, time = 85.92 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5486, time = 85.20 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.4977, time = 85.24 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.3821, time = 85.84 seconds ___\n",
            "\n",
            "*** avg_loss : 0.64, time : ~10.0 min (629.11 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.64, time : 76.20 sec\n",
            "\n",
            "threshold:  [0.7612148]\n",
            "=====>\t{'Positive Rate': array([0.67545307], dtype=float32), 'threshold': 0.7612148, 'accuracy': 0.4464579901153213, 'f1': 0.44554455445544555, 'recall': 0.32926829268292684, 'specificity': 0.6903553299492385, 'default_accuracy': 0.6754530477759473, 'default_f1': 0.8062930186823992, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "\n",
            "=============== EPOCH 5 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.4371, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6167, time = 85.98 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6364, time = 85.73 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5315, time = 85.33 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.8081, time = 86.13 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5410, time = 85.45 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5027, time = 85.49 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.3823, time = 86.10 seconds ___\n",
            "\n",
            "*** avg_loss : 0.64, time : ~10.0 min (630.08 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.64, time : 76.66 sec\n",
            "\n",
            "threshold:  [0.75985026]\n",
            "=====>\t{'Positive Rate': array([0.67545307], dtype=float32), 'threshold': 0.75985026, 'accuracy': 0.4382207578253707, 'f1': 0.43636363636363634, 'recall': 0.32195121951219513, 'specificity': 0.6802030456852792, 'default_accuracy': 0.6754530477759473, 'default_f1': 0.8062930186823992, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "\n",
            "=============== EPOCH 6 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.4647, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.5878, time = 86.02 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6518, time = 85.72 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5025, time = 85.31 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7781, time = 85.69 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5487, time = 85.05 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.4962, time = 85.12 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.4004, time = 85.69 seconds ___\n",
            "\n",
            "*** avg_loss : 0.64, time : ~10.0 min (628.34 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.64, time : 76.64 sec\n",
            "\n",
            "threshold:  [0.7565044]\n",
            "=====>\t{'Positive Rate': array([0.67545307], dtype=float32), 'threshold': 0.7565044, 'accuracy': 0.4497528830313015, 'f1': 0.4414715719063545, 'recall': 0.32195121951219513, 'specificity': 0.7157360406091371, 'default_accuracy': 0.6754530477759473, 'default_f1': 0.8062930186823992, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "\n",
            "=============== EPOCH 7 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.4515, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.5821, time = 85.59 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6418, time = 85.34 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.4982, time = 84.89 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7862, time = 85.69 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5451, time = 85.04 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5020, time = 85.12 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.3934, time = 85.69 seconds ___\n",
            "\n",
            "*** avg_loss : 0.63, time : ~10.0 min (627.12 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.64, time : 76.70 sec\n",
            "\n",
            "threshold:  [0.74876314]\n",
            "model did not progress for 5 followed epochs\n",
            "-----------------BEST TH:  0.7565044\n",
            "-----------------TEST EVALUATION {'Positive Rate': array([0.6908784], dtype=float32), 'accuracy': 0.46790540540540543, 'f1': 0.4705882352941177, 'recall': 0.3422982885085575, 'specificity': 0.7486338797814208, 'default_accuracy': 0.6908783783783784, 'default_f1': 0.8171828171828172, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Para label:  Apoyo psicóloga(o)   4 %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "\n",
            "=============== EPOCH 1 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.6966, time = 0.34 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.4301, time = 85.50 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7275, time = 85.42 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 1.2568, time = 85.08 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7409, time = 85.86 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.4623, time = 85.22 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.2921, time = 85.26 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.2201, time = 85.88 seconds ___\n",
            "\n",
            "*** avg_loss : 0.53, time : ~10.0 min (628.02 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.49, time : 77.02 sec\n",
            "\n",
            "threshold:  [0.17082426]\n",
            "=====>\t{'Positive Rate': array([0.19439869], dtype=float32), 'threshold': 0.17082426, 'accuracy': 0.3228995057660626, 'f1': 0.32512315270935965, 'recall': 0.8389830508474576, 'specificity': 0.1983640081799591, 'default_accuracy': 0.8056013179571664, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 2 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1867, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.1960, time = 85.66 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.8296, time = 85.29 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 1.5946, time = 84.90 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.8582, time = 85.74 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.3911, time = 84.90 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.2740, time = 84.83 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.2179, time = 85.40 seconds ___\n",
            "\n",
            "*** avg_loss : 0.52, time : ~10.0 min (626.37 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.49, time : 76.24 sec\n",
            "\n",
            "threshold:  [0.1657178]\n",
            "=====>\t{'Positive Rate': array([0.19439869], dtype=float32), 'threshold': 0.1657178, 'accuracy': 0.3311367380560132, 'f1': 0.3387622149837134, 'recall': 0.8813559322033898, 'specificity': 0.1983640081799591, 'default_accuracy': 0.8056013179571664, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 3 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.2048, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.2006, time = 85.31 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.8187, time = 85.02 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 1.7029, time = 84.62 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.4806, time = 85.42 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.3079, time = 84.75 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.2314, time = 84.82 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.2011, time = 85.40 seconds ___\n",
            "\n",
            "*** avg_loss : 0.51, time : ~10.0 min (624.98 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.50, time : 76.23 sec\n",
            "\n",
            "threshold:  [0.15094276]\n",
            "=====>\t{'Positive Rate': array([0.19439869], dtype=float32), 'threshold': 0.15094276, 'accuracy': 0.32784184514003295, 'f1': 0.32894736842105265, 'recall': 0.847457627118644, 'specificity': 0.20245398773006135, 'default_accuracy': 0.8056013179571664, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 4 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1798, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.1861, time = 85.32 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.8378, time = 85.00 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 1.5010, time = 84.59 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.5654, time = 85.41 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.3878, time = 84.77 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.2849, time = 84.81 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.2204, time = 85.37 seconds ___\n",
            "\n",
            "*** avg_loss : 0.52, time : ~10.0 min (624.91 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.49, time : 76.23 sec\n",
            "\n",
            "threshold:  [0.1692949]\n",
            "=====>\t{'Positive Rate': array([0.19439869], dtype=float32), 'threshold': 0.1692949, 'accuracy': 0.2899505766062603, 'f1': 0.2991869918699187, 'recall': 0.7796610169491526, 'specificity': 0.17177914110429449, 'default_accuracy': 0.8056013179571664, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 5 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.2067, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.2013, time = 85.29 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.8191, time = 85.01 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 1.7016, time = 84.63 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.6573, time = 85.42 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.3577, time = 84.76 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.2419, time = 84.81 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.1904, time = 85.42 seconds ___\n",
            "\n",
            "*** avg_loss : 0.51, time : ~10.0 min (624.99 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.50, time : 76.25 sec\n",
            "\n",
            "threshold:  [0.15243693]\n",
            "=====>\t{'Positive Rate': array([0.19439869], dtype=float32), 'threshold': 0.15243693, 'accuracy': 0.31466227347611203, 'f1': 0.3224755700325732, 'recall': 0.8389830508474576, 'specificity': 0.18813905930470348, 'default_accuracy': 0.8056013179571664, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 6 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1795, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.1793, time = 85.31 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.8404, time = 85.01 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 1.4353, time = 84.60 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.6555, time = 85.48 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.3646, time = 84.78 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.2030, time = 84.82 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.1673, time = 85.40 seconds ___\n",
            "\n",
            "*** avg_loss : 0.49, time : ~10.0 min (625.07 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.50, time : 76.23 sec\n",
            "\n",
            "threshold:  [0.1317934]\n",
            "=====>\t{'Positive Rate': array([0.19439869], dtype=float32), 'threshold': 0.1317934, 'accuracy': 0.33607907742998355, 'f1': 0.3382594417077176, 'recall': 0.8728813559322034, 'specificity': 0.2065439672801636, 'default_accuracy': 0.8056013179571664, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 7 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1585, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.1961, time = 85.30 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.8540, time = 85.01 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 1.3212, time = 84.63 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.6431, time = 85.43 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.4478, time = 84.75 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.2675, time = 84.84 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.1857, time = 85.40 seconds ___\n",
            "\n",
            "*** avg_loss : 0.51, time : ~10.0 min (625.02 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.50, time : 76.23 sec\n",
            "\n",
            "threshold:  [0.15085806]\n",
            "model did not progress for 5 followed epochs\n",
            "-----------------BEST TH:  0.1317934\n",
            "-----------------TEST EVALUATION {'Positive Rate': array([0.19763513], dtype=float32), 'accuracy': 0.3293918918918919, 'f1': 0.3394342762063227, 'recall': 0.8717948717948718, 'specificity': 0.1957894736842105, 'default_accuracy': 0.8023648648648649, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Para label:  Apoyo fonoaudióloga(o)   5 %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "\n",
            "=============== EPOCH 1 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.8069, time = 0.34 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.4186, time = 85.18 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6323, time = 84.93 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.7492, time = 84.50 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.3669, time = 85.32 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.2527, time = 84.67 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1831, time = 84.70 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.1489, time = 85.31 seconds ___\n",
            "\n",
            "*** avg_loss : 0.44, time : ~10.0 min (624.24 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.38, time : 76.02 sec\n",
            "\n",
            "threshold:  [0.11786257]\n",
            "=====>\t{'Positive Rate': array([0.12520593], dtype=float32), 'threshold': 0.11786257, 'accuracy': 0.21746293245469522, 'f1': 0.22003284072249588, 'recall': 0.881578947368421, 'specificity': 0.1224105461393597, 'default_accuracy': 0.8747940691927513, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 2 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1483, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.1400, time = 85.25 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7327, time = 84.95 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.7560, time = 84.56 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.3762, time = 85.37 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.2700, time = 84.71 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1771, time = 84.74 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.1324, time = 85.36 seconds ___\n",
            "\n",
            "*** avg_loss : 0.42, time : ~10.0 min (624.57 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.37, time : 76.05 sec\n",
            "\n",
            "threshold:  [0.10526246]\n",
            "=====>\t{'Positive Rate': array([0.12520593], dtype=float32), 'threshold': 0.10526246, 'accuracy': 0.21911037891268534, 'f1': 0.2280130293159609, 'recall': 0.9210526315789473, 'specificity': 0.11864406779661017, 'default_accuracy': 0.8747940691927513, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 3 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1480, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.1243, time = 85.23 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7474, time = 84.96 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.4550, time = 84.54 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1595, time = 85.35 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1344, time = 84.70 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1147, time = 84.71 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.0981, time = 85.31 seconds ___\n",
            "\n",
            "*** avg_loss : 0.33, time : ~10.0 min (624.41 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.38, time : 76.11 sec\n",
            "\n",
            "threshold:  [0.0781251]\n",
            "=====>\t{'Positive Rate': array([0.12520593], dtype=float32), 'threshold': 0.0781251, 'accuracy': 0.214168039538715, 'f1': 0.2167487684729064, 'recall': 0.868421052631579, 'specificity': 0.12052730696798493, 'default_accuracy': 0.8747940691927513, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 4 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1069, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.0986, time = 85.20 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7958, time = 84.89 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5062, time = 84.50 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1695, time = 85.81 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1439, time = 85.28 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1201, time = 85.16 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.0987, time = 85.78 seconds ___\n",
            "\n",
            "*** avg_loss : 0.39, time : ~10.0 min (626.42 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.38, time : 76.96 sec\n",
            "\n",
            "threshold:  [0.07957892]\n",
            "=====>\t{'Positive Rate': array([0.12520593], dtype=float32), 'threshold': 0.07957892, 'accuracy': 0.21252059308072488, 'f1': 0.21895424836601307, 'recall': 0.881578947368421, 'specificity': 0.1167608286252354, 'default_accuracy': 0.8747940691927513, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 5 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1181, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.1061, time = 85.65 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7905, time = 85.18 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5254, time = 84.91 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1517, time = 85.51 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1269, time = 84.87 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1063, time = 84.74 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.0932, time = 85.42 seconds ___\n",
            "\n",
            "*** avg_loss : 0.37, time : ~10.0 min (626.14 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.38, time : 76.32 sec\n",
            "\n",
            "threshold:  [0.07706376]\n",
            "=====>\t{'Positive Rate': array([0.12520593], dtype=float32), 'threshold': 0.07706376, 'accuracy': 0.2158154859967051, 'f1': 0.219672131147541, 'recall': 0.881578947368421, 'specificity': 0.12052730696798493, 'default_accuracy': 0.8747940691927513, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 6 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1058, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.1324, time = 85.41 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7924, time = 85.28 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6931, time = 84.78 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.2878, time = 85.35 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.2010, time = 84.88 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1371, time = 84.93 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.1021, time = 85.39 seconds ___\n",
            "\n",
            "*** avg_loss : 0.40, time : ~10.0 min (625.67 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.38, time : 76.51 sec\n",
            "\n",
            "threshold:  [0.08009022]\n",
            "=====>\t{'Positive Rate': array([0.12520593], dtype=float32), 'threshold': 0.080090225, 'accuracy': 0.21746293245469522, 'f1': 0.22003284072249588, 'recall': 0.881578947368421, 'specificity': 0.1224105461393597, 'default_accuracy': 0.8747940691927513, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 7 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1264, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.1006, time = 85.71 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7823, time = 85.34 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.7514, time = 84.90 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1836, time = 85.93 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1639, time = 85.16 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1249, time = 85.15 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.0981, time = 85.73 seconds ___\n",
            "\n",
            "*** avg_loss : 0.40, time : ~10.0 min (627.73 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.38, time : 76.89 sec\n",
            "\n",
            "threshold:  [0.0759531]\n",
            "model did not progress for 5 followed epochs\n",
            "-----------------BEST TH:  0.080090225\n",
            "-----------------TEST EVALUATION {'Positive Rate': array([0.1266892], dtype=float32), 'accuracy': 0.20101351351351351, 'f1': 0.2258592471358429, 'recall': 0.92, 'specificity': 0.09671179883945841, 'default_accuracy': 0.8733108108108109, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Para label:  Apoyo Educador(a) Diferencial   6 %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "\n",
            "=============== EPOCH 1 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.7513, time = 0.37 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6682, time = 85.49 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6237, time = 85.25 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6410, time = 84.77 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7659, time = 85.58 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.7846, time = 84.94 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.4631, time = 85.27 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.6085, time = 86.01 seconds ___\n",
            "\n",
            "*** avg_loss : 0.70, time : ~10.0 min (627.09 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.69, time : 76.83 sec\n",
            "\n",
            "threshold:  [0.36867148]\n",
            "=====>\t{'Positive Rate': array([0.43163097], dtype=float32), 'threshold': 0.36867148, 'accuracy': 0.4942339373970346, 'f1': 0.4958949096880131, 'recall': 0.5763358778625954, 'specificity': 0.4318840579710145, 'default_accuracy': 0.5683690280065898, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 2 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.0212, time = 0.36 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6806, time = 85.88 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6235, time = 85.59 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5349, time = 85.01 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.8392, time = 85.77 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.8228, time = 85.12 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.4986, time = 85.14 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.6221, time = 85.69 seconds ___\n",
            "\n",
            "*** avg_loss : 0.70, time : ~10.0 min (628.14 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.68, time : 76.63 sec\n",
            "\n",
            "threshold:  [0.40394494]\n",
            "=====>\t{'Positive Rate': array([0.43163097], dtype=float32), 'threshold': 0.40394494, 'accuracy': 0.5321252059308073, 'f1': 0.5328947368421052, 'recall': 0.6183206106870229, 'specificity': 0.4666666666666667, 'default_accuracy': 0.5683690280065898, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 3 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.8494, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6663, time = 85.56 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6189, time = 85.40 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5564, time = 84.86 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.8119, time = 85.76 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.8147, time = 85.43 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5551, time = 85.64 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.5642, time = 86.24 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (628.79 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.69, time : 76.70 sec\n",
            "\n",
            "threshold:  [0.34313804]\n",
            "=====>\t{'Positive Rate': array([0.43163097], dtype=float32), 'threshold': 0.34313804, 'accuracy': 0.5354200988467874, 'f1': 0.5361842105263158, 'recall': 0.6221374045801527, 'specificity': 0.46956521739130436, 'default_accuracy': 0.5683690280065898, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 4 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.9763, time = 0.36 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6729, time = 86.09 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6256, time = 85.72 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6022, time = 85.66 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7932, time = 88.47 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.8074, time = 85.13 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.4828, time = 85.11 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.6577, time = 85.58 seconds ___\n",
            "\n",
            "*** avg_loss : 0.70, time : ~10.0 min (631.51 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.68, time : 76.18 sec\n",
            "\n",
            "threshold:  [0.41800237]\n",
            "=====>\t{'Positive Rate': array([0.43163097], dtype=float32), 'threshold': 0.41800237, 'accuracy': 0.5255354200988468, 'f1': 0.5263157894736843, 'recall': 0.6106870229007634, 'specificity': 0.4608695652173913, 'default_accuracy': 0.5683690280065898, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 5 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.8203, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6577, time = 85.54 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6339, time = 85.17 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5869, time = 84.83 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.8078, time = 85.78 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.8016, time = 85.03 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6570, time = 85.14 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.6304, time = 85.60 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (626.91 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.68, time : 76.12 sec\n",
            "\n",
            "threshold:  [0.42966884]\n",
            "=====>\t{'Positive Rate': array([0.43163097], dtype=float32), 'threshold': 0.42966884, 'accuracy': 0.5337726523887973, 'f1': 0.535303776683087, 'recall': 0.6221374045801527, 'specificity': 0.4666666666666667, 'default_accuracy': 0.5914332784184514, 'default_f1': 0.253012048192771, 'default_recall': 0.16030534351145037, 'default_specificity': 0.9188405797101449}\n",
            "\n",
            "=============== EPOCH 6 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.8348, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6784, time = 85.64 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6218, time = 85.78 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5963, time = 85.15 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.8108, time = 85.97 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.8291, time = 85.46 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6884, time = 85.51 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.6015, time = 86.05 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (629.30 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.68, time : 76.21 sec\n",
            "\n",
            "threshold:  [0.42542285]\n",
            "=====>\t{'Positive Rate': array([0.43163097], dtype=float32), 'threshold': 0.42542285, 'accuracy': 0.5189456342668863, 'f1': 0.5197368421052632, 'recall': 0.6030534351145038, 'specificity': 0.45507246376811594, 'default_accuracy': 0.5930807248764415, 'default_f1': 0.2756598240469208, 'default_recall': 0.17938931297709923, 'default_specificity': 0.9072463768115943}\n",
            "\n",
            "=============== EPOCH 7 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.8842, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6828, time = 85.80 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6379, time = 85.42 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5716, time = 85.00 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.8403, time = 86.99 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.8444, time = 85.37 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6247, time = 85.35 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.5951, time = 85.70 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (629.49 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.68, time : 76.38 sec\n",
            "\n",
            "threshold:  [0.3845058]\n",
            "=====>\t{'Positive Rate': array([0.43163097], dtype=float32), 'threshold': 0.3845058, 'accuracy': 0.5205930807248764, 'f1': 0.522167487684729, 'recall': 0.6068702290076335, 'specificity': 0.45507246376811594, 'default_accuracy': 0.5700164744645799, 'default_f1': 0.015094339622641508, 'default_recall': 0.007633587786259542, 'default_specificity': 0.9971014492753624}\n",
            "\n",
            "=============== EPOCH 8 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.8390, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6474, time = 85.61 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6292, time = 85.30 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6628, time = 85.01 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7759, time = 85.75 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.7912, time = 85.34 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.6495, time = 85.90 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.6477, time = 85.85 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (628.64 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.68, time : 76.38 sec\n",
            "\n",
            "threshold:  [0.43483895]\n",
            "model did not progress for 5 followed epochs\n",
            "-----------------BEST TH:  0.3845058\n",
            "-----------------TEST EVALUATION {'Positive Rate': array([0.44256756], dtype=float32), 'accuracy': 0.5337837837837838, 'f1': 0.5619047619047619, 'recall': 0.6755725190839694, 'specificity': 0.4212121212121212, 'default_accuracy': 0.5574324324324325, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Para label:  Apoyo Interdisciplinario   11 %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "\n",
            "=============== EPOCH 1 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.6179, time = 0.40 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6748, time = 86.27 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7697, time = 86.16 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6367, time = 85.37 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7229, time = 85.90 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.7102, time = 85.43 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.7161, time = 85.49 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.9079, time = 86.05 seconds ___\n",
            "\n",
            "*** avg_loss : 0.70, time : ~10.0 min (630.73 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.69, time : 76.30 sec\n",
            "\n",
            "threshold:  [0.49271116]\n",
            "=====>\t{'Positive Rate': array([0.47446457], dtype=float32), 'threshold': 0.49271116, 'accuracy': 0.48599670510708404, 'f1': 0.4901960784313726, 'recall': 0.5208333333333334, 'specificity': 0.45454545454545453, 'default_accuracy': 0.4942339373970346, 'default_f1': 0.40618955512572535, 'default_recall': 0.3645833333333333, 'default_specificity': 0.6112852664576802}\n",
            "\n",
            "=============== EPOCH 2 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.6820, time = 0.35 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6622, time = 85.47 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7758, time = 85.19 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6322, time = 84.86 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7315, time = 85.58 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.7072, time = 85.07 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.7161, time = 85.12 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.8533, time = 85.68 seconds ___\n",
            "\n",
            "*** avg_loss : 0.70, time : ~10.0 min (626.85 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.69, time : 76.09 sec\n",
            "\n",
            "threshold:  [0.5001784]\n",
            "=====>\t{'Positive Rate': array([0.47446457], dtype=float32), 'threshold': 0.5001784, 'accuracy': 0.4876441515650741, 'f1': 0.4893267651888342, 'recall': 0.5173611111111112, 'specificity': 0.4608150470219436, 'default_accuracy': 0.4876441515650741, 'default_f1': 0.4959481361426257, 'default_recall': 0.53125, 'default_specificity': 0.4482758620689655}\n",
            "\n",
            "=============== EPOCH 3 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.6938, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6681, time = 85.56 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7749, time = 85.28 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6332, time = 84.87 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7429, time = 85.78 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.7178, time = 85.10 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.7189, time = 85.18 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.8229, time = 85.97 seconds ___\n",
            "\n",
            "*** avg_loss : 0.70, time : ~10.0 min (627.71 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.70, time : 76.63 sec\n",
            "\n",
            "threshold:  [0.51264983]\n",
            "=====>\t{'Positive Rate': array([0.47446457], dtype=float32), 'threshold': 0.51264983, 'accuracy': 0.5090609555189456, 'f1': 0.5130718954248366, 'recall': 0.5451388888888888, 'specificity': 0.47648902821316613, 'default_accuracy': 0.48599670510708404, 'default_f1': 0.6430205949656751, 'default_recall': 0.9756944444444444, 'default_specificity': 0.0438871473354232}\n",
            "\n",
            "=============== EPOCH 4 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.7158, time = 0.36 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6762, time = 86.08 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7524, time = 85.87 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6376, time = 85.83 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7466, time = 86.44 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.7206, time = 85.88 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.7073, time = 252.54 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7960, time = 22304.35 seconds ___\n",
            "\n",
            "*** avg_loss : 0.70, time : ~383.0 min (23016.84 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.69, time : 76.63 sec\n",
            "\n",
            "threshold:  [0.50519156]\n",
            "=====>\t{'Positive Rate': array([0.47446457], dtype=float32), 'threshold': 0.50519156, 'accuracy': 0.48599670510708404, 'f1': 0.4868421052631579, 'recall': 0.5138888888888888, 'specificity': 0.4608150470219436, 'default_accuracy': 0.5041186161449753, 'default_f1': 0.5801952580195258, 'default_recall': 0.7222222222222222, 'default_specificity': 0.3072100313479624}\n",
            "\n",
            "=============== EPOCH 5 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.7128, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6769, time = 86.22 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7447, time = 86.07 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6421, time = 85.70 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7343, time = 86.67 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.7079, time = 85.89 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.7138, time = 85.99 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7900, time = 86.53 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (633.19 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.69, time : 77.32 sec\n",
            "\n",
            "threshold:  [0.5068451]\n",
            "=====>\t{'Positive Rate': array([0.47446457], dtype=float32), 'threshold': 0.5068451, 'accuracy': 0.4794069192751236, 'f1': 0.48026315789473684, 'recall': 0.5069444444444444, 'specificity': 0.45454545454545453, 'default_accuracy': 0.49917627677100496, 'default_f1': 0.5891891891891892, 'default_recall': 0.7569444444444444, 'default_specificity': 0.2664576802507837}\n",
            "\n",
            "=============== EPOCH 6 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.7090, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6721, time = 86.43 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7424, time = 86.16 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6390, time = 85.82 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7456, time = 86.61 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.7080, time = 85.87 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.7137, time = 85.85 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7731, time = 86.67 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (633.45 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.69, time : 77.41 sec\n",
            "\n",
            "threshold:  [0.5094712]\n",
            "=====>\t{'Positive Rate': array([0.47446457], dtype=float32), 'threshold': 0.5094712, 'accuracy': 0.49917627677100496, 'f1': 0.5, 'recall': 0.5277777777777778, 'specificity': 0.47335423197492166, 'default_accuracy': 0.4876441515650741, 'default_f1': 0.5780189959294437, 'default_recall': 0.7395833333333334, 'default_specificity': 0.2601880877742947}\n",
            "\n",
            "=============== EPOCH 7 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.6955, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.6738, time = 86.44 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.7285, time = 86.28 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.6591, time = 85.87 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.7461, time = 86.66 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.7214, time = 85.79 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.7031, time = 85.94 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7248, time = 86.63 seconds ___\n",
            "\n",
            "*** avg_loss : 0.69, time : ~10.0 min (633.71 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.69, time : 77.56 sec\n",
            "\n",
            "threshold:  [0.497556]\n",
            "model did not progress for 5 followed epochs\n",
            "-----------------BEST TH:  0.5094712\n",
            "-----------------TEST EVALUATION {'Positive Rate': array([0.4864865], dtype=float32), 'accuracy': 0.49324324324324326, 'f1': 0.5145631067961165, 'recall': 0.5520833333333334, 'specificity': 0.4375, 'default_accuracy': 0.5016891891891891, 'default_f1': 0.6581691772885284, 'default_recall': 0.9861111111111112, 'default_specificity': 0.04276315789473684}\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Para label:  Adecuación curricular de acceso   12 %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "\n",
            "=============== EPOCH 1 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.7367, time = 0.35 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.5478, time = 86.19 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6042, time = 85.93 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.5141, time = 85.63 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.9188, time = 86.37 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5219, time = 85.71 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5542, time = 85.74 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7057, time = 86.36 seconds ___\n",
            "\n",
            "*** avg_loss : 0.60, time : ~10.0 min (631.99 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.53, time : 77.20 sec\n",
            "\n",
            "threshold:  [0.7555091]\n",
            "=====>\t{'Positive Rate': array([0.78088963], dtype=float32), 'threshold': 0.7555091, 'accuracy': 0.3723228995057661, 'f1': 0.36815920398009955, 'recall': 0.23417721518987342, 'specificity': 0.8646616541353384, 'default_accuracy': 0.7808896210873146, 'default_f1': 0.8769657724329325, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "\n",
            "=============== EPOCH 2 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.3395, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.4135, time = 86.27 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6231, time = 86.00 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.4205, time = 85.57 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 1.0003, time = 86.38 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5255, time = 85.69 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5258, time = 85.77 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7151, time = 86.37 seconds ___\n",
            "\n",
            "*** avg_loss : 0.59, time : ~10.0 min (632.04 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.53, time : 77.28 sec\n",
            "\n",
            "threshold:  [0.7579778]\n",
            "=====>\t{'Positive Rate': array([0.78088963], dtype=float32), 'threshold': 0.7579778, 'accuracy': 0.37067545304777594, 'f1': 0.36963696369636967, 'recall': 0.23628691983122363, 'specificity': 0.849624060150376, 'default_accuracy': 0.7808896210873146, 'default_f1': 0.8769657724329325, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "\n",
            "=============== EPOCH 3 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.3298, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.4077, time = 86.33 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6294, time = 86.00 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.4132, time = 85.71 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 1.0195, time = 86.41 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5258, time = 85.75 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5221, time = 85.84 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7224, time = 86.38 seconds ___\n",
            "\n",
            "*** avg_loss : 0.59, time : ~10.0 min (632.40 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.53, time : 77.30 sec\n",
            "\n",
            "threshold:  [0.7643453]\n",
            "=====>\t{'Positive Rate': array([0.78088963], dtype=float32), 'threshold': 0.7643453, 'accuracy': 0.3657331136738056, 'f1': 0.36363636363636365, 'recall': 0.2320675105485232, 'specificity': 0.8421052631578947, 'default_accuracy': 0.7808896210873146, 'default_f1': 0.8769657724329325, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "\n",
            "=============== EPOCH 4 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.3396, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.4147, time = 86.27 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6313, time = 85.97 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.4197, time = 85.60 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 1.0073, time = 86.38 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5283, time = 85.74 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5254, time = 85.79 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7202, time = 86.36 seconds ___\n",
            "\n",
            "*** avg_loss : 0.59, time : ~10.0 min (632.11 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.53, time : 77.27 sec\n",
            "\n",
            "threshold:  [0.76614094]\n",
            "=====>\t{'Positive Rate': array([0.78088963], dtype=float32), 'threshold': 0.76614094, 'accuracy': 0.3640856672158155, 'f1': 0.3630363036303631, 'recall': 0.2320675105485232, 'specificity': 0.8345864661654135, 'default_accuracy': 0.7808896210873146, 'default_f1': 0.8769657724329325, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "\n",
            "=============== EPOCH 5 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.3871, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.4021, time = 86.29 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6348, time = 85.99 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.4218, time = 85.62 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 1.0411, time = 86.44 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5290, time = 85.75 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5231, time = 85.81 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7241, time = 86.37 seconds ___\n",
            "\n",
            "*** avg_loss : 0.59, time : ~10.0 min (632.36 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.53, time : 77.28 sec\n",
            "\n",
            "threshold:  [0.77276874]\n",
            "=====>\t{'Positive Rate': array([0.78088963], dtype=float32), 'threshold': 0.77276874, 'accuracy': 0.3640856672158155, 'f1': 0.3630363036303631, 'recall': 0.2320675105485232, 'specificity': 0.8345864661654135, 'default_accuracy': 0.7808896210873146, 'default_f1': 0.8769657724329325, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "\n",
            "=============== EPOCH 6 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.3784, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.3940, time = 86.28 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6371, time = 86.03 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.4281, time = 85.60 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 1.0195, time = 86.42 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5327, time = 85.74 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5257, time = 85.82 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7295, time = 86.39 seconds ___\n",
            "\n",
            "*** avg_loss : 0.58, time : ~10.0 min (632.26 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.53, time : 77.26 sec\n",
            "\n",
            "threshold:  [0.783399]\n",
            "=====>\t{'Positive Rate': array([0.78088963], dtype=float32), 'threshold': 0.783399, 'accuracy': 0.35914332784184516, 'f1': 0.3570247933884298, 'recall': 0.22784810126582278, 'specificity': 0.8270676691729323, 'default_accuracy': 0.7808896210873146, 'default_f1': 0.8769657724329325, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "\n",
            "=============== EPOCH 7 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 1.4044, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 0.3916, time = 86.25 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.6412, time = 85.91 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.4280, time = 85.54 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 1.0163, time = 86.31 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.5372, time = 85.68 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.5238, time = 85.75 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.7392, time = 86.32 seconds ___\n",
            "\n",
            "*** avg_loss : 0.58, time : ~10.0 min (631.73 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.53, time : 76.89 sec\n",
            "\n",
            "threshold:  [0.790394]\n",
            "model did not progress for 5 followed epochs\n",
            "-----------------BEST TH:  0.783399\n",
            "-----------------TEST EVALUATION {'Positive Rate': array([0.7685811], dtype=float32), 'accuracy': 0.3902027027027027, 'f1': 0.38500851788756396, 'recall': 0.24835164835164836, 'specificity': 0.8613138686131386, 'default_accuracy': 0.768581081081081, 'default_f1': 0.8691499522445081, 'default_recall': 1.0, 'default_specificity': 0.0}\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Para label:  Adecuación curricular de objetivos   13 %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "\n",
            "=============== EPOCH 1 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.6457, time = 0.35 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 1.0441, time = 85.92 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.4922, time = 87.26 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.3150, time = 85.24 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.2277, time = 86.10 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1698, time = 85.42 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1439, time = 85.44 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.1225, time = 86.03 seconds ___\n",
            "\n",
            "*** avg_loss : 0.35, time : ~10.0 min (631.32 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.31, time : 76.19 sec\n",
            "\n",
            "threshold:  [0.09347881]\n",
            "=====>\t{'Positive Rate': array([0.092257], dtype=float32), 'threshold': 0.093478814, 'accuracy': 0.15815485996705106, 'f1': 0.16091954022988506, 'recall': 0.875, 'specificity': 0.0852994555353902, 'default_accuracy': 0.9077429983525536, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 2 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.1029, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 1.7100, time = 85.95 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.4062, time = 85.68 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.2210, time = 85.25 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1479, time = 86.04 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1234, time = 85.40 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1115, time = 85.48 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.0996, time = 86.03 seconds ___\n",
            "\n",
            "*** avg_loss : 0.33, time : ~10.0 min (629.75 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.31, time : 76.36 sec\n",
            "\n",
            "threshold:  [0.08103853]\n",
            "=====>\t{'Positive Rate': array([0.092257], dtype=float32), 'threshold': 0.081038535, 'accuracy': 0.14662273476112025, 'f1': 0.1480263157894737, 'recall': 0.8035714285714286, 'specificity': 0.07985480943738657, 'default_accuracy': 0.9077429983525536, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 3 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.0906, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 1.5840, time = 85.89 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.3661, time = 85.68 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.1938, time = 85.34 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1277, time = 86.12 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1060, time = 85.39 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.0985, time = 85.61 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.0893, time = 85.89 seconds ___\n",
            "\n",
            "*** avg_loss : 0.31, time : ~10.0 min (629.74 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.31, time : 76.28 sec\n",
            "\n",
            "threshold:  [0.07130119]\n",
            "=====>\t{'Positive Rate': array([0.092257], dtype=float32), 'threshold': 0.07130119, 'accuracy': 0.14497528830313014, 'f1': 0.15057283142389524, 'recall': 0.8214285714285714, 'specificity': 0.07622504537205081, 'default_accuracy': 0.9077429983525536, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 4 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.0794, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 1.5205, time = 86.65 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.4696, time = 86.57 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.1887, time = 86.55 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1270, time = 87.37 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1117, time = 86.53 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.1008, time = 86.75 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.0866, time = 86.37 seconds ___\n",
            "\n",
            "*** avg_loss : 0.33, time : ~10.0 min (636.66 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.31, time : 76.53 sec\n",
            "\n",
            "threshold:  [0.06933478]\n",
            "=====>\t{'Positive Rate': array([0.092257], dtype=float32), 'threshold': 0.069334775, 'accuracy': 0.14991762767710048, 'f1': 0.15409836065573773, 'recall': 0.8392857142857143, 'specificity': 0.07985480943738657, 'default_accuracy': 0.9077429983525536, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 5 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.0810, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 1.6770, time = 85.73 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.4105, time = 85.43 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.3130, time = 85.02 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1612, time = 85.84 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1084, time = 85.14 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.0919, time = 85.19 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.0793, time = 85.80 seconds ___\n",
            "\n",
            "*** avg_loss : 0.34, time : ~10.0 min (627.94 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.31, time : 76.79 sec\n",
            "\n",
            "threshold:  [0.06447199]\n",
            "=====>\t{'Positive Rate': array([0.092257], dtype=float32), 'threshold': 0.06447199, 'accuracy': 0.14662273476112025, 'f1': 0.15359477124183005, 'recall': 0.8392857142857143, 'specificity': 0.07622504537205081, 'default_accuracy': 0.9077429983525536, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n",
            "\n",
            "=============== EPOCH 6 / 40 ===============\n",
            "\n",
            "___ batch index = 0 / 1836 (0.00%), loss = 0.0758, time = 0.33 seconds ___\n",
            "___ batch index = 250 / 1836 (13.62%), loss = 1.7730, time = 86.12 seconds ___\n",
            "___ batch index = 500 / 1836 (27.23%), loss = 0.2988, time = 85.87 seconds ___\n",
            "___ batch index = 750 / 1836 (40.85%), loss = 0.2602, time = 85.46 seconds ___\n",
            "___ batch index = 1000 / 1836 (54.47%), loss = 0.1732, time = 86.30 seconds ___\n",
            "___ batch index = 1250 / 1836 (68.08%), loss = 0.1006, time = 85.59 seconds ___\n",
            "___ batch index = 1500 / 1836 (81.70%), loss = 0.0833, time = 86.24 seconds ___\n",
            "___ batch index = 1750 / 1836 (95.32%), loss = 0.0721, time = 87.36 seconds ___\n",
            "\n",
            "*** avg_loss : 0.33, time : ~10.0 min (633.25 sec) ***\n",
            "\n",
            "==> evaluation : avg_loss = 0.32, time : 78.30 sec\n",
            "\n",
            "threshold:  [0.05922852]\n",
            "model did not progress for 5 followed epochs\n",
            "-----------------BEST TH:  0.06447199\n",
            "-----------------TEST EVALUATION {'Positive Rate': array([0.0945946], dtype=float32), 'accuracy': 0.14189189189189189, 'f1': 0.16171617161716173, 'recall': 0.875, 'specificity': 0.06529850746268656, 'default_accuracy': 0.9054054054054054, 'default_f1': 0.0, 'default_recall': 0.0, 'default_specificity': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "sSy80ynPNVnE"
      },
      "source": [
        "# Results using GA 4, lr 6 last epoch eval 'threshold': 0.11975692, 'accuracy': 0.5518945634266886, 'f1': 0.5540983606557377\n",
        "# Results using GA 8, lr 6 last epoch eval 'threshold': 0.3185914, 'accuracy': 0.5848434925864909, 'f1': 0.5855263157894737\n",
        "# Results using GA 16, lr 6 last epoch eval 'threshold': 0.45071128, 'accuracy': 0.5601317957166392, 'f1': 0.5615763546798029\n",
        "# torch.save(model, f\"/research/jamunoz/models/flair_fine_tuning/d_lstm_model_\"+str(LABEL_INDEX)+\"_v3.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "RZ2g5nxbNVnE"
      },
      "source": [
        "# output, target=individual_test_loop_fun1(test_data_loader, model, device, label_index=LABEL_INDEX)\n",
        "# tmp_test=individual_test(target, output, th)\n",
        "# print(\"-----------------BEST TH: \", th)\n",
        "# print(\"-----------------TEST EVALUATION\", tmp_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}